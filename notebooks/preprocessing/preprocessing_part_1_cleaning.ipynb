{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAST30034: Applied Data Science Project 1\n",
    "---\n",
    "# Preprocessing Part 1: Cleaning The Data\n",
    "#### Xavier Travers (1178369)\n",
    "\n",
    "Cleaning the datasets of null, inconsistent, or unnecessary values.\n",
    "This is performed on the TLC data and COVID data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports used throughout this notebook\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import DataFrame, Column\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "\n",
    "# add homemade helpers\n",
    "sys.path.insert(1, '../../scripts')\n",
    "import helpers.cleaning_helpers as ch\n",
    "import helpers.join_helpers as jh\n",
    "\n",
    "# path where the data files are stored\n",
    "DATA_PATH = '../../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/17 02:08:35 WARN Utils: Your hostname, Polaris resolves to a loopback address: 127.0.1.1; using 172.22.167.96 instead (on interface eth0)\n",
      "22/08/17 02:08:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/17 02:08:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName('MAST30034 XT Project 1')\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config('spark.sql.repl.eagerEval.enabled', True) \n",
    "    .config('spark.sql.parquet.cacheMetadata', 'true')\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>month</th><th>day</th><th>cdc_week</th><th>week_index</th><th>us_format</th><th>week_ending</th><th>week_month</th><th>week_year</th><th>timeline</th></tr>\n",
       "<tr><td>2017</td><td>12</td><td>31</td><td>1</td><td>1</td><td>12/31/2017</td><td>2018-01-06</td><td>1</td><td>2018</td><td>0</td></tr>\n",
       "<tr><td>2018</td><td>1</td><td>1</td><td>1</td><td>1</td><td>01/01/2018</td><td>2018-01-06</td><td>1</td><td>2018</td><td>0</td></tr>\n",
       "<tr><td>2018</td><td>1</td><td>2</td><td>1</td><td>1</td><td>01/02/2018</td><td>2018-01-06</td><td>1</td><td>2018</td><td>0</td></tr>\n",
       "<tr><td>2018</td><td>1</td><td>3</td><td>1</td><td>1</td><td>01/03/2018</td><td>2018-01-06</td><td>1</td><td>2018</td><td>0</td></tr>\n",
       "<tr><td>2018</td><td>1</td><td>4</td><td>1</td><td>1</td><td>01/04/2018</td><td>2018-01-06</td><td>1</td><td>2018</td><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-----+---+--------+----------+----------+-----------+----------+---------+--------+\n",
       "|year|month|day|cdc_week|week_index| us_format|week_ending|week_month|week_year|timeline|\n",
       "+----+-----+---+--------+----------+----------+-----------+----------+---------+--------+\n",
       "|2017|   12| 31|       1|         1|12/31/2017| 2018-01-06|         1|     2018|       0|\n",
       "|2018|    1|  1|       1|         1|01/01/2018| 2018-01-06|         1|     2018|       0|\n",
       "|2018|    1|  2|       1|         1|01/02/2018| 2018-01-06|         1|     2018|       0|\n",
       "|2018|    1|  3|       1|         1|01/03/2018| 2018-01-06|         1|     2018|       0|\n",
       "|2018|    1|  4|       1|         1|01/04/2018| 2018-01-06|         1|     2018|       0|\n",
       "+----+-----+---+--------+----------+----------+-----------+----------+---------+--------+"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the cdc week file to convert all dates to cdc weeks now\n",
    "mmwr_weeks_df = spark.read.parquet(f'{DATA_PATH}/raw/virals/mmwr_weeks.parquet')\n",
    "mmwr_weeks_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>LocationID</th><th>Borough</th><th>Zone</th><th>service_zone</th></tr>\n",
       "<tr><td>1</td><td>EWR</td><td>Newark Airport</td><td>EWR</td></tr>\n",
       "<tr><td>2</td><td>Queens</td><td>Jamaica Bay</td><td>Boro Zone</td></tr>\n",
       "<tr><td>3</td><td>Bronx</td><td>Allerton/Pelham G...</td><td>Boro Zone</td></tr>\n",
       "<tr><td>4</td><td>Manhattan</td><td>Alphabet City</td><td>Yellow Zone</td></tr>\n",
       "<tr><td>5</td><td>Staten Island</td><td>Arden Heights</td><td>Boro Zone</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+-------------+--------------------+------------+\n",
       "|LocationID|      Borough|                Zone|service_zone|\n",
       "+----------+-------------+--------------------+------------+\n",
       "|         1|          EWR|      Newark Airport|         EWR|\n",
       "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
       "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
       "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
       "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
       "+----------+-------------+--------------------+------------+"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the zones dataset\n",
    "zones_df = spark.read.csv(f'{DATA_PATH}/raw/tlc_zones/zones.csv',\n",
    "    header = True)\n",
    "zones_df.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Apply population statistics to zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New York</th>\n",
       "      <th>.Albany County, New York</th>\n",
       "      <th>.Allegany County, New York</th>\n",
       "      <th>.Bronx County, New York</th>\n",
       "      <th>.Broome County, New York</th>\n",
       "      <th>.Cattaraugus County, New York</th>\n",
       "      <th>.Cayuga County, New York</th>\n",
       "      <th>.Chautauqua County, New York</th>\n",
       "      <th>.Chemung County, New York</th>\n",
       "      <th>.Chenango County, New York</th>\n",
       "      <th>...</th>\n",
       "      <th>.Washington County, New York</th>\n",
       "      <th>.Wayne County, New York</th>\n",
       "      <th>.Westchester County, New York</th>\n",
       "      <th>.Wyoming County, New York</th>\n",
       "      <th>.Yates County, New York</th>\n",
       "      <th>Note: The estimates are based on the 2010 Census and reflect changes to the April 1, 2010 population due to the Count Question Resolution program and geographic program revisions. All geographic boundaries for the 2019 population estimates are as of January 1, 2019. For population estimates methodology statements, see http://www.census.gov/programs-surveys/popest/technical-documentation/methodology.html.</th>\n",
       "      <th>Suggested Citation:</th>\n",
       "      <th>Annual Estimates of the Resident Population for Counties in New York: April 1, 2010 to July 1, 2019 (CO-EST2019-ANNRES-36)</th>\n",
       "      <th>Source: U.S. Census Bureau, Population Division</th>\n",
       "      <th>Release Date: March 2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Census</th>\n",
       "      <td>19378102.0</td>\n",
       "      <td>304204.0</td>\n",
       "      <td>48946.0</td>\n",
       "      <td>1385108.0</td>\n",
       "      <td>200600.0</td>\n",
       "      <td>80317.0</td>\n",
       "      <td>80026.0</td>\n",
       "      <td>134905.0</td>\n",
       "      <td>88830.0</td>\n",
       "      <td>50477.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63216.0</td>\n",
       "      <td>93772.0</td>\n",
       "      <td>949113.0</td>\n",
       "      <td>42155.0</td>\n",
       "      <td>25348.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimates Base</th>\n",
       "      <td>19378144.0</td>\n",
       "      <td>304208.0</td>\n",
       "      <td>48923.0</td>\n",
       "      <td>1384580.0</td>\n",
       "      <td>200675.0</td>\n",
       "      <td>80337.0</td>\n",
       "      <td>80008.0</td>\n",
       "      <td>134907.0</td>\n",
       "      <td>88847.0</td>\n",
       "      <td>50511.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63254.0</td>\n",
       "      <td>93751.0</td>\n",
       "      <td>949218.0</td>\n",
       "      <td>42154.0</td>\n",
       "      <td>25364.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>19399878.0</td>\n",
       "      <td>304086.0</td>\n",
       "      <td>48971.0</td>\n",
       "      <td>1387298.0</td>\n",
       "      <td>200481.0</td>\n",
       "      <td>80218.0</td>\n",
       "      <td>79895.0</td>\n",
       "      <td>134725.0</td>\n",
       "      <td>88895.0</td>\n",
       "      <td>50399.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63356.0</td>\n",
       "      <td>93751.0</td>\n",
       "      <td>950601.0</td>\n",
       "      <td>42126.0</td>\n",
       "      <td>25376.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>19499241.0</td>\n",
       "      <td>304596.0</td>\n",
       "      <td>48800.0</td>\n",
       "      <td>1397335.0</td>\n",
       "      <td>199363.0</td>\n",
       "      <td>79815.0</td>\n",
       "      <td>79693.0</td>\n",
       "      <td>134209.0</td>\n",
       "      <td>88899.0</td>\n",
       "      <td>50182.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63091.0</td>\n",
       "      <td>93256.0</td>\n",
       "      <td>956262.0</td>\n",
       "      <td>41849.0</td>\n",
       "      <td>25454.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>19572932.0</td>\n",
       "      <td>305723.0</td>\n",
       "      <td>48210.0</td>\n",
       "      <td>1411496.0</td>\n",
       "      <td>198667.0</td>\n",
       "      <td>79348.0</td>\n",
       "      <td>79505.0</td>\n",
       "      <td>133304.0</td>\n",
       "      <td>89137.0</td>\n",
       "      <td>49883.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63003.0</td>\n",
       "      <td>93029.0</td>\n",
       "      <td>959585.0</td>\n",
       "      <td>41700.0</td>\n",
       "      <td>25337.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  New York  .Albany County, New York  \\\n",
       "Census          19378102.0                  304204.0   \n",
       "Estimates Base  19378144.0                  304208.0   \n",
       "2010            19399878.0                  304086.0   \n",
       "2011            19499241.0                  304596.0   \n",
       "2012            19572932.0                  305723.0   \n",
       "\n",
       "                .Allegany County, New York  .Bronx County, New York  \\\n",
       "Census                             48946.0                1385108.0   \n",
       "Estimates Base                     48923.0                1384580.0   \n",
       "2010                               48971.0                1387298.0   \n",
       "2011                               48800.0                1397335.0   \n",
       "2012                               48210.0                1411496.0   \n",
       "\n",
       "                .Broome County, New York  .Cattaraugus County, New York  \\\n",
       "Census                          200600.0                        80317.0   \n",
       "Estimates Base                  200675.0                        80337.0   \n",
       "2010                            200481.0                        80218.0   \n",
       "2011                            199363.0                        79815.0   \n",
       "2012                            198667.0                        79348.0   \n",
       "\n",
       "                .Cayuga County, New York  .Chautauqua County, New York  \\\n",
       "Census                           80026.0                      134905.0   \n",
       "Estimates Base                   80008.0                      134907.0   \n",
       "2010                             79895.0                      134725.0   \n",
       "2011                             79693.0                      134209.0   \n",
       "2012                             79505.0                      133304.0   \n",
       "\n",
       "                .Chemung County, New York  .Chenango County, New York  ...  \\\n",
       "Census                            88830.0                     50477.0  ...   \n",
       "Estimates Base                    88847.0                     50511.0  ...   \n",
       "2010                              88895.0                     50399.0  ...   \n",
       "2011                              88899.0                     50182.0  ...   \n",
       "2012                              89137.0                     49883.0  ...   \n",
       "\n",
       "                .Washington County, New York  .Wayne County, New York  \\\n",
       "Census                               63216.0                  93772.0   \n",
       "Estimates Base                       63254.0                  93751.0   \n",
       "2010                                 63356.0                  93751.0   \n",
       "2011                                 63091.0                  93256.0   \n",
       "2012                                 63003.0                  93029.0   \n",
       "\n",
       "                .Westchester County, New York  .Wyoming County, New York  \\\n",
       "Census                               949113.0                    42155.0   \n",
       "Estimates Base                       949218.0                    42154.0   \n",
       "2010                                 950601.0                    42126.0   \n",
       "2011                                 956262.0                    41849.0   \n",
       "2012                                 959585.0                    41700.0   \n",
       "\n",
       "                .Yates County, New York  \\\n",
       "Census                          25348.0   \n",
       "Estimates Base                  25364.0   \n",
       "2010                            25376.0   \n",
       "2011                            25454.0   \n",
       "2012                            25337.0   \n",
       "\n",
       "                Note: The estimates are based on the 2010 Census and reflect changes to the April 1, 2010 population due to the Count Question Resolution program and geographic program revisions. All geographic boundaries for the 2019 population estimates are as of January 1, 2019. For population estimates methodology statements, see http://www.census.gov/programs-surveys/popest/technical-documentation/methodology.html.  \\\n",
       "Census                                                        NaN                                                                                                                                                                                                                                                                                                                                                                         \n",
       "Estimates Base                                                NaN                                                                                                                                                                                                                                                                                                                                                                         \n",
       "2010                                                          NaN                                                                                                                                                                                                                                                                                                                                                                         \n",
       "2011                                                          NaN                                                                                                                                                                                                                                                                                                                                                                         \n",
       "2012                                                          NaN                                                                                                                                                                                                                                                                                                                                                                         \n",
       "\n",
       "                Suggested Citation:  \\\n",
       "Census                          NaN   \n",
       "Estimates Base                  NaN   \n",
       "2010                            NaN   \n",
       "2011                            NaN   \n",
       "2012                            NaN   \n",
       "\n",
       "                Annual Estimates of the Resident Population for Counties in New York: April 1, 2010 to July 1, 2019 (CO-EST2019-ANNRES-36)  \\\n",
       "Census                                                        NaN                                                                            \n",
       "Estimates Base                                                NaN                                                                            \n",
       "2010                                                          NaN                                                                            \n",
       "2011                                                          NaN                                                                            \n",
       "2012                                                          NaN                                                                            \n",
       "\n",
       "                Source: U.S. Census Bureau, Population Division  \\\n",
       "Census                                                      NaN   \n",
       "Estimates Base                                              NaN   \n",
       "2010                                                        NaN   \n",
       "2011                                                        NaN   \n",
       "2012                                                        NaN   \n",
       "\n",
       "                Release Date: March 2020  \n",
       "Census                               NaN  \n",
       "Estimates Base                       NaN  \n",
       "2010                                 NaN  \n",
       "2011                                 NaN  \n",
       "2012                                 NaN  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the populations data\n",
    "pop_df_2010_2019 = pd.read_excel(f'{DATA_PATH}/raw/populations/2010_2019.xlsx',\n",
    "    header = [3], index_col=0).transpose()\n",
    "\n",
    "pop_df_2010_2019.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Census</th>\n",
       "      <td>1385108.0</td>\n",
       "      <td>2504700.0</td>\n",
       "      <td>1585873.0</td>\n",
       "      <td>2230722.0</td>\n",
       "      <td>468730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimates Base</th>\n",
       "      <td>1384580.0</td>\n",
       "      <td>2504721.0</td>\n",
       "      <td>1586381.0</td>\n",
       "      <td>2230619.0</td>\n",
       "      <td>468730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>1387298.0</td>\n",
       "      <td>2509828.0</td>\n",
       "      <td>1588767.0</td>\n",
       "      <td>2234701.0</td>\n",
       "      <td>469615.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>1397335.0</td>\n",
       "      <td>2540817.0</td>\n",
       "      <td>1608293.0</td>\n",
       "      <td>2255482.0</td>\n",
       "      <td>471021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>1411496.0</td>\n",
       "      <td>2568450.0</td>\n",
       "      <td>1623911.0</td>\n",
       "      <td>2272222.0</td>\n",
       "      <td>470614.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Bronx   Brooklyn  Manhattan     Queens  Staten Island\n",
       "Census          1385108.0  2504700.0  1585873.0  2230722.0       468730.0\n",
       "Estimates Base  1384580.0  2504721.0  1586381.0  2230619.0       468730.0\n",
       "2010            1387298.0  2509828.0  1588767.0  2234701.0       469615.0\n",
       "2011            1397335.0  2540817.0  1608293.0  2255482.0       471021.0\n",
       "2012            1411496.0  2568450.0  1623911.0  2272222.0       470614.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_df_2010_2019 = pop_df_2010_2019[[\n",
    "    '.Bronx County, New York',\n",
    "    '.Kings County, New York',\n",
    "    '.New York County, New York',\n",
    "    '.Queens County, New York',\n",
    "    '.Richmond County, New York']]\n",
    "pop_df_2010_2019.columns = [\n",
    "    'Bronx',\n",
    "    'Brooklyn',\n",
    "    'Manhattan',\n",
    "    'Queens',\n",
    "    'Staten Island'\n",
    "]\n",
    "pop_df_2010_2019.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New York</th>\n",
       "      <th>.Albany County, New York</th>\n",
       "      <th>.Allegany County, New York</th>\n",
       "      <th>.Bronx County, New York</th>\n",
       "      <th>.Broome County, New York</th>\n",
       "      <th>.Cattaraugus County, New York</th>\n",
       "      <th>.Cayuga County, New York</th>\n",
       "      <th>.Chautauqua County, New York</th>\n",
       "      <th>.Chemung County, New York</th>\n",
       "      <th>.Chenango County, New York</th>\n",
       "      <th>...</th>\n",
       "      <th>.Washington County, New York</th>\n",
       "      <th>.Wayne County, New York</th>\n",
       "      <th>.Westchester County, New York</th>\n",
       "      <th>.Wyoming County, New York</th>\n",
       "      <th>.Yates County, New York</th>\n",
       "      <th>Note: The estimates are developed from a base that incorporates the 2020 Census, Vintage 2020 estimates, and 2020 Demographic Analysis estimates.  For population estimates methodology statements, see http://www.census.gov/programs-surveys/popest/technical-documentation/methodology.html. The estimates feature geographic boundaries from the Vintage 2020 estimates series; the geographic boundaries for these 2021 population estimates are as of January 1, 2020.</th>\n",
       "      <th>Suggested Citation:</th>\n",
       "      <th>Annual Estimates of the Resident Population for Counties in New York: April 1, 2020 to July 1, 2021\\n(CO-EST2021-POP-36)</th>\n",
       "      <th>Source: U.S. Census Bureau, Population Division</th>\n",
       "      <th>Release Date: March 2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <td>20201249.0</td>\n",
       "      <td>314848.0</td>\n",
       "      <td>46456.0</td>\n",
       "      <td>1472654.0</td>\n",
       "      <td>198683.0</td>\n",
       "      <td>77042.0</td>\n",
       "      <td>76248.0</td>\n",
       "      <td>127657.0</td>\n",
       "      <td>84148.0</td>\n",
       "      <td>47220.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61302.0</td>\n",
       "      <td>91283.0</td>\n",
       "      <td>1004457.0</td>\n",
       "      <td>40531.0</td>\n",
       "      <td>24774.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>20154933.0</td>\n",
       "      <td>314368.0</td>\n",
       "      <td>46373.0</td>\n",
       "      <td>1466438.0</td>\n",
       "      <td>198199.0</td>\n",
       "      <td>76907.0</td>\n",
       "      <td>76095.0</td>\n",
       "      <td>127424.0</td>\n",
       "      <td>83882.0</td>\n",
       "      <td>47073.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61143.0</td>\n",
       "      <td>91103.0</td>\n",
       "      <td>1003245.0</td>\n",
       "      <td>40401.0</td>\n",
       "      <td>24709.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>19835913.0</td>\n",
       "      <td>313743.0</td>\n",
       "      <td>46106.0</td>\n",
       "      <td>1424948.0</td>\n",
       "      <td>197240.0</td>\n",
       "      <td>76426.0</td>\n",
       "      <td>75880.0</td>\n",
       "      <td>126807.0</td>\n",
       "      <td>83045.0</td>\n",
       "      <td>46537.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60956.0</td>\n",
       "      <td>90923.0</td>\n",
       "      <td>997895.0</td>\n",
       "      <td>40491.0</td>\n",
       "      <td>24613.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              New York  .Albany County, New York  .Allegany County, New York  \\\n",
       "Unnamed: 1  20201249.0                  314848.0                     46456.0   \n",
       "2020        20154933.0                  314368.0                     46373.0   \n",
       "2021        19835913.0                  313743.0                     46106.0   \n",
       "\n",
       "            .Bronx County, New York  .Broome County, New York  \\\n",
       "Unnamed: 1                1472654.0                  198683.0   \n",
       "2020                      1466438.0                  198199.0   \n",
       "2021                      1424948.0                  197240.0   \n",
       "\n",
       "            .Cattaraugus County, New York  .Cayuga County, New York  \\\n",
       "Unnamed: 1                        77042.0                   76248.0   \n",
       "2020                              76907.0                   76095.0   \n",
       "2021                              76426.0                   75880.0   \n",
       "\n",
       "            .Chautauqua County, New York  .Chemung County, New York  \\\n",
       "Unnamed: 1                      127657.0                    84148.0   \n",
       "2020                            127424.0                    83882.0   \n",
       "2021                            126807.0                    83045.0   \n",
       "\n",
       "            .Chenango County, New York  ...  .Washington County, New York  \\\n",
       "Unnamed: 1                     47220.0  ...                       61302.0   \n",
       "2020                           47073.0  ...                       61143.0   \n",
       "2021                           46537.0  ...                       60956.0   \n",
       "\n",
       "            .Wayne County, New York  .Westchester County, New York  \\\n",
       "Unnamed: 1                  91283.0                      1004457.0   \n",
       "2020                        91103.0                      1003245.0   \n",
       "2021                        90923.0                       997895.0   \n",
       "\n",
       "            .Wyoming County, New York  .Yates County, New York  \\\n",
       "Unnamed: 1                    40531.0                  24774.0   \n",
       "2020                          40401.0                  24709.0   \n",
       "2021                          40491.0                  24613.0   \n",
       "\n",
       "            Note: The estimates are developed from a base that incorporates the 2020 Census, Vintage 2020 estimates, and 2020 Demographic Analysis estimates.  For population estimates methodology statements, see http://www.census.gov/programs-surveys/popest/technical-documentation/methodology.html. The estimates feature geographic boundaries from the Vintage 2020 estimates series; the geographic boundaries for these 2021 population estimates are as of January 1, 2020.   \\\n",
       "Unnamed: 1                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "2020                                                      NaN                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "2021                                                      NaN                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "\n",
       "            Suggested Citation:  \\\n",
       "Unnamed: 1                  NaN   \n",
       "2020                        NaN   \n",
       "2021                        NaN   \n",
       "\n",
       "            Annual Estimates of the Resident Population for Counties in New York: April 1, 2020 to July 1, 2021\\n(CO-EST2021-POP-36)  \\\n",
       "Unnamed: 1                                                NaN                                                                          \n",
       "2020                                                      NaN                                                                          \n",
       "2021                                                      NaN                                                                          \n",
       "\n",
       "            Source: U.S. Census Bureau, Population Division  \\\n",
       "Unnamed: 1                                              NaN   \n",
       "2020                                                    NaN   \n",
       "2021                                                    NaN   \n",
       "\n",
       "            Release Date: March 2022  \n",
       "Unnamed: 1                       NaN  \n",
       "2020                             NaN  \n",
       "2021                             NaN  \n",
       "\n",
       "[3 rows x 68 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the populations data\n",
    "pop_df_2020_2021 = pd.read_excel(f'{DATA_PATH}/raw/populations/2020_2021.xlsx',\n",
    "    header = [3], index_col=0).transpose()\n",
    "\n",
    "pop_df_2020_2021.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <td>1472654.0</td>\n",
       "      <td>2736074.0</td>\n",
       "      <td>1694251.0</td>\n",
       "      <td>2405464.0</td>\n",
       "      <td>495747.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>1466438.0</td>\n",
       "      <td>2727393.0</td>\n",
       "      <td>1687834.0</td>\n",
       "      <td>2395791.0</td>\n",
       "      <td>495522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>1424948.0</td>\n",
       "      <td>2641052.0</td>\n",
       "      <td>1576876.0</td>\n",
       "      <td>2331143.0</td>\n",
       "      <td>493494.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Bronx   Brooklyn  Manhattan     Queens  Staten Island\n",
       "Unnamed: 1  1472654.0  2736074.0  1694251.0  2405464.0       495747.0\n",
       "2020        1466438.0  2727393.0  1687834.0  2395791.0       495522.0\n",
       "2021        1424948.0  2641052.0  1576876.0  2331143.0       493494.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_df_2020_2021 = pop_df_2020_2021[[\n",
    "    '.Bronx County, New York',\n",
    "    '.Kings County, New York',\n",
    "    '.New York County, New York',\n",
    "    '.Queens County, New York',\n",
    "    '.Richmond County, New York']]\n",
    "pop_df_2020_2021.columns = [\n",
    "    'Bronx',\n",
    "    'Brooklyn',\n",
    "    'Manhattan',\n",
    "    'Queens',\n",
    "    'Staten Island'\n",
    "]\n",
    "pop_df_2020_2021.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1432087.0</td>\n",
       "      <td>2578074.0</td>\n",
       "      <td>1629055.0</td>\n",
       "      <td>2274605.0</td>\n",
       "      <td>476260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>1418207.0</td>\n",
       "      <td>2559903.0</td>\n",
       "      <td>1628706.0</td>\n",
       "      <td>2253858.0</td>\n",
       "      <td>476143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>1466438.0</td>\n",
       "      <td>2727393.0</td>\n",
       "      <td>1687834.0</td>\n",
       "      <td>2395791.0</td>\n",
       "      <td>495522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>1424948.0</td>\n",
       "      <td>2641052.0</td>\n",
       "      <td>1576876.0</td>\n",
       "      <td>2331143.0</td>\n",
       "      <td>493494.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Bronx   Brooklyn  Manhattan     Queens  Staten Island\n",
       "2018  1432087.0  2578074.0  1629055.0  2274605.0       476260.0\n",
       "2019  1418207.0  2559903.0  1628706.0  2253858.0       476143.0\n",
       "2020  1466438.0  2727393.0  1687834.0  2395791.0       495522.0\n",
       "2021  1424948.0  2641052.0  1576876.0  2331143.0       493494.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack the population data\n",
    "pop_df = pd.concat(\n",
    "    [pop_df_2010_2019, pop_df_2020_2021]\n",
    ")\n",
    "# only keep 2018-2021 data\n",
    "pop_df = pop_df.filter(items = [2018, 2019, 2020, 2021], axis = 0)\n",
    "pop_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_year</th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>1432087.0</td>\n",
       "      <td>2578074.0</td>\n",
       "      <td>1629055.0</td>\n",
       "      <td>2274605.0</td>\n",
       "      <td>476260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>1418207.0</td>\n",
       "      <td>2559903.0</td>\n",
       "      <td>1628706.0</td>\n",
       "      <td>2253858.0</td>\n",
       "      <td>476143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>1466438.0</td>\n",
       "      <td>2727393.0</td>\n",
       "      <td>1687834.0</td>\n",
       "      <td>2395791.0</td>\n",
       "      <td>495522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>1424948.0</td>\n",
       "      <td>2641052.0</td>\n",
       "      <td>1576876.0</td>\n",
       "      <td>2331143.0</td>\n",
       "      <td>493494.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week_year      Bronx   Brooklyn  Manhattan     Queens  Staten Island\n",
       "0       2018  1432087.0  2578074.0  1629055.0  2274605.0       476260.0\n",
       "1       2019  1418207.0  2559903.0  1628706.0  2253858.0       476143.0\n",
       "2       2020  1466438.0  2727393.0  1687834.0  2395791.0       495522.0\n",
       "3       2021  1424948.0  2641052.0  1576876.0  2331143.0       493494.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename the index column\n",
    "pop_df.index.name = 'week_year'\n",
    "pop_df = pop_df.reset_index()\n",
    "pop_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>week_year</th><th>population</th><th>borough</th></tr>\n",
       "<tr><td>2018</td><td>1432087.0</td><td>Bronx</td></tr>\n",
       "<tr><td>2019</td><td>1418207.0</td><td>Bronx</td></tr>\n",
       "<tr><td>2020</td><td>1466438.0</td><td>Bronx</td></tr>\n",
       "<tr><td>2021</td><td>1424948.0</td><td>Bronx</td></tr>\n",
       "<tr><td>2018</td><td>2578074.0</td><td>Brooklyn</td></tr>\n",
       "<tr><td>2019</td><td>2559903.0</td><td>Brooklyn</td></tr>\n",
       "<tr><td>2020</td><td>2727393.0</td><td>Brooklyn</td></tr>\n",
       "<tr><td>2021</td><td>2641052.0</td><td>Brooklyn</td></tr>\n",
       "<tr><td>2018</td><td>1629055.0</td><td>Manhattan</td></tr>\n",
       "<tr><td>2019</td><td>1628706.0</td><td>Manhattan</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+----------+---------+\n",
       "|week_year|population|  borough|\n",
       "+---------+----------+---------+\n",
       "|     2018| 1432087.0|    Bronx|\n",
       "|     2019| 1418207.0|    Bronx|\n",
       "|     2020| 1466438.0|    Bronx|\n",
       "|     2021| 1424948.0|    Bronx|\n",
       "|     2018| 2578074.0| Brooklyn|\n",
       "|     2019| 2559903.0| Brooklyn|\n",
       "|     2020| 2727393.0| Brooklyn|\n",
       "|     2021| 2641052.0| Brooklyn|\n",
       "|     2018| 1629055.0|Manhattan|\n",
       "|     2019| 1628706.0|Manhattan|\n",
       "+---------+----------+---------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verticalize the data (I just want a year column and a borough column)\n",
    "temp_df = None\n",
    "for col in pop_df.columns[1:]:\n",
    "    # using .copy() hides a space-hog warning about not editing pop_df \n",
    "    # (which is my intention)\n",
    "    b_pop_df = pop_df[['week_year', col]].copy()\n",
    "    b_pop_df.columns = ['week_year', 'population']\n",
    "    b_pop_df['borough'] = col\n",
    "\n",
    "    if temp_df is None:\n",
    "        temp_df = b_pop_df \n",
    "    else:\n",
    "        temp_df = pd.concat([temp_df, b_pop_df])\n",
    "pop_df = spark.createDataFrame(temp_df)\n",
    "pop_df.limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the population df\n",
    "pop_df.write.mode('overwrite').parquet(f'{DATA_PATH}/curated/population_by_borough_by_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cleaning the TLC dataset(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th></tr>\n",
       "<tr><td>2</td><td>2019-07-01 00:51:04</td><td>2019-07-01 00:51:33</td><td>1.0</td><td>0.0</td><td>1.0</td><td>N</td><td>193</td><td>193</td><td>1</td><td>2.5</td><td>0.5</td><td>0.5</td><td>1.14</td><td>0.0</td><td>0.3</td><td>4.94</td><td>0.0</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2019-07-01 00:46:04</td><td>2019-07-01 01:05:46</td><td>1.0</td><td>4.16</td><td>1.0</td><td>N</td><td>234</td><td>25</td><td>2</td><td>16.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>20.3</td><td>2.5</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-07-01 00:25:09</td><td>2019-07-01 01:00:56</td><td>1.0</td><td>18.8</td><td>2.0</td><td>N</td><td>132</td><td>42</td><td>1</td><td>52.0</td><td>0.0</td><td>0.5</td><td>11.75</td><td>6.12</td><td>0.3</td><td>70.67</td><td>0.0</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2019-07-01 00:33:32</td><td>2019-07-01 01:15:27</td><td>1.0</td><td>18.46</td><td>2.0</td><td>N</td><td>132</td><td>142</td><td>1</td><td>52.0</td><td>0.0</td><td>0.5</td><td>11.06</td><td>0.0</td><td>0.3</td><td>66.36</td><td>2.5</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-07-01 00:00:55</td><td>2019-07-01 00:13:05</td><td>0.0</td><td>1.7</td><td>1.0</td><td>N</td><td>107</td><td>114</td><td>1</td><td>9.5</td><td>3.0</td><td>0.5</td><td>2.0</td><td>0.0</td><td>0.3</td><td>15.3</td><td>2.5</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|       2| 2019-07-01 00:51:04|  2019-07-01 00:51:33|            1.0|          0.0|       1.0|                 N|         193|         193|           1|        2.5|  0.5|    0.5|      1.14|         0.0|                  0.3|        4.94|                 0.0|       null|\n",
       "|       2| 2019-07-01 00:46:04|  2019-07-01 01:05:46|            1.0|         4.16|       1.0|                 N|         234|          25|           2|       16.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        20.3|                 2.5|       null|\n",
       "|       1| 2019-07-01 00:25:09|  2019-07-01 01:00:56|            1.0|         18.8|       2.0|                 N|         132|          42|           1|       52.0|  0.0|    0.5|     11.75|        6.12|                  0.3|       70.67|                 0.0|       null|\n",
       "|       2| 2019-07-01 00:33:32|  2019-07-01 01:15:27|            1.0|        18.46|       2.0|                 N|         132|         142|           1|       52.0|  0.0|    0.5|     11.06|         0.0|                  0.3|       66.36|                 2.5|       null|\n",
       "|       1| 2019-07-01 00:00:55|  2019-07-01 00:13:05|            0.0|          1.7|       1.0|                 N|         107|         114|           1|        9.5|  3.0|    0.5|       2.0|         0.0|                  0.3|        15.3|                 2.5|       null|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df = spark.read.parquet(f'{DATA_PATH}/raw/tlc/yellow/2019_07.parquet/')\n",
    "example_df.limit(5)\n",
    "# TODO: commenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th></tr>\n",
       "<tr><td>2</td><td>2019-07-29 09:46:42</td><td>2019-07-29 15:12:31</td><td>1.0</td><td>311.56</td><td>4.0</td><td>N</td><td>68</td><td>265</td><td>2</td><td>1574.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>10.5</td><td>0.3</td><td>1587.8</td><td>2.5</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-07-17 13:42:23</td><td>2019-07-17 14:15:25</td><td>1.0</td><td>307.5</td><td>1.0</td><td>N</td><td>161</td><td>138</td><td>1</td><td>28.5</td><td>2.5</td><td>0.5</td><td>5.0</td><td>0.0</td><td>0.3</td><td>36.8</td><td>2.5</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2019-07-03 16:13:11</td><td>2019-07-03 20:09:21</td><td>2.0</td><td>180.09</td><td>5.0</td><td>N</td><td>93</td><td>265</td><td>1</td><td>400.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>57.12</td><td>0.3</td><td>457.42</td><td>0.0</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2019-07-19 07:01:46</td><td>2019-07-19 10:50:56</td><td>2.0</td><td>169.47</td><td>4.0</td><td>N</td><td>43</td><td>265</td><td>2</td><td>794.5</td><td>0.0</td><td>0.5</td><td>0.0</td><td>12.5</td><td>0.3</td><td>807.8</td><td>0.0</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2019-07-13 05:40:49</td><td>2019-07-13 08:32:15</td><td>4.0</td><td>168.44</td><td>4.0</td><td>N</td><td>132</td><td>265</td><td>2</td><td>796.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>797.8</td><td>0.0</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|       2| 2019-07-29 09:46:42|  2019-07-29 15:12:31|            1.0|       311.56|       4.0|                 N|          68|         265|           2|     1574.0|  0.0|    0.5|       0.0|        10.5|                  0.3|      1587.8|                 2.5|       null|\n",
       "|       1| 2019-07-17 13:42:23|  2019-07-17 14:15:25|            1.0|        307.5|       1.0|                 N|         161|         138|           1|       28.5|  2.5|    0.5|       5.0|         0.0|                  0.3|        36.8|                 2.5|       null|\n",
       "|       2| 2019-07-03 16:13:11|  2019-07-03 20:09:21|            2.0|       180.09|       5.0|                 N|          93|         265|           1|      400.0|  0.0|    0.0|       0.0|       57.12|                  0.3|      457.42|                 0.0|       null|\n",
       "|       2| 2019-07-19 07:01:46|  2019-07-19 10:50:56|            2.0|       169.47|       4.0|                 N|          43|         265|           2|      794.5|  0.0|    0.5|       0.0|        12.5|                  0.3|       807.8|                 0.0|       null|\n",
       "|       2| 2019-07-13 05:40:49|  2019-07-13 08:32:15|            4.0|       168.44|       4.0|                 N|         132|         265|           2|      796.5|  0.5|    0.5|       0.0|         0.0|                  0.3|       797.8|                 0.0|       null|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df.sort('trip_distance', ascending = False).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th></tr>\n",
       "<tr><td>1</td><td>2018-06-01 00:15:40</td><td>2018-06-01 00:16:46</td><td>1.0</td><td>0.0</td><td>1.0</td><td>N</td><td>145</td><td>145</td><td>2</td><td>3.0</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>4.3</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2018-06-01 00:04:18</td><td>2018-06-01 00:09:18</td><td>1.0</td><td>1.0</td><td>1.0</td><td>N</td><td>230</td><td>161</td><td>1</td><td>5.5</td><td>0.5</td><td>0.5</td><td>1.35</td><td>0.0</td><td>0.3</td><td>8.15</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2018-06-01 00:14:39</td><td>2018-06-01 00:29:46</td><td>1.0</td><td>3.3</td><td>1.0</td><td>N</td><td>100</td><td>263</td><td>2</td><td>13.0</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>14.3</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2018-06-01 00:51:25</td><td>2018-06-01 00:51:29</td><td>3.0</td><td>0.0</td><td>1.0</td><td>N</td><td>145</td><td>145</td><td>2</td><td>2.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>3.8</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2018-06-01 00:55:06</td><td>2018-06-01 00:55:10</td><td>1.0</td><td>0.0</td><td>1.0</td><td>N</td><td>145</td><td>145</td><td>2</td><td>2.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>3.8</td><td>null</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|       1| 2018-06-01 00:15:40|  2018-06-01 00:16:46|            1.0|          0.0|       1.0|                 N|         145|         145|           2|        3.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.3|                null|       null|\n",
       "|       1| 2018-06-01 00:04:18|  2018-06-01 00:09:18|            1.0|          1.0|       1.0|                 N|         230|         161|           1|        5.5|  0.5|    0.5|      1.35|         0.0|                  0.3|        8.15|                null|       null|\n",
       "|       1| 2018-06-01 00:14:39|  2018-06-01 00:29:46|            1.0|          3.3|       1.0|                 N|         100|         263|           2|       13.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        14.3|                null|       null|\n",
       "|       1| 2018-06-01 00:51:25|  2018-06-01 00:51:29|            3.0|          0.0|       1.0|                 N|         145|         145|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                null|       null|\n",
       "|       1| 2018-06-01 00:55:06|  2018-06-01 00:55:10|            1.0|          0.0|       1.0|                 N|         145|         145|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                null|       null|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the tlc data\n",
    "tlc_df = jh.read_stacked_tlc_df(spark)\n",
    "tlc_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "181904060"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "tlc_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive extra values which are used to filter out valid trips\n",
    "SECONDS_TO_HOURS = 1 / (60*60)\n",
    "tlc_df = tlc_df\\\n",
    "    .withColumn('hours_elapsed', \n",
    "        (\n",
    "            (F.col(\"tpep_dropoff_datetime\").cast(\"long\")\n",
    "            - F.col('tpep_pickup_datetime').cast(\"long\")) \n",
    "            * SECONDS_TO_HOURS\n",
    "        )\n",
    "    )\\\n",
    "    .withColumn('mph', (F.col('trip_distance') / F.col('hours_elapsed')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th><th>hours_elapsed</th><th>mph</th></tr>\n",
       "<tr><td>1</td><td>2018-06-01 00:15:40</td><td>2018-06-01 00:16:46</td><td>1.0</td><td>0.0</td><td>1.0</td><td>N</td><td>145</td><td>145</td><td>2</td><td>3.0</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>4.3</td><td>null</td><td>null</td><td>0.018333333333333333</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2018-06-01 00:04:18</td><td>2018-06-01 00:09:18</td><td>1.0</td><td>1.0</td><td>1.0</td><td>N</td><td>230</td><td>161</td><td>1</td><td>5.5</td><td>0.5</td><td>0.5</td><td>1.35</td><td>0.0</td><td>0.3</td><td>8.15</td><td>null</td><td>null</td><td>0.08333333333333333</td><td>12.0</td></tr>\n",
       "<tr><td>1</td><td>2018-06-01 00:14:39</td><td>2018-06-01 00:29:46</td><td>1.0</td><td>3.3</td><td>1.0</td><td>N</td><td>100</td><td>263</td><td>2</td><td>13.0</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>14.3</td><td>null</td><td>null</td><td>0.25194444444444447</td><td>13.098125689084894</td></tr>\n",
       "<tr><td>1</td><td>2018-06-01 00:51:25</td><td>2018-06-01 00:51:29</td><td>3.0</td><td>0.0</td><td>1.0</td><td>N</td><td>145</td><td>145</td><td>2</td><td>2.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>3.8</td><td>null</td><td>null</td><td>0.001111111111111...</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2018-06-01 00:55:06</td><td>2018-06-01 00:55:10</td><td>1.0</td><td>0.0</td><td>1.0</td><td>N</td><td>145</td><td>145</td><td>2</td><td>2.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>3.8</td><td>null</td><td>null</td><td>0.001111111111111...</td><td>0.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+--------------------+------------------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|       hours_elapsed|               mph|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+--------------------+------------------+\n",
       "|       1| 2018-06-01 00:15:40|  2018-06-01 00:16:46|            1.0|          0.0|       1.0|                 N|         145|         145|           2|        3.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.3|                null|       null|0.018333333333333333|               0.0|\n",
       "|       1| 2018-06-01 00:04:18|  2018-06-01 00:09:18|            1.0|          1.0|       1.0|                 N|         230|         161|           1|        5.5|  0.5|    0.5|      1.35|         0.0|                  0.3|        8.15|                null|       null| 0.08333333333333333|              12.0|\n",
       "|       1| 2018-06-01 00:14:39|  2018-06-01 00:29:46|            1.0|          3.3|       1.0|                 N|         100|         263|           2|       13.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        14.3|                null|       null| 0.25194444444444447|13.098125689084894|\n",
       "|       1| 2018-06-01 00:51:25|  2018-06-01 00:51:29|            3.0|          0.0|       1.0|                 N|         145|         145|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                null|       null|0.001111111111111...|               0.0|\n",
       "|       1| 2018-06-01 00:55:06|  2018-06-01 00:55:10|            1.0|          0.0|       1.0|                 N|         145|         145|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                null|       null|0.001111111111111...|               0.0|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+--------------------+------------------+"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlc_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ypdcrime.com/vt/article30.php?zoom_highlight=fifty+five+miles+per+hour#t1180-a\n",
    "# As per: https://www.dot.ny.gov/divisions/operating/oom/transportation-systems/repository/TSMI-17-05.pdf\n",
    "# the NYS maximum speed limit is 65 mph. filter out trips faster than legal.\n",
    "tlc_df = tlc_df.where(\n",
    "    (F.col('mph').isNotNull()) &\n",
    "    (F.col('mph') <= 65)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th><th>hours_elapsed</th><th>mph</th></tr>\n",
       "<tr><td>1</td><td>2020-06-02 06:36:15</td><td>2020-06-02 14:33:50</td><td>1.0</td><td>441.6</td><td>5.0</td><td>N</td><td>68</td><td>265</td><td>2</td><td>300.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.3</td><td>300.3</td><td>0.0</td><td>null</td><td>7.959722222222222</td><td>55.479322980282674</td></tr>\n",
       "<tr><td>1</td><td>2021-01-20 11:22:05</td><td>2021-01-20 19:47:56</td><td>1.0</td><td>427.7</td><td>1.0</td><td>Y</td><td>4</td><td>265</td><td>1</td><td>1128.5</td><td>2.5</td><td>0.5</td><td>1140.44</td><td>20.16</td><td>0.3</td><td>2292.4</td><td>2.5</td><td>null</td><td>8.430833333333334</td><td>50.73045369180586</td></tr>\n",
       "<tr><td>1</td><td>2020-07-30 15:10:02</td><td>2020-07-30 22:04:34</td><td>1.0</td><td>414.4</td><td>5.0</td><td>N</td><td>138</td><td>265</td><td>1</td><td>400.0</td><td>0.0</td><td>0.0</td><td>87.2</td><td>35.74</td><td>0.3</td><td>523.24</td><td>0.0</td><td>null</td><td>6.908888888888889</td><td>59.98070119009328</td></tr>\n",
       "<tr><td>2</td><td>2020-12-06 07:33:27</td><td>2020-12-06 14:01:29</td><td>1.0</td><td>407.78</td><td>5.0</td><td>N</td><td>264</td><td>265</td><td>1</td><td>200.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>11.75</td><td>0.3</td><td>215.55</td><td>2.5</td><td>null</td><td>6.467222222222222</td><td>63.05334593248002</td></tr>\n",
       "<tr><td>2</td><td>2018-08-12 06:48:02</td><td>2018-08-12 18:51:02</td><td>1.0</td><td>380.83</td><td>5.0</td><td>N</td><td>68</td><td>244</td><td>2</td><td>0.01</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.3</td><td>0.31</td><td>null</td><td>null</td><td>12.05</td><td>31.60414937759336</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-----------------+------------------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|    hours_elapsed|               mph|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-----------------+------------------+\n",
       "|       1| 2020-06-02 06:36:15|  2020-06-02 14:33:50|            1.0|        441.6|       5.0|                 N|          68|         265|           2|      300.0|  0.0|    0.0|       0.0|         0.0|                  0.3|       300.3|                 0.0|       null|7.959722222222222|55.479322980282674|\n",
       "|       1| 2021-01-20 11:22:05|  2021-01-20 19:47:56|            1.0|        427.7|       1.0|                 Y|           4|         265|           1|     1128.5|  2.5|    0.5|   1140.44|       20.16|                  0.3|      2292.4|                 2.5|       null|8.430833333333334| 50.73045369180586|\n",
       "|       1| 2020-07-30 15:10:02|  2020-07-30 22:04:34|            1.0|        414.4|       5.0|                 N|         138|         265|           1|      400.0|  0.0|    0.0|      87.2|       35.74|                  0.3|      523.24|                 0.0|       null|6.908888888888889| 59.98070119009328|\n",
       "|       2| 2020-12-06 07:33:27|  2020-12-06 14:01:29|            1.0|       407.78|       5.0|                 N|         264|         265|           1|      200.0|  0.0|    0.0|       1.0|       11.75|                  0.3|      215.55|                 2.5|       null|6.467222222222222| 63.05334593248002|\n",
       "|       2| 2018-08-12 06:48:02|  2018-08-12 18:51:02|            1.0|       380.83|       5.0|                 N|          68|         244|           2|       0.01|  0.0|    0.0|       0.0|         0.0|                  0.3|        0.31|                null|       null|            12.05| 31.60414937759336|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-----------------+------------------+"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this one is time instensive \n",
    "tlc_df.sort('trip_distance', ascending = False).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of the tlc datasets to clean \n",
    "# (I was originally planning on working on fhvhv and green as well)\n",
    "TLC_NAMES = ['yellow']\n",
    "\n",
    "# dictionary to rename all the columns I want to keep\n",
    "TLC_KEEP_COLUMNS = {\n",
    "    'tpep_pickup_datetime': 'date',\n",
    "    'passenger_count': 'passengers',\n",
    "    'trip_distance': 'trip_distance',\n",
    "    'PULocationID': 'pu_location_id',\n",
    "    'DOLocationID': 'do_location_id',\n",
    "    'hours_elapsed': 'hours_elapsed'\n",
    "    # #  below only apply to fhvhv\n",
    "    # 'hvfhs_license_num': 'fhvhv_license',\n",
    "    # 'pickup_datetime': 'date',\n",
    "    # 'trip_miles': 'trip_distance',\n",
    "    # 'shared_request_flag': 'shared'\n",
    "}\n",
    "\n",
    "# create a dictionary of the columns to keep and the required filters\n",
    "TLC_CLEAN_COLUMNS = {\n",
    "    'pu_location_id': [ch.non_null], \n",
    "    'do_location_id': [ch.non_null], \n",
    "    'passengers': [ch.non_null], \n",
    "    'trip_distance': [ch.non_null, ch.non_negative], \n",
    "    # 'fhvhv_license': [ch.non_null], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlc_df = ch.perform_cleaning(tlc_df, mmwr_weeks_df, TLC_KEEP_COLUMNS, \n",
    "    TLC_CLEAN_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>month</th><th>day</th><th>week_ending</th><th>week_year</th><th>week_month</th><th>week_index</th><th>timeline</th><th>date</th><th>passengers</th><th>trip_distance</th><th>pu_location_id</th><th>do_location_id</th><th>hours_elapsed</th><th>pu_borough</th><th>do_borough</th></tr>\n",
       "<tr><td>2018</td><td>8</td><td>12</td><td>2018-08-18</td><td>2018</td><td>8</td><td>33</td><td>1</td><td>08/12/2018</td><td>1.0</td><td>380.83</td><td>68</td><td>244</td><td>12.05</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>2020</td><td>9</td><td>9</td><td>2020-09-12</td><td>2020</td><td>9</td><td>141</td><td>2</td><td>09/09/2020</td><td>1.0</td><td>358.33</td><td>186</td><td>69</td><td>16.1075</td><td>Manhattan</td><td>Bronx</td></tr>\n",
       "<tr><td>2021</td><td>1</td><td>12</td><td>2021-01-16</td><td>2021</td><td>1</td><td>159</td><td>2</td><td>01/12/2021</td><td>0.0</td><td>326.1</td><td>234</td><td>39</td><td>8.66611111111111</td><td>Manhattan</td><td>Brooklyn</td></tr>\n",
       "<tr><td>2020</td><td>5</td><td>16</td><td>2020-05-16</td><td>2020</td><td>5</td><td>124</td><td>1</td><td>05/16/2020</td><td>2.0</td><td>305.1</td><td>4</td><td>79</td><td>6.5875</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>2020</td><td>11</td><td>13</td><td>2020-11-14</td><td>2020</td><td>11</td><td>150</td><td>2</td><td>11/13/2020</td><td>1.0</td><td>277.8</td><td>79</td><td>4</td><td>10.786388888888888</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-----+---+-----------+---------+----------+----------+--------+----------+----------+-------------+--------------+--------------+------------------+----------+----------+\n",
       "|year|month|day|week_ending|week_year|week_month|week_index|timeline|      date|passengers|trip_distance|pu_location_id|do_location_id|     hours_elapsed|pu_borough|do_borough|\n",
       "+----+-----+---+-----------+---------+----------+----------+--------+----------+----------+-------------+--------------+--------------+------------------+----------+----------+\n",
       "|2018|    8| 12| 2018-08-18|     2018|         8|        33|       1|08/12/2018|       1.0|       380.83|            68|           244|             12.05| Manhattan| Manhattan|\n",
       "|2020|    9|  9| 2020-09-12|     2020|         9|       141|       2|09/09/2020|       1.0|       358.33|           186|            69|           16.1075| Manhattan|     Bronx|\n",
       "|2021|    1| 12| 2021-01-16|     2021|         1|       159|       2|01/12/2021|       0.0|        326.1|           234|            39|  8.66611111111111| Manhattan|  Brooklyn|\n",
       "|2020|    5| 16| 2020-05-16|     2020|         5|       124|       1|05/16/2020|       2.0|        305.1|             4|            79|            6.5875| Manhattan| Manhattan|\n",
       "|2020|   11| 13| 2020-11-14|     2020|        11|       150|       2|11/13/2020|       1.0|        277.8|            79|             4|10.786388888888888| Manhattan| Manhattan|\n",
       "+----+-----+---+-----------+---------+----------+----------+--------+----------+----------+-------------+--------------+--------------+------------------+----------+----------+"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next, filter out trips which do not start and/or end within the 5 boroughs \n",
    "tlc_df = ch.extract_borough_name(tlc_df, zones_df,  'pu')\n",
    "tlc_df = ch.extract_borough_name(tlc_df, zones_df,  'do')\n",
    "tlc_df.sort('trip_distance', ascending=False).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>month</th><th>day</th><th>week_ending</th><th>week_year</th><th>week_month</th><th>week_index</th><th>timeline</th><th>date</th><th>passengers</th><th>trip_distance</th><th>pu_location_id</th><th>do_location_id</th><th>hours_elapsed</th><th>pu_borough</th><th>do_borough</th></tr>\n",
       "<tr><td>2021</td><td>12</td><td>15</td><td>2021-12-18</td><td>2021</td><td>12</td><td>207</td><td>0</td><td>12/15/2021</td><td>1.0</td><td>7.8</td><td>163</td><td>95</td><td>7.765833333333333</td><td>Manhattan</td><td>Queens</td></tr>\n",
       "<tr><td>2021</td><td>12</td><td>15</td><td>2021-12-18</td><td>2021</td><td>12</td><td>207</td><td>0</td><td>12/15/2021</td><td>1.0</td><td>0.78</td><td>107</td><td>234</td><td>0.12777777777777777</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>2021</td><td>12</td><td>15</td><td>2021-12-18</td><td>2021</td><td>12</td><td>207</td><td>0</td><td>12/15/2021</td><td>1.0</td><td>1.62</td><td>234</td><td>79</td><td>0.175</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>2021</td><td>12</td><td>15</td><td>2021-12-18</td><td>2021</td><td>12</td><td>207</td><td>0</td><td>12/15/2021</td><td>1.0</td><td>1.77</td><td>79</td><td>233</td><td>0.1597222222222222</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>2021</td><td>12</td><td>15</td><td>2021-12-18</td><td>2021</td><td>12</td><td>207</td><td>0</td><td>12/15/2021</td><td>1.0</td><td>1.23</td><td>233</td><td>163</td><td>0.13694444444444445</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>2021</td><td>11</td><td>24</td><td>2021-11-27</td><td>2021</td><td>11</td><td>204</td><td>0</td><td>11/24/2021</td><td>1.0</td><td>2.2</td><td>231</td><td>4</td><td>0.20944444444444443</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>2021</td><td>11</td><td>24</td><td>2021-11-27</td><td>2021</td><td>11</td><td>204</td><td>0</td><td>11/24/2021</td><td>1.0</td><td>2.06</td><td>164</td><td>249</td><td>0.16416666666666666</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>2021</td><td>11</td><td>24</td><td>2021-11-27</td><td>2021</td><td>11</td><td>204</td><td>0</td><td>11/24/2021</td><td>1.0</td><td>1.52</td><td>249</td><td>231</td><td>0.10888888888888888</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>2021</td><td>11</td><td>3</td><td>2021-11-06</td><td>2021</td><td>11</td><td>201</td><td>0</td><td>11/03/2021</td><td>1.0</td><td>2.98</td><td>75</td><td>161</td><td>6.339722222222222</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>2021</td><td>11</td><td>3</td><td>2021-11-06</td><td>2021</td><td>11</td><td>201</td><td>0</td><td>11/03/2021</td><td>2.0</td><td>1.29</td><td>41</td><td>42</td><td>0.12694444444444444</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-----+---+-----------+---------+----------+----------+--------+----------+----------+-------------+--------------+--------------+-------------------+----------+----------+\n",
       "|year|month|day|week_ending|week_year|week_month|week_index|timeline|      date|passengers|trip_distance|pu_location_id|do_location_id|      hours_elapsed|pu_borough|do_borough|\n",
       "+----+-----+---+-----------+---------+----------+----------+--------+----------+----------+-------------+--------------+--------------+-------------------+----------+----------+\n",
       "|2021|   12| 15| 2021-12-18|     2021|        12|       207|       0|12/15/2021|       1.0|          7.8|           163|            95|  7.765833333333333| Manhattan|    Queens|\n",
       "|2021|   12| 15| 2021-12-18|     2021|        12|       207|       0|12/15/2021|       1.0|         0.78|           107|           234|0.12777777777777777| Manhattan| Manhattan|\n",
       "|2021|   12| 15| 2021-12-18|     2021|        12|       207|       0|12/15/2021|       1.0|         1.62|           234|            79|              0.175| Manhattan| Manhattan|\n",
       "|2021|   12| 15| 2021-12-18|     2021|        12|       207|       0|12/15/2021|       1.0|         1.77|            79|           233| 0.1597222222222222| Manhattan| Manhattan|\n",
       "|2021|   12| 15| 2021-12-18|     2021|        12|       207|       0|12/15/2021|       1.0|         1.23|           233|           163|0.13694444444444445| Manhattan| Manhattan|\n",
       "|2021|   11| 24| 2021-11-27|     2021|        11|       204|       0|11/24/2021|       1.0|          2.2|           231|             4|0.20944444444444443| Manhattan| Manhattan|\n",
       "|2021|   11| 24| 2021-11-27|     2021|        11|       204|       0|11/24/2021|       1.0|         2.06|           164|           249|0.16416666666666666| Manhattan| Manhattan|\n",
       "|2021|   11| 24| 2021-11-27|     2021|        11|       204|       0|11/24/2021|       1.0|         1.52|           249|           231|0.10888888888888888| Manhattan| Manhattan|\n",
       "|2021|   11|  3| 2021-11-06|     2021|        11|       201|       0|11/03/2021|       1.0|         2.98|            75|           161|  6.339722222222222| Manhattan| Manhattan|\n",
       "|2021|   11|  3| 2021-11-06|     2021|        11|       201|       0|11/03/2021|       2.0|         1.29|            41|            42|0.12694444444444444| Manhattan| Manhattan|\n",
       "+----+-----+---+-----------+---------+----------+----------+--------+----------+----------+-------------+--------------+--------------+-------------------+----------+----------+"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlc_df.sort('week_index', ascending = False).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>month</th><th>day</th><th>week_ending</th><th>week_year</th><th>week_month</th><th>week_index</th><th>timeline</th><th>date</th><th>passengers</th><th>trip_distance</th><th>pu_location_id</th><th>do_location_id</th><th>hours_elapsed</th><th>pu_borough</th><th>do_borough</th></tr>\n",
       "<tr><td>2018</td><td>8</td><td>12</td><td>2018-08-18</td><td>2018</td><td>8</td><td>33</td><td>1</td><td>08/12/2018</td><td>1.0</td><td>380.83</td><td>68</td><td>244</td><td>12.05</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>2020</td><td>9</td><td>9</td><td>2020-09-12</td><td>2020</td><td>9</td><td>141</td><td>2</td><td>09/09/2020</td><td>1.0</td><td>358.33</td><td>186</td><td>69</td><td>16.1075</td><td>Manhattan</td><td>Bronx</td></tr>\n",
       "<tr><td>2021</td><td>1</td><td>12</td><td>2021-01-16</td><td>2021</td><td>1</td><td>159</td><td>2</td><td>01/12/2021</td><td>0.0</td><td>326.1</td><td>234</td><td>39</td><td>8.66611111111111</td><td>Manhattan</td><td>Brooklyn</td></tr>\n",
       "<tr><td>2020</td><td>5</td><td>16</td><td>2020-05-16</td><td>2020</td><td>5</td><td>124</td><td>1</td><td>05/16/2020</td><td>2.0</td><td>305.1</td><td>4</td><td>79</td><td>6.5875</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>2020</td><td>11</td><td>13</td><td>2020-11-14</td><td>2020</td><td>11</td><td>150</td><td>2</td><td>11/13/2020</td><td>1.0</td><td>277.8</td><td>79</td><td>4</td><td>10.786388888888888</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-----+---+-----------+---------+----------+----------+--------+----------+----------+-------------+--------------+--------------+------------------+----------+----------+\n",
       "|year|month|day|week_ending|week_year|week_month|week_index|timeline|      date|passengers|trip_distance|pu_location_id|do_location_id|     hours_elapsed|pu_borough|do_borough|\n",
       "+----+-----+---+-----------+---------+----------+----------+--------+----------+----------+-------------+--------------+--------------+------------------+----------+----------+\n",
       "|2018|    8| 12| 2018-08-18|     2018|         8|        33|       1|08/12/2018|       1.0|       380.83|            68|           244|             12.05| Manhattan| Manhattan|\n",
       "|2020|    9|  9| 2020-09-12|     2020|         9|       141|       2|09/09/2020|       1.0|       358.33|           186|            69|           16.1075| Manhattan|     Bronx|\n",
       "|2021|    1| 12| 2021-01-16|     2021|         1|       159|       2|01/12/2021|       0.0|        326.1|           234|            39|  8.66611111111111| Manhattan|  Brooklyn|\n",
       "|2020|    5| 16| 2020-05-16|     2020|         5|       124|       1|05/16/2020|       2.0|        305.1|             4|            79|            6.5875| Manhattan| Manhattan|\n",
       "|2020|   11| 13| 2020-11-14|     2020|        11|       150|       2|11/13/2020|       1.0|        277.8|            79|             4|10.786388888888888| Manhattan| Manhattan|\n",
       "+----+-----+---+-----------+---------+----------+----------+--------+----------+----------+-------------+--------------+--------------+------------------+----------+----------+"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlc_df.sort('trip_distance', ascending=False).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out any thing not in Timeline 1 (and 2)\n",
    "tlc_df = tlc_df.where(F.col('timeline') > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>month</th><th>day</th><th>week_ending</th><th>week_year</th><th>week_month</th><th>week_index</th><th>timeline</th><th>date</th><th>passengers</th><th>trip_distance</th><th>pu_location_id</th><th>do_location_id</th><th>hours_elapsed</th><th>pu_borough</th><th>do_borough</th></tr>\n",
       "<tr><td>2018</td><td>7</td><td>19</td><td>2018-07-21</td><td>2018</td><td>7</td><td>29</td><td>1</td><td>07/19/2018</td><td>2.0</td><td>0.52</td><td>237</td><td>141</td><td>0.05361111111111111</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>2018</td><td>7</td><td>19</td><td>2018-07-21</td><td>2018</td><td>7</td><td>29</td><td>1</td><td>07/19/2018</td><td>2.0</td><td>7.63</td><td>237</td><td>88</td><td>0.3927777777777778</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>2018</td><td>7</td><td>19</td><td>2018-07-21</td><td>2018</td><td>7</td><td>29</td><td>1</td><td>07/19/2018</td><td>2.0</td><td>4.82</td><td>261</td><td>107</td><td>7.309722222222222</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "<tr><td>2018</td><td>8</td><td>10</td><td>2018-08-11</td><td>2018</td><td>8</td><td>32</td><td>1</td><td>08/10/2018</td><td>2.0</td><td>5.05</td><td>107</td><td>33</td><td>0.2802777777777778</td><td>Manhattan</td><td>Brooklyn</td></tr>\n",
       "<tr><td>2018</td><td>8</td><td>10</td><td>2018-08-11</td><td>2018</td><td>8</td><td>32</td><td>1</td><td>08/10/2018</td><td>2.0</td><td>6.91</td><td>144</td><td>263</td><td>7.510833333333333</td><td>Manhattan</td><td>Manhattan</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-----+---+-----------+---------+----------+----------+--------+----------+----------+-------------+--------------+--------------+-------------------+----------+----------+\n",
       "|year|month|day|week_ending|week_year|week_month|week_index|timeline|      date|passengers|trip_distance|pu_location_id|do_location_id|      hours_elapsed|pu_borough|do_borough|\n",
       "+----+-----+---+-----------+---------+----------+----------+--------+----------+----------+-------------+--------------+--------------+-------------------+----------+----------+\n",
       "|2018|    7| 19| 2018-07-21|     2018|         7|        29|       1|07/19/2018|       2.0|         0.52|           237|           141|0.05361111111111111| Manhattan| Manhattan|\n",
       "|2018|    7| 19| 2018-07-21|     2018|         7|        29|       1|07/19/2018|       2.0|         7.63|           237|            88| 0.3927777777777778| Manhattan| Manhattan|\n",
       "|2018|    7| 19| 2018-07-21|     2018|         7|        29|       1|07/19/2018|       2.0|         4.82|           261|           107|  7.309722222222222| Manhattan| Manhattan|\n",
       "|2018|    8| 10| 2018-08-11|     2018|         8|        32|       1|08/10/2018|       2.0|         5.05|           107|            33| 0.2802777777777778| Manhattan|  Brooklyn|\n",
       "|2018|    8| 10| 2018-08-11|     2018|         8|        32|       1|08/10/2018|       2.0|         6.91|           144|           263|  7.510833333333333| Manhattan| Manhattan|\n",
       "+----+-----+---+-----------+---------+----------+----------+--------+----------+----------+-------------+--------------+--------------+-------------------+----------+----------+"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlc_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "165599082"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlc_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save the stacked df by month (this will take a while)\n",
    "tlc_df = tlc_df.sort('week_year', 'week_month')\n",
    "tlc_df.write\\\n",
    "    .partitionBy('week_year', 'week_month')\\\n",
    "    .mode('overwrite')\\\n",
    "    .parquet(f'{DATA_PATH}/curated/tlc/cleaned/yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cleaning the COVID dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/17 02:21:56 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>date_of_interest</th><th>CASE_COUNT</th><th>PROBABLE_CASE_COUNT</th><th>HOSPITALIZED_COUNT</th><th>DEATH_COUNT</th><th>PROBABLE_DEATH_COUNT</th><th>CASE_COUNT_7DAY_AVG</th><th>ALL_CASE_COUNT_7DAY_AVG</th><th>HOSP_COUNT_7DAY_AVG</th><th>DEATH_COUNT_7DAY_AVG</th><th>ALL_DEATH_COUNT_7DAY_AVG</th><th>BX_CASE_COUNT</th><th>BX_PROBABLE_CASE_COUNT</th><th>BX_HOSPITALIZED_COUNT</th><th>BX_DEATH_COUNT</th><th>BX_PROBABLE_DEATH_COUNT</th><th>BX_CASE_COUNT_7DAY_AVG</th><th>BX_PROBABLE_CASE_COUNT_7DAY_AVG</th><th>BX_ALL_CASE_COUNT_7DAY_AVG</th><th>BX_HOSPITALIZED_COUNT_7DAY_AVG</th><th>BX_DEATH_COUNT_7DAY_AVG</th><th>BX_ALL_DEATH_COUNT_7DAY_AVG</th><th>BK_CASE_COUNT</th><th>BK_PROBABLE_CASE_COUNT</th><th>BK_HOSPITALIZED_COUNT</th><th>BK_DEATH_COUNT</th><th>BK_PROBABLE_DEATH_COUNT</th><th>BK_CASE_COUNT_7DAY_AVG</th><th>BK_PROBABLE_CASE_COUNT_7DAY_AVG</th><th>BK_ALL_CASE_COUNT_7DAY_AVG</th><th>BK_HOSPITALIZED_COUNT_7DAY_AVG</th><th>BK_DEATH_COUNT_7DAY_AVG</th><th>BK_ALL_DEATH_COUNT_7DAY_AVG</th><th>MN_CASE_COUNT</th><th>MN_PROBABLE_CASE_COUNT</th><th>MN_HOSPITALIZED_COUNT</th><th>MN_DEATH_COUNT</th><th>MN_PROBABLE_DEATH_COUNT</th><th>MN_CASE_COUNT_7DAY_AVG</th><th>MN_PROBABLE_CASE_COUNT_7DAY_AVG</th><th>MN_ALL_CASE_COUNT_7DAY_AVG</th><th>MN_HOSPITALIZED_COUNT_7DAY_AVG</th><th>MN_DEATH_COUNT_7DAY_AVG</th><th>MN_ALL_DEATH_COUNT_7DAY_AVG</th><th>QN_CASE_COUNT</th><th>QN_PROBABLE_CASE_COUNT</th><th>QN_HOSPITALIZED_COUNT</th><th>QN_DEATH_COUNT</th><th>QN_PROBABLE_DEATH_COUNT</th><th>QN_CASE_COUNT_7DAY_AVG</th><th>QN_PROBABLE_CASE_COUNT_7DAY_AVG</th><th>QN_ALL_CASE_COUNT_7DAY_AVG</th><th>QN_HOSPITALIZED_COUNT_7DAY_AVG</th><th>QN_DEATH_COUNT_7DAY_AVG</th><th>QN_ALL_DEATH_COUNT_7DAY_AVG</th><th>SI_CASE_COUNT</th><th>SI_PROBABLE_CASE_COUNT</th><th>SI_HOSPITALIZED_COUNT</th><th>SI_DEATH_COUNT</th><th>SI_PROBABLE_DEATH_COUNT</th><th>SI_CASE_COUNT_7DAY_AVG</th><th>SI_PROBABLE_CASE_COUNT_7DAY_AVG</th><th>SI_ALL_CASE_COUNT_7DAY_AVG</th><th>SI_HOSPITALIZED_COUNT_7DAY_AVG</th><th>SI_DEATH_COUNT_7DAY_AVG</th><th>SI_ALL_DEATH_COUNT_7DAY_AVG</th><th>INCOMPLETE</th></tr>\n",
       "<tr><td>02/29/2020</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>03/01/2020</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>03/02/2020</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>03/03/2020</td><td>1</td><td>0</td><td>7</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>03/04/2020</td><td>5</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------------+----------+-------------------+------------------+-----------+--------------------+-------------------+-----------------------+-------------------+--------------------+------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+----------+\n",
       "|date_of_interest|CASE_COUNT|PROBABLE_CASE_COUNT|HOSPITALIZED_COUNT|DEATH_COUNT|PROBABLE_DEATH_COUNT|CASE_COUNT_7DAY_AVG|ALL_CASE_COUNT_7DAY_AVG|HOSP_COUNT_7DAY_AVG|DEATH_COUNT_7DAY_AVG|ALL_DEATH_COUNT_7DAY_AVG|BX_CASE_COUNT|BX_PROBABLE_CASE_COUNT|BX_HOSPITALIZED_COUNT|BX_DEATH_COUNT|BX_PROBABLE_DEATH_COUNT|BX_CASE_COUNT_7DAY_AVG|BX_PROBABLE_CASE_COUNT_7DAY_AVG|BX_ALL_CASE_COUNT_7DAY_AVG|BX_HOSPITALIZED_COUNT_7DAY_AVG|BX_DEATH_COUNT_7DAY_AVG|BX_ALL_DEATH_COUNT_7DAY_AVG|BK_CASE_COUNT|BK_PROBABLE_CASE_COUNT|BK_HOSPITALIZED_COUNT|BK_DEATH_COUNT|BK_PROBABLE_DEATH_COUNT|BK_CASE_COUNT_7DAY_AVG|BK_PROBABLE_CASE_COUNT_7DAY_AVG|BK_ALL_CASE_COUNT_7DAY_AVG|BK_HOSPITALIZED_COUNT_7DAY_AVG|BK_DEATH_COUNT_7DAY_AVG|BK_ALL_DEATH_COUNT_7DAY_AVG|MN_CASE_COUNT|MN_PROBABLE_CASE_COUNT|MN_HOSPITALIZED_COUNT|MN_DEATH_COUNT|MN_PROBABLE_DEATH_COUNT|MN_CASE_COUNT_7DAY_AVG|MN_PROBABLE_CASE_COUNT_7DAY_AVG|MN_ALL_CASE_COUNT_7DAY_AVG|MN_HOSPITALIZED_COUNT_7DAY_AVG|MN_DEATH_COUNT_7DAY_AVG|MN_ALL_DEATH_COUNT_7DAY_AVG|QN_CASE_COUNT|QN_PROBABLE_CASE_COUNT|QN_HOSPITALIZED_COUNT|QN_DEATH_COUNT|QN_PROBABLE_DEATH_COUNT|QN_CASE_COUNT_7DAY_AVG|QN_PROBABLE_CASE_COUNT_7DAY_AVG|QN_ALL_CASE_COUNT_7DAY_AVG|QN_HOSPITALIZED_COUNT_7DAY_AVG|QN_DEATH_COUNT_7DAY_AVG|QN_ALL_DEATH_COUNT_7DAY_AVG|SI_CASE_COUNT|SI_PROBABLE_CASE_COUNT|SI_HOSPITALIZED_COUNT|SI_DEATH_COUNT|SI_PROBABLE_DEATH_COUNT|SI_CASE_COUNT_7DAY_AVG|SI_PROBABLE_CASE_COUNT_7DAY_AVG|SI_ALL_CASE_COUNT_7DAY_AVG|SI_HOSPITALIZED_COUNT_7DAY_AVG|SI_DEATH_COUNT_7DAY_AVG|SI_ALL_DEATH_COUNT_7DAY_AVG|INCOMPLETE|\n",
       "+----------------+----------+-------------------+------------------+-----------+--------------------+-------------------+-----------------------+-------------------+--------------------+------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+----------+\n",
       "|      02/29/2020|         1|                  0|                 1|          0|                   0|                  0|                      0|                  0|                   0|                       0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    1|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            1|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|         0|\n",
       "|      03/01/2020|         0|                  0|                 1|          0|                   0|                  0|                      0|                  0|                   0|                       0|            0|                     0|                    1|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|         0|\n",
       "|      03/02/2020|         0|                  0|                 2|          0|                   0|                  0|                      0|                  0|                   0|                       0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    2|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|         0|\n",
       "|      03/03/2020|         1|                  0|                 7|          0|                   0|                  0|                      0|                  0|                   0|                       0|            0|                     0|                    1|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    3|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    1|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            1|                     0|                    2|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|         0|\n",
       "|      03/04/2020|         5|                  0|                 2|          0|                   0|                  0|                      0|                  0|                   0|                       0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            1|                     0|                    1|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            2|                     0|                    1|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            2|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|         0|\n",
       "+----------------+----------+-------------------+------------------+-----------+--------------------+-------------------+-----------------------+-------------------+--------------------+------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+----------+"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the covid dataset\n",
    "covid_df = spark.read.csv(f'{DATA_PATH}/raw/virals/covid/cases_by_day.csv',\n",
    "    header = True)\n",
    "covid_df.limit(5)\n",
    "# TODO: commenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(INCOMPLETE + 0)'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum the number of incomplete datasets (ensure no incomplete values)\n",
    "sum(covid_df.select('INCOMPLETE'))\n",
    "# TODO: commenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: commenting on covid cleaning\n",
    "COVID_KEEP_COLUMNS = {\n",
    "    'date_of_interest':'date'\n",
    "}\n",
    "\n",
    "COVID_CLEAN_COLUMNS = defaultdict(lambda: ch.non_negative)\n",
    "\n",
    "COVID_BOROUGHS = {\n",
    "    'BX_':'Bronx',\n",
    "    'BK_':'Brooklyn',\n",
    "    'MN_':'Manhattan',\n",
    "    'QN_':'Queens',\n",
    "    'SI_':'Staten Island',\n",
    "}\n",
    "\n",
    "COVID_COUNTS = {\n",
    "    'CASE_COUNT': 'cases', \n",
    "    'DEATH_COUNT': 'deaths', \n",
    "    'HOSPITALIZED_COUNT': 'hospitalised'\n",
    "}\n",
    "# TODO: commenting\n",
    "for prefix, new_prefix in COVID_BOROUGHS.items():\n",
    "    for suffix, new_suffix in COVID_COUNTS.items():\n",
    "        COVID_KEEP_COLUMNS[f'{prefix}{suffix}'] = f'{new_prefix}{new_suffix}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = ch.perform_cleaning(covid_df, mmwr_weeks_df, COVID_KEEP_COLUMNS, \n",
    "    COVID_CLEAN_COLUMNS)\n",
    "# TODO: commenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: commenting\n",
    "COVID_DATE_COLUMNS = [\n",
    "    F.col('date'), \n",
    "    F.col('week_ending'), \n",
    "    F.col('week_year'), \n",
    "    F.col('week_month'), \n",
    "    F.col('week_index'),\n",
    "    F.col('timeline')\n",
    "]\n",
    "\n",
    "# The data here is very wide, I'd rather just have a 'borough' column\n",
    "# for homogeneity of all the data\n",
    "temp_df = None\n",
    "for prefix in COVID_BOROUGHS.values():\n",
    "    borough_columns = []\n",
    "    for suffix in COVID_COUNTS.values():\n",
    "        borough_columns.append(F.col(f'{prefix}{suffix}').alias(suffix))\n",
    "\n",
    "    if temp_df == None:\n",
    "        temp_df = covid_df.select(COVID_DATE_COLUMNS + borough_columns)\\\n",
    "            .withColumn('borough', F.lit(prefix))\n",
    "    else:\n",
    "        temp_df = temp_df\\\n",
    "            .union(\n",
    "                covid_df.select(COVID_DATE_COLUMNS + borough_columns)\\\n",
    "                    .withColumn('borough', F.lit(prefix))\n",
    "            )\n",
    "    \n",
    "covid_df = temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>date</th><th>week_ending</th><th>week_year</th><th>week_month</th><th>week_index</th><th>timeline</th><th>cases</th><th>deaths</th><th>hospitalised</th><th>borough</th></tr>\n",
       "<tr><td>02/29/2020</td><td>2020-02-29</td><td>2020</td><td>2</td><td>113</td><td>1</td><td>0</td><td>0</td><td>1</td><td>Brooklyn</td></tr>\n",
       "<tr><td>02/29/2020</td><td>2020-02-29</td><td>2020</td><td>2</td><td>113</td><td>1</td><td>1</td><td>0</td><td>0</td><td>Manhattan</td></tr>\n",
       "<tr><td>02/29/2020</td><td>2020-02-29</td><td>2020</td><td>2</td><td>113</td><td>1</td><td>0</td><td>0</td><td>0</td><td>Bronx</td></tr>\n",
       "<tr><td>02/29/2020</td><td>2020-02-29</td><td>2020</td><td>2</td><td>113</td><td>1</td><td>0</td><td>0</td><td>0</td><td>Queens</td></tr>\n",
       "<tr><td>02/29/2020</td><td>2020-02-29</td><td>2020</td><td>2</td><td>113</td><td>1</td><td>0</td><td>0</td><td>0</td><td>Staten Island</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+-----------+---------+----------+----------+--------+-----+------+------------+-------------+\n",
       "|      date|week_ending|week_year|week_month|week_index|timeline|cases|deaths|hospitalised|      borough|\n",
       "+----------+-----------+---------+----------+----------+--------+-----+------+------------+-------------+\n",
       "|02/29/2020| 2020-02-29|     2020|         2|       113|       1|    0|     0|           1|     Brooklyn|\n",
       "|02/29/2020| 2020-02-29|     2020|         2|       113|       1|    1|     0|           0|    Manhattan|\n",
       "|02/29/2020| 2020-02-29|     2020|         2|       113|       1|    0|     0|           0|        Bronx|\n",
       "|02/29/2020| 2020-02-29|     2020|         2|       113|       1|    0|     0|           0|       Queens|\n",
       "|02/29/2020| 2020-02-29|     2020|         2|       113|       1|    0|     0|           0|Staten Island|\n",
       "+----------+-----------+---------+----------+----------+--------+-----+------+------------+-------------+"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df.sort('week_index', 'date').limit(5)\n",
    "# TODO: commenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out any thing not in Timeline 1 (and 2)\n",
    "covid_df = covid_df.where(F.col('timeline') > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned covid data\n",
    "# TODO: commenting\n",
    "covid_df.write.mode('overwrite').parquet(f'{DATA_PATH}/curated/virals/covid/cleaned/cases_by_day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cleaning the flu dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Season</th><th>Region</th><th>County</th><th>CDC Week</th><th>Week Ending Date</th><th>Disease</th><th>Count</th><th>County Centroid</th><th>FIPS</th></tr>\n",
       "<tr><td>2012-2013</td><td>NYC</td><td>RICHMOND</td><td>10</td><td>03/09/2013</td><td>INFLUENZA_A</td><td>0</td><td>(40.5795, -74.1502)</td><td>36085</td></tr>\n",
       "<tr><td>2011-2012</td><td>CAPITAL DISTRICT</td><td>ALBANY</td><td>10</td><td>03/10/2012</td><td>INFLUENZA_UNSPECI...</td><td>0</td><td>(42.5882713, -73....</td><td>36001</td></tr>\n",
       "<tr><td>2009-2010</td><td>CAPITAL DISTRICT</td><td>SCHENECTADY</td><td>41</td><td>10/17/2009</td><td>INFLUENZA_UNSPECI...</td><td>0</td><td>(42.8175421, -74....</td><td>36093</td></tr>\n",
       "<tr><td>2010-2011</td><td>WESTERN</td><td>CHAUTAUQUA</td><td>19</td><td>05/14/2011</td><td>INFLUENZA_B</td><td>0</td><td>(42.3042159, -79....</td><td>36013</td></tr>\n",
       "<tr><td>2013-2014</td><td>METRO</td><td>DUTCHESS</td><td>44</td><td>11/02/2013</td><td>INFLUENZA_A</td><td>0</td><td>(41.7550085, -73....</td><td>36027</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+----------------+-----------+--------+----------------+--------------------+-----+--------------------+-----+\n",
       "|   Season|          Region|     County|CDC Week|Week Ending Date|             Disease|Count|     County Centroid| FIPS|\n",
       "+---------+----------------+-----------+--------+----------------+--------------------+-----+--------------------+-----+\n",
       "|2012-2013|             NYC|   RICHMOND|      10|      03/09/2013|         INFLUENZA_A|    0| (40.5795, -74.1502)|36085|\n",
       "|2011-2012|CAPITAL DISTRICT|     ALBANY|      10|      03/10/2012|INFLUENZA_UNSPECI...|    0|(42.5882713, -73....|36001|\n",
       "|2009-2010|CAPITAL DISTRICT|SCHENECTADY|      41|      10/17/2009|INFLUENZA_UNSPECI...|    0|(42.8175421, -74....|36093|\n",
       "|2010-2011|         WESTERN| CHAUTAUQUA|      19|      05/14/2011|         INFLUENZA_B|    0|(42.3042159, -79....|36013|\n",
       "|2013-2014|           METRO|   DUTCHESS|      44|      11/02/2013|         INFLUENZA_A|    0|(41.7550085, -73....|36027|\n",
       "+---------+----------------+-----------+--------+----------------+--------------------+-----+--------------------+-----+"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the flu dataset\n",
    "# TODO: commenting\n",
    "flu_df = spark.read.csv(f'{DATA_PATH}/raw/virals/flu/cases_by_week.csv',\n",
    "    header=True)\n",
    "flu_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLU_KEEP_COLUMNS = {\n",
    "    'Week Ending Date': 'date',\n",
    "    'Region': 'region',\n",
    "    'County': 'borough',\n",
    "    'Disease': 'disease',\n",
    "    'Count': 'cases',\n",
    "}\n",
    "# TODO: commenting\n",
    "FLU_CLEAN_COLUMNS = {\n",
    "    'date': [],\n",
    "    'region': [lambda _: F.col('region') == 'NYC'],\n",
    "    'borough': [],\n",
    "    'disease': [],\n",
    "    'cases': [ch.non_negative]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: commenting\n",
    "flu_df:DataFrame = ch.perform_cleaning(flu_df, mmwr_weeks_df, FLU_KEEP_COLUMNS, \n",
    "    FLU_CLEAN_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>borough</th></tr>\n",
       "<tr><td>KINGS</td></tr>\n",
       "<tr><td>QUEENS</td></tr>\n",
       "<tr><td>BRONX</td></tr>\n",
       "<tr><td>RICHMOND</td></tr>\n",
       "<tr><td>NEW YORK</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+\n",
       "| borough|\n",
       "+--------+\n",
       "|   KINGS|\n",
       "|  QUEENS|\n",
       "|   BRONX|\n",
       "|RICHMOND|\n",
       "|NEW YORK|\n",
       "+--------+"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the list of distinct counties (column now called 'borough')\n",
    "flu_df.select('borough').distinct().limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the boroughs to their proper names\n",
    "# from: https://portal.311.nyc.gov/article/?kanumber=KA-02877\n",
    "# also from map dict\n",
    "FLU_COUNTY_TO_BOROUGH = {\n",
    "    'BRONX': 'Bronx',\n",
    "    'KINGS': 'Brooklyn',\n",
    "    'NEW YORK': 'Manhattan',\n",
    "    'QUEENS': 'Queens',\n",
    "    'RICHMOND': 'Staten Island'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the mapping to the flu df\n",
    "flu_df = ch.replace_column_using_dict(flu_df, 'borough', FLU_COUNTY_TO_BOROUGH)\n",
    "\n",
    "# also remove the regions column (not needed anymore)\n",
    "columns_without_regions = flu_df.columns[:]\n",
    "columns_without_regions.remove('region')\n",
    "flu_df = flu_df.select(columns_without_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>month</th><th>day</th><th>week_ending</th><th>week_year</th><th>week_month</th><th>week_index</th><th>timeline</th><th>date</th><th>borough</th><th>disease</th><th>cases</th></tr>\n",
       "<tr><td>2018</td><td>4</td><td>7</td><td>2018-04-07</td><td>2018</td><td>4</td><td>14</td><td>0</td><td>04/07/2018</td><td>Staten Island</td><td>INFLUENZA_B</td><td>34</td></tr>\n",
       "<tr><td>2018</td><td>4</td><td>21</td><td>2018-04-21</td><td>2018</td><td>4</td><td>16</td><td>0</td><td>04/21/2018</td><td>Brooklyn</td><td>INFLUENZA_UNSPECI...</td><td>0</td></tr>\n",
       "<tr><td>2018</td><td>4</td><td>14</td><td>2018-04-14</td><td>2018</td><td>4</td><td>15</td><td>0</td><td>04/14/2018</td><td>Bronx</td><td>INFLUENZA_A</td><td>31</td></tr>\n",
       "<tr><td>2018</td><td>5</td><td>12</td><td>2018-05-12</td><td>2018</td><td>5</td><td>19</td><td>0</td><td>05/12/2018</td><td>Queens</td><td>INFLUENZA_B</td><td>24</td></tr>\n",
       "<tr><td>2018</td><td>1</td><td>6</td><td>2018-01-06</td><td>2018</td><td>1</td><td>1</td><td>0</td><td>01/06/2018</td><td>Manhattan</td><td>INFLUENZA_A</td><td>117</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-----+---+-----------+---------+----------+----------+--------+----------+-------------+--------------------+-----+\n",
       "|year|month|day|week_ending|week_year|week_month|week_index|timeline|      date|      borough|             disease|cases|\n",
       "+----+-----+---+-----------+---------+----------+----------+--------+----------+-------------+--------------------+-----+\n",
       "|2018|    4|  7| 2018-04-07|     2018|         4|        14|       0|04/07/2018|Staten Island|         INFLUENZA_B|   34|\n",
       "|2018|    4| 21| 2018-04-21|     2018|         4|        16|       0|04/21/2018|     Brooklyn|INFLUENZA_UNSPECI...|    0|\n",
       "|2018|    4| 14| 2018-04-14|     2018|         4|        15|       0|04/14/2018|        Bronx|         INFLUENZA_A|   31|\n",
       "|2018|    5| 12| 2018-05-12|     2018|         5|        19|       0|05/12/2018|       Queens|         INFLUENZA_B|   24|\n",
       "|2018|    1|  6| 2018-01-06|     2018|         1|         1|       0|01/06/2018|    Manhattan|         INFLUENZA_A|  117|\n",
       "+----+-----+---+-----------+---------+----------+----------+--------+----------+-------------+--------------------+-----+"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flu_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out any thing not in Timeline 1 (and 2)\n",
    "flu_df = flu_df.where(F.col('timeline') > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned flu data\n",
    "flu_df.write.mode('overwrite').parquet(f'{DATA_PATH}/curated/virals/flu/cleaned/cases_by_week')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
