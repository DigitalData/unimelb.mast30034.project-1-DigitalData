{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAST30034: Applied Data Science Project 1\n",
    "---\n",
    "# Preprocessing Part 1: Cleaning The Data\n",
    "#### Xavier Travers (1178369)\n",
    "\n",
    "Cleaning the datasets of null, inconsistent, or unnecessary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports used throughout this notebook\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "\n",
    "# add homemade helpers\n",
    "sys.path.insert(1, '../../scripts')\n",
    "import helpers.cleaning_helpers as ch\n",
    "import helpers.join_helpers as jh\n",
    "\n",
    "# path where the data files are stored\n",
    "DATA_PATH = '../../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/21 08:24:34 WARN Utils: Your hostname, Polaris resolves to a loopback address: 127.0.1.1; using 172.18.201.145 instead (on interface eth0)\n",
      "22/08/21 08:24:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/21 08:24:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/08/21 08:24:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName('MAST30034 XT Project 1')\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config('spark.sql.repl.eagerEval.enabled', True) \n",
    "    .config('spark.sql.parquet.cacheMetadata', 'true')\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>month</th><th>day</th><th>month_mmwr_index</th><th>week_index</th><th>us_format</th><th>week_ending</th><th>week_month</th><th>week_year</th><th>borough</th><th>__index_level_0__</th></tr>\n",
       "<tr><td>2019</td><td>12</td><td>29</td><td>1</td><td>1</td><td>12/29/2019</td><td>2020-01-04</td><td>1</td><td>2020</td><td>Bronx</td><td>0</td></tr>\n",
       "<tr><td>2019</td><td>12</td><td>30</td><td>1</td><td>1</td><td>12/30/2019</td><td>2020-01-04</td><td>1</td><td>2020</td><td>Bronx</td><td>1</td></tr>\n",
       "<tr><td>2019</td><td>12</td><td>31</td><td>1</td><td>1</td><td>12/31/2019</td><td>2020-01-04</td><td>1</td><td>2020</td><td>Bronx</td><td>2</td></tr>\n",
       "<tr><td>2020</td><td>1</td><td>1</td><td>1</td><td>1</td><td>01/01/2020</td><td>2020-01-04</td><td>1</td><td>2020</td><td>Bronx</td><td>3</td></tr>\n",
       "<tr><td>2020</td><td>1</td><td>2</td><td>1</td><td>1</td><td>01/02/2020</td><td>2020-01-04</td><td>1</td><td>2020</td><td>Bronx</td><td>4</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-----+---+----------------+----------+----------+-----------+----------+---------+-------+-----------------+\n",
       "|year|month|day|month_mmwr_index|week_index| us_format|week_ending|week_month|week_year|borough|__index_level_0__|\n",
       "+----+-----+---+----------------+----------+----------+-----------+----------+---------+-------+-----------------+\n",
       "|2019|   12| 29|               1|         1|12/29/2019| 2020-01-04|         1|     2020|  Bronx|                0|\n",
       "|2019|   12| 30|               1|         1|12/30/2019| 2020-01-04|         1|     2020|  Bronx|                1|\n",
       "|2019|   12| 31|               1|         1|12/31/2019| 2020-01-04|         1|     2020|  Bronx|                2|\n",
       "|2020|    1|  1|               1|         1|01/01/2020| 2020-01-04|         1|     2020|  Bronx|                3|\n",
       "|2020|    1|  2|               1|         1|01/02/2020| 2020-01-04|         1|     2020|  Bronx|                4|\n",
       "+----+-----+---+----------------+----------+----------+-----------+----------+---------+-------+-----------------+"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the cdc week file to convert all dates to cdc weeks now\n",
    "mmwr_weeks_df = spark.read.parquet(f'{DATA_PATH}/raw/virals/mmwr_weeks.parquet')\n",
    "mmwr_weeks_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>LocationID</th><th>Borough</th><th>Zone</th><th>service_zone</th></tr>\n",
       "<tr><td>1</td><td>EWR</td><td>Newark Airport</td><td>EWR</td></tr>\n",
       "<tr><td>2</td><td>Queens</td><td>Jamaica Bay</td><td>Boro Zone</td></tr>\n",
       "<tr><td>3</td><td>Bronx</td><td>Allerton/Pelham G...</td><td>Boro Zone</td></tr>\n",
       "<tr><td>4</td><td>Manhattan</td><td>Alphabet City</td><td>Yellow Zone</td></tr>\n",
       "<tr><td>5</td><td>Staten Island</td><td>Arden Heights</td><td>Boro Zone</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+-------------+--------------------+------------+\n",
       "|LocationID|      Borough|                Zone|service_zone|\n",
       "+----------+-------------+--------------------+------------+\n",
       "|         1|          EWR|      Newark Airport|         EWR|\n",
       "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
       "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
       "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
       "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
       "+----------+-------------+--------------------+------------+"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the zones dataset\n",
    "zones_df = spark.read.csv(f'{DATA_PATH}/raw/tlc_zones/zones.csv',\n",
    "    header = True)\n",
    "zones_df.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Join population statistics with zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New York</th>\n",
       "      <th>.Albany County, New York</th>\n",
       "      <th>.Allegany County, New York</th>\n",
       "      <th>.Bronx County, New York</th>\n",
       "      <th>.Broome County, New York</th>\n",
       "      <th>.Cattaraugus County, New York</th>\n",
       "      <th>.Cayuga County, New York</th>\n",
       "      <th>.Chautauqua County, New York</th>\n",
       "      <th>.Chemung County, New York</th>\n",
       "      <th>.Chenango County, New York</th>\n",
       "      <th>...</th>\n",
       "      <th>.Washington County, New York</th>\n",
       "      <th>.Wayne County, New York</th>\n",
       "      <th>.Westchester County, New York</th>\n",
       "      <th>.Wyoming County, New York</th>\n",
       "      <th>.Yates County, New York</th>\n",
       "      <th>Note: The estimates are based on the 2010 Census and reflect changes to the April 1, 2010 population due to the Count Question Resolution program and geographic program revisions. All geographic boundaries for the 2019 population estimates are as of January 1, 2019. For population estimates methodology statements, see http://www.census.gov/programs-surveys/popest/technical-documentation/methodology.html.</th>\n",
       "      <th>Suggested Citation:</th>\n",
       "      <th>Annual Estimates of the Resident Population for Counties in New York: April 1, 2010 to July 1, 2019 (CO-EST2019-ANNRES-36)</th>\n",
       "      <th>Source: U.S. Census Bureau, Population Division</th>\n",
       "      <th>Release Date: March 2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Census</th>\n",
       "      <td>19378102.0</td>\n",
       "      <td>304204.0</td>\n",
       "      <td>48946.0</td>\n",
       "      <td>1385108.0</td>\n",
       "      <td>200600.0</td>\n",
       "      <td>80317.0</td>\n",
       "      <td>80026.0</td>\n",
       "      <td>134905.0</td>\n",
       "      <td>88830.0</td>\n",
       "      <td>50477.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63216.0</td>\n",
       "      <td>93772.0</td>\n",
       "      <td>949113.0</td>\n",
       "      <td>42155.0</td>\n",
       "      <td>25348.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimates Base</th>\n",
       "      <td>19378144.0</td>\n",
       "      <td>304208.0</td>\n",
       "      <td>48923.0</td>\n",
       "      <td>1384580.0</td>\n",
       "      <td>200675.0</td>\n",
       "      <td>80337.0</td>\n",
       "      <td>80008.0</td>\n",
       "      <td>134907.0</td>\n",
       "      <td>88847.0</td>\n",
       "      <td>50511.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63254.0</td>\n",
       "      <td>93751.0</td>\n",
       "      <td>949218.0</td>\n",
       "      <td>42154.0</td>\n",
       "      <td>25364.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>19399878.0</td>\n",
       "      <td>304086.0</td>\n",
       "      <td>48971.0</td>\n",
       "      <td>1387298.0</td>\n",
       "      <td>200481.0</td>\n",
       "      <td>80218.0</td>\n",
       "      <td>79895.0</td>\n",
       "      <td>134725.0</td>\n",
       "      <td>88895.0</td>\n",
       "      <td>50399.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63356.0</td>\n",
       "      <td>93751.0</td>\n",
       "      <td>950601.0</td>\n",
       "      <td>42126.0</td>\n",
       "      <td>25376.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>19499241.0</td>\n",
       "      <td>304596.0</td>\n",
       "      <td>48800.0</td>\n",
       "      <td>1397335.0</td>\n",
       "      <td>199363.0</td>\n",
       "      <td>79815.0</td>\n",
       "      <td>79693.0</td>\n",
       "      <td>134209.0</td>\n",
       "      <td>88899.0</td>\n",
       "      <td>50182.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63091.0</td>\n",
       "      <td>93256.0</td>\n",
       "      <td>956262.0</td>\n",
       "      <td>41849.0</td>\n",
       "      <td>25454.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>19572932.0</td>\n",
       "      <td>305723.0</td>\n",
       "      <td>48210.0</td>\n",
       "      <td>1411496.0</td>\n",
       "      <td>198667.0</td>\n",
       "      <td>79348.0</td>\n",
       "      <td>79505.0</td>\n",
       "      <td>133304.0</td>\n",
       "      <td>89137.0</td>\n",
       "      <td>49883.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63003.0</td>\n",
       "      <td>93029.0</td>\n",
       "      <td>959585.0</td>\n",
       "      <td>41700.0</td>\n",
       "      <td>25337.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  New York  .Albany County, New York  \\\n",
       "Census          19378102.0                  304204.0   \n",
       "Estimates Base  19378144.0                  304208.0   \n",
       "2010            19399878.0                  304086.0   \n",
       "2011            19499241.0                  304596.0   \n",
       "2012            19572932.0                  305723.0   \n",
       "\n",
       "                .Allegany County, New York  .Bronx County, New York  \\\n",
       "Census                             48946.0                1385108.0   \n",
       "Estimates Base                     48923.0                1384580.0   \n",
       "2010                               48971.0                1387298.0   \n",
       "2011                               48800.0                1397335.0   \n",
       "2012                               48210.0                1411496.0   \n",
       "\n",
       "                .Broome County, New York  .Cattaraugus County, New York  \\\n",
       "Census                          200600.0                        80317.0   \n",
       "Estimates Base                  200675.0                        80337.0   \n",
       "2010                            200481.0                        80218.0   \n",
       "2011                            199363.0                        79815.0   \n",
       "2012                            198667.0                        79348.0   \n",
       "\n",
       "                .Cayuga County, New York  .Chautauqua County, New York  \\\n",
       "Census                           80026.0                      134905.0   \n",
       "Estimates Base                   80008.0                      134907.0   \n",
       "2010                             79895.0                      134725.0   \n",
       "2011                             79693.0                      134209.0   \n",
       "2012                             79505.0                      133304.0   \n",
       "\n",
       "                .Chemung County, New York  .Chenango County, New York  ...  \\\n",
       "Census                            88830.0                     50477.0  ...   \n",
       "Estimates Base                    88847.0                     50511.0  ...   \n",
       "2010                              88895.0                     50399.0  ...   \n",
       "2011                              88899.0                     50182.0  ...   \n",
       "2012                              89137.0                     49883.0  ...   \n",
       "\n",
       "                .Washington County, New York  .Wayne County, New York  \\\n",
       "Census                               63216.0                  93772.0   \n",
       "Estimates Base                       63254.0                  93751.0   \n",
       "2010                                 63356.0                  93751.0   \n",
       "2011                                 63091.0                  93256.0   \n",
       "2012                                 63003.0                  93029.0   \n",
       "\n",
       "                .Westchester County, New York  .Wyoming County, New York  \\\n",
       "Census                               949113.0                    42155.0   \n",
       "Estimates Base                       949218.0                    42154.0   \n",
       "2010                                 950601.0                    42126.0   \n",
       "2011                                 956262.0                    41849.0   \n",
       "2012                                 959585.0                    41700.0   \n",
       "\n",
       "                .Yates County, New York  \\\n",
       "Census                          25348.0   \n",
       "Estimates Base                  25364.0   \n",
       "2010                            25376.0   \n",
       "2011                            25454.0   \n",
       "2012                            25337.0   \n",
       "\n",
       "                Note: The estimates are based on the 2010 Census and reflect changes to the April 1, 2010 population due to the Count Question Resolution program and geographic program revisions. All geographic boundaries for the 2019 population estimates are as of January 1, 2019. For population estimates methodology statements, see http://www.census.gov/programs-surveys/popest/technical-documentation/methodology.html.  \\\n",
       "Census                                                        NaN                                                                                                                                                                                                                                                                                                                                                                         \n",
       "Estimates Base                                                NaN                                                                                                                                                                                                                                                                                                                                                                         \n",
       "2010                                                          NaN                                                                                                                                                                                                                                                                                                                                                                         \n",
       "2011                                                          NaN                                                                                                                                                                                                                                                                                                                                                                         \n",
       "2012                                                          NaN                                                                                                                                                                                                                                                                                                                                                                         \n",
       "\n",
       "                Suggested Citation:  \\\n",
       "Census                          NaN   \n",
       "Estimates Base                  NaN   \n",
       "2010                            NaN   \n",
       "2011                            NaN   \n",
       "2012                            NaN   \n",
       "\n",
       "                Annual Estimates of the Resident Population for Counties in New York: April 1, 2010 to July 1, 2019 (CO-EST2019-ANNRES-36)  \\\n",
       "Census                                                        NaN                                                                            \n",
       "Estimates Base                                                NaN                                                                            \n",
       "2010                                                          NaN                                                                            \n",
       "2011                                                          NaN                                                                            \n",
       "2012                                                          NaN                                                                            \n",
       "\n",
       "                Source: U.S. Census Bureau, Population Division  \\\n",
       "Census                                                      NaN   \n",
       "Estimates Base                                              NaN   \n",
       "2010                                                        NaN   \n",
       "2011                                                        NaN   \n",
       "2012                                                        NaN   \n",
       "\n",
       "                Release Date: March 2020  \n",
       "Census                               NaN  \n",
       "Estimates Base                       NaN  \n",
       "2010                                 NaN  \n",
       "2011                                 NaN  \n",
       "2012                                 NaN  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the populations data\n",
    "pop_df_2010_2019 = pd.read_excel(f'{DATA_PATH}/raw/populations/2010_2019.xlsx',\n",
    "    header = [3], index_col=0).transpose()\n",
    "\n",
    "pop_df_2010_2019.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Census</th>\n",
       "      <td>1385108.0</td>\n",
       "      <td>2504700.0</td>\n",
       "      <td>1585873.0</td>\n",
       "      <td>2230722.0</td>\n",
       "      <td>468730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimates Base</th>\n",
       "      <td>1384580.0</td>\n",
       "      <td>2504721.0</td>\n",
       "      <td>1586381.0</td>\n",
       "      <td>2230619.0</td>\n",
       "      <td>468730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>1387298.0</td>\n",
       "      <td>2509828.0</td>\n",
       "      <td>1588767.0</td>\n",
       "      <td>2234701.0</td>\n",
       "      <td>469615.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>1397335.0</td>\n",
       "      <td>2540817.0</td>\n",
       "      <td>1608293.0</td>\n",
       "      <td>2255482.0</td>\n",
       "      <td>471021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>1411496.0</td>\n",
       "      <td>2568450.0</td>\n",
       "      <td>1623911.0</td>\n",
       "      <td>2272222.0</td>\n",
       "      <td>470614.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Bronx   Brooklyn  Manhattan     Queens  Staten Island\n",
       "Census          1385108.0  2504700.0  1585873.0  2230722.0       468730.0\n",
       "Estimates Base  1384580.0  2504721.0  1586381.0  2230619.0       468730.0\n",
       "2010            1387298.0  2509828.0  1588767.0  2234701.0       469615.0\n",
       "2011            1397335.0  2540817.0  1608293.0  2255482.0       471021.0\n",
       "2012            1411496.0  2568450.0  1623911.0  2272222.0       470614.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the new york city boroughs\n",
    "pop_df_2010_2019 = pop_df_2010_2019[[\n",
    "    '.Bronx County, New York',\n",
    "    '.Kings County, New York',\n",
    "    '.New York County, New York',\n",
    "    '.Queens County, New York',\n",
    "    '.Richmond County, New York']]\n",
    "\n",
    "# rename the columns to their corresponding boroughs\n",
    "pop_df_2010_2019.columns = [\n",
    "    'Bronx',\n",
    "    'Brooklyn',\n",
    "    'Manhattan',\n",
    "    'Queens',\n",
    "    'Staten Island'\n",
    "]\n",
    "pop_df_2010_2019.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New York</th>\n",
       "      <th>.Albany County, New York</th>\n",
       "      <th>.Allegany County, New York</th>\n",
       "      <th>.Bronx County, New York</th>\n",
       "      <th>.Broome County, New York</th>\n",
       "      <th>.Cattaraugus County, New York</th>\n",
       "      <th>.Cayuga County, New York</th>\n",
       "      <th>.Chautauqua County, New York</th>\n",
       "      <th>.Chemung County, New York</th>\n",
       "      <th>.Chenango County, New York</th>\n",
       "      <th>...</th>\n",
       "      <th>.Washington County, New York</th>\n",
       "      <th>.Wayne County, New York</th>\n",
       "      <th>.Westchester County, New York</th>\n",
       "      <th>.Wyoming County, New York</th>\n",
       "      <th>.Yates County, New York</th>\n",
       "      <th>Note: The estimates are developed from a base that incorporates the 2020 Census, Vintage 2020 estimates, and 2020 Demographic Analysis estimates.  For population estimates methodology statements, see http://www.census.gov/programs-surveys/popest/technical-documentation/methodology.html. The estimates feature geographic boundaries from the Vintage 2020 estimates series; the geographic boundaries for these 2021 population estimates are as of January 1, 2020.</th>\n",
       "      <th>Suggested Citation:</th>\n",
       "      <th>Annual Estimates of the Resident Population for Counties in New York: April 1, 2020 to July 1, 2021\\n(CO-EST2021-POP-36)</th>\n",
       "      <th>Source: U.S. Census Bureau, Population Division</th>\n",
       "      <th>Release Date: March 2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <td>20201249.0</td>\n",
       "      <td>314848.0</td>\n",
       "      <td>46456.0</td>\n",
       "      <td>1472654.0</td>\n",
       "      <td>198683.0</td>\n",
       "      <td>77042.0</td>\n",
       "      <td>76248.0</td>\n",
       "      <td>127657.0</td>\n",
       "      <td>84148.0</td>\n",
       "      <td>47220.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61302.0</td>\n",
       "      <td>91283.0</td>\n",
       "      <td>1004457.0</td>\n",
       "      <td>40531.0</td>\n",
       "      <td>24774.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>20154933.0</td>\n",
       "      <td>314368.0</td>\n",
       "      <td>46373.0</td>\n",
       "      <td>1466438.0</td>\n",
       "      <td>198199.0</td>\n",
       "      <td>76907.0</td>\n",
       "      <td>76095.0</td>\n",
       "      <td>127424.0</td>\n",
       "      <td>83882.0</td>\n",
       "      <td>47073.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61143.0</td>\n",
       "      <td>91103.0</td>\n",
       "      <td>1003245.0</td>\n",
       "      <td>40401.0</td>\n",
       "      <td>24709.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>19835913.0</td>\n",
       "      <td>313743.0</td>\n",
       "      <td>46106.0</td>\n",
       "      <td>1424948.0</td>\n",
       "      <td>197240.0</td>\n",
       "      <td>76426.0</td>\n",
       "      <td>75880.0</td>\n",
       "      <td>126807.0</td>\n",
       "      <td>83045.0</td>\n",
       "      <td>46537.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60956.0</td>\n",
       "      <td>90923.0</td>\n",
       "      <td>997895.0</td>\n",
       "      <td>40491.0</td>\n",
       "      <td>24613.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              New York  .Albany County, New York  .Allegany County, New York  \\\n",
       "Unnamed: 1  20201249.0                  314848.0                     46456.0   \n",
       "2020        20154933.0                  314368.0                     46373.0   \n",
       "2021        19835913.0                  313743.0                     46106.0   \n",
       "\n",
       "            .Bronx County, New York  .Broome County, New York  \\\n",
       "Unnamed: 1                1472654.0                  198683.0   \n",
       "2020                      1466438.0                  198199.0   \n",
       "2021                      1424948.0                  197240.0   \n",
       "\n",
       "            .Cattaraugus County, New York  .Cayuga County, New York  \\\n",
       "Unnamed: 1                        77042.0                   76248.0   \n",
       "2020                              76907.0                   76095.0   \n",
       "2021                              76426.0                   75880.0   \n",
       "\n",
       "            .Chautauqua County, New York  .Chemung County, New York  \\\n",
       "Unnamed: 1                      127657.0                    84148.0   \n",
       "2020                            127424.0                    83882.0   \n",
       "2021                            126807.0                    83045.0   \n",
       "\n",
       "            .Chenango County, New York  ...  .Washington County, New York  \\\n",
       "Unnamed: 1                     47220.0  ...                       61302.0   \n",
       "2020                           47073.0  ...                       61143.0   \n",
       "2021                           46537.0  ...                       60956.0   \n",
       "\n",
       "            .Wayne County, New York  .Westchester County, New York  \\\n",
       "Unnamed: 1                  91283.0                      1004457.0   \n",
       "2020                        91103.0                      1003245.0   \n",
       "2021                        90923.0                       997895.0   \n",
       "\n",
       "            .Wyoming County, New York  .Yates County, New York  \\\n",
       "Unnamed: 1                    40531.0                  24774.0   \n",
       "2020                          40401.0                  24709.0   \n",
       "2021                          40491.0                  24613.0   \n",
       "\n",
       "            Note: The estimates are developed from a base that incorporates the 2020 Census, Vintage 2020 estimates, and 2020 Demographic Analysis estimates.  For population estimates methodology statements, see http://www.census.gov/programs-surveys/popest/technical-documentation/methodology.html. The estimates feature geographic boundaries from the Vintage 2020 estimates series; the geographic boundaries for these 2021 population estimates are as of January 1, 2020.   \\\n",
       "Unnamed: 1                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "2020                                                      NaN                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "2021                                                      NaN                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "\n",
       "            Suggested Citation:  \\\n",
       "Unnamed: 1                  NaN   \n",
       "2020                        NaN   \n",
       "2021                        NaN   \n",
       "\n",
       "            Annual Estimates of the Resident Population for Counties in New York: April 1, 2020 to July 1, 2021\\n(CO-EST2021-POP-36)  \\\n",
       "Unnamed: 1                                                NaN                                                                          \n",
       "2020                                                      NaN                                                                          \n",
       "2021                                                      NaN                                                                          \n",
       "\n",
       "            Source: U.S. Census Bureau, Population Division  \\\n",
       "Unnamed: 1                                              NaN   \n",
       "2020                                                    NaN   \n",
       "2021                                                    NaN   \n",
       "\n",
       "            Release Date: March 2022  \n",
       "Unnamed: 1                       NaN  \n",
       "2020                             NaN  \n",
       "2021                             NaN  \n",
       "\n",
       "[3 rows x 68 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the populations data\n",
    "pop_df_2020_2021 = pd.read_excel(f'{DATA_PATH}/raw/populations/2020_2021.xlsx',\n",
    "    header = [3], index_col=0).transpose()\n",
    "\n",
    "pop_df_2020_2021.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <td>1472654.0</td>\n",
       "      <td>2736074.0</td>\n",
       "      <td>1694251.0</td>\n",
       "      <td>2405464.0</td>\n",
       "      <td>495747.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>1466438.0</td>\n",
       "      <td>2727393.0</td>\n",
       "      <td>1687834.0</td>\n",
       "      <td>2395791.0</td>\n",
       "      <td>495522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>1424948.0</td>\n",
       "      <td>2641052.0</td>\n",
       "      <td>1576876.0</td>\n",
       "      <td>2331143.0</td>\n",
       "      <td>493494.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Bronx   Brooklyn  Manhattan     Queens  Staten Island\n",
       "Unnamed: 1  1472654.0  2736074.0  1694251.0  2405464.0       495747.0\n",
       "2020        1466438.0  2727393.0  1687834.0  2395791.0       495522.0\n",
       "2021        1424948.0  2641052.0  1576876.0  2331143.0       493494.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the new york city boroughs\n",
    "pop_df_2020_2021 = pop_df_2020_2021[[\n",
    "    '.Bronx County, New York',\n",
    "    '.Kings County, New York',\n",
    "    '.New York County, New York',\n",
    "    '.Queens County, New York',\n",
    "    '.Richmond County, New York']]\n",
    "\n",
    "# rename the columns to their corresponding boroughs\n",
    "pop_df_2020_2021.columns = [\n",
    "    'Bronx',\n",
    "    'Brooklyn',\n",
    "    'Manhattan',\n",
    "    'Queens',\n",
    "    'Staten Island'\n",
    "]\n",
    "pop_df_2020_2021.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1432087.0</td>\n",
       "      <td>2578074.0</td>\n",
       "      <td>1629055.0</td>\n",
       "      <td>2274605.0</td>\n",
       "      <td>476260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>1418207.0</td>\n",
       "      <td>2559903.0</td>\n",
       "      <td>1628706.0</td>\n",
       "      <td>2253858.0</td>\n",
       "      <td>476143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>1466438.0</td>\n",
       "      <td>2727393.0</td>\n",
       "      <td>1687834.0</td>\n",
       "      <td>2395791.0</td>\n",
       "      <td>495522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>1424948.0</td>\n",
       "      <td>2641052.0</td>\n",
       "      <td>1576876.0</td>\n",
       "      <td>2331143.0</td>\n",
       "      <td>493494.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Bronx   Brooklyn  Manhattan     Queens  Staten Island\n",
       "2018  1432087.0  2578074.0  1629055.0  2274605.0       476260.0\n",
       "2019  1418207.0  2559903.0  1628706.0  2253858.0       476143.0\n",
       "2020  1466438.0  2727393.0  1687834.0  2395791.0       495522.0\n",
       "2021  1424948.0  2641052.0  1576876.0  2331143.0       493494.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack the population data\n",
    "pop_df = pd.concat(\n",
    "    [pop_df_2010_2019, pop_df_2020_2021]\n",
    ")\n",
    "\n",
    "# only keep 2018-2021 data\n",
    "pop_df = pop_df.filter(items = [2018, 2019, 2020, 2021], axis = 0)\n",
    "pop_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_year</th>\n",
       "      <th>Bronx</th>\n",
       "      <th>Brooklyn</th>\n",
       "      <th>Manhattan</th>\n",
       "      <th>Queens</th>\n",
       "      <th>Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>1432087.0</td>\n",
       "      <td>2578074.0</td>\n",
       "      <td>1629055.0</td>\n",
       "      <td>2274605.0</td>\n",
       "      <td>476260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>1418207.0</td>\n",
       "      <td>2559903.0</td>\n",
       "      <td>1628706.0</td>\n",
       "      <td>2253858.0</td>\n",
       "      <td>476143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>1466438.0</td>\n",
       "      <td>2727393.0</td>\n",
       "      <td>1687834.0</td>\n",
       "      <td>2395791.0</td>\n",
       "      <td>495522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>1424948.0</td>\n",
       "      <td>2641052.0</td>\n",
       "      <td>1576876.0</td>\n",
       "      <td>2331143.0</td>\n",
       "      <td>493494.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week_year      Bronx   Brooklyn  Manhattan     Queens  Staten Island\n",
       "0       2018  1432087.0  2578074.0  1629055.0  2274605.0       476260.0\n",
       "1       2019  1418207.0  2559903.0  1628706.0  2253858.0       476143.0\n",
       "2       2020  1466438.0  2727393.0  1687834.0  2395791.0       495522.0\n",
       "3       2021  1424948.0  2641052.0  1576876.0  2331143.0       493494.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename the index column\n",
    "pop_df.index.name = 'week_year'\n",
    "pop_df = pop_df.reset_index()\n",
    "pop_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>week_year</th><th>population</th><th>borough</th></tr>\n",
       "<tr><td>2018</td><td>1432087.0</td><td>Bronx</td></tr>\n",
       "<tr><td>2019</td><td>1418207.0</td><td>Bronx</td></tr>\n",
       "<tr><td>2020</td><td>1466438.0</td><td>Bronx</td></tr>\n",
       "<tr><td>2021</td><td>1424948.0</td><td>Bronx</td></tr>\n",
       "<tr><td>2018</td><td>2578074.0</td><td>Brooklyn</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+----------+--------+\n",
       "|week_year|population| borough|\n",
       "+---------+----------+--------+\n",
       "|     2018| 1432087.0|   Bronx|\n",
       "|     2019| 1418207.0|   Bronx|\n",
       "|     2020| 1466438.0|   Bronx|\n",
       "|     2021| 1424948.0|   Bronx|\n",
       "|     2018| 2578074.0|Brooklyn|\n",
       "+---------+----------+--------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verticalize the data (I just want a year column and a borough column)\n",
    "temp_df = None\n",
    "for col in pop_df.columns[1:]:\n",
    "    # add the borough to an extracted borough column\n",
    "    # using .copy() hides a space-hog warning about not editing pop_df \n",
    "    # (which is my intention)\n",
    "    b_pop_df = pop_df[['week_year', col]].copy()\n",
    "    b_pop_df.columns = ['week_year', 'population']\n",
    "    b_pop_df['borough'] = col\n",
    "\n",
    "    if temp_df is None:\n",
    "        temp_df = b_pop_df \n",
    "    else:\n",
    "        temp_df = pd.concat([temp_df, b_pop_df])\n",
    "\n",
    "# set the verticalized data to the population data\n",
    "pop_df = spark.createDataFrame(temp_df)\n",
    "pop_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save the population df\n",
    "pop_df.write.mode('overwrite').parquet(f'{DATA_PATH}/curated/population_by_borough_by_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cleaning the TLC dataset(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th></tr>\n",
       "<tr><td>1</td><td>2019-12-01 00:26:58</td><td>2019-12-01 00:41:45</td><td>1.0</td><td>4.2</td><td>1.0</td><td>N</td><td>142</td><td>116</td><td>2</td><td>14.5</td><td>3.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>18.3</td><td>2.5</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-12-01 00:12:08</td><td>2019-12-01 00:12:14</td><td>1.0</td><td>0.0</td><td>1.0</td><td>N</td><td>145</td><td>145</td><td>2</td><td>2.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>3.8</td><td>0.0</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-12-01 00:25:53</td><td>2019-12-01 00:26:04</td><td>1.0</td><td>0.0</td><td>1.0</td><td>N</td><td>145</td><td>145</td><td>2</td><td>2.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>3.8</td><td>0.0</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-12-01 00:12:03</td><td>2019-12-01 00:33:19</td><td>2.0</td><td>9.4</td><td>1.0</td><td>N</td><td>138</td><td>25</td><td>1</td><td>28.5</td><td>0.5</td><td>0.5</td><td>10.0</td><td>0.0</td><td>0.3</td><td>39.8</td><td>0.0</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-12-01 00:05:27</td><td>2019-12-01 00:16:32</td><td>2.0</td><td>1.6</td><td>1.0</td><td>N</td><td>161</td><td>237</td><td>2</td><td>9.0</td><td>3.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>12.8</td><td>2.5</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|       1| 2019-12-01 00:26:58|  2019-12-01 00:41:45|            1.0|          4.2|       1.0|                 N|         142|         116|           2|       14.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        18.3|                 2.5|       null|\n",
       "|       1| 2019-12-01 00:12:08|  2019-12-01 00:12:14|            1.0|          0.0|       1.0|                 N|         145|         145|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                 0.0|       null|\n",
       "|       1| 2019-12-01 00:25:53|  2019-12-01 00:26:04|            1.0|          0.0|       1.0|                 N|         145|         145|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                 0.0|       null|\n",
       "|       1| 2019-12-01 00:12:03|  2019-12-01 00:33:19|            2.0|          9.4|       1.0|                 N|         138|          25|           1|       28.5|  0.5|    0.5|      10.0|         0.0|                  0.3|        39.8|                 0.0|       null|\n",
       "|       1| 2019-12-01 00:05:27|  2019-12-01 00:16:32|            2.0|          1.6|       1.0|                 N|         161|         237|           2|        9.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        12.8|                 2.5|       null|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in an example to see the datatypes\n",
    "example_df = spark.read.parquet(f'{DATA_PATH}/raw/tlc/yellow/2019_12.parquet/')\n",
    "example_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th></tr>\n",
       "<tr><td>2</td><td>2019-12-04 10:20:13</td><td>2019-12-04 10:24:43</td><td>1.0</td><td>19130.18</td><td>5.0</td><td>N</td><td>224</td><td>224</td><td>2</td><td>11.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>11.0</td><td>0.0</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2019-12-25 20:44:07</td><td>2019-12-26 03:10:41</td><td>2.0</td><td>363.13</td><td>5.0</td><td>N</td><td>132</td><td>265</td><td>2</td><td>400.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>46.34</td><td>0.3</td><td>447.14</td><td>0.0</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2019-12-09 21:17:33</td><td>2019-12-10 02:55:18</td><td>4.0</td><td>323.81</td><td>5.0</td><td>N</td><td>130</td><td>265</td><td>2</td><td>400.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>126.0</td><td>0.3</td><td>526.3</td><td>0.0</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-12-29 12:29:25</td><td>2019-12-29 12:34:03</td><td>1.0</td><td>300.8</td><td>1.0</td><td>N</td><td>231</td><td>125</td><td>2</td><td>5.5</td><td>2.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>8.8</td><td>2.5</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-12-15 10:44:46</td><td>2019-12-15 14:45:38</td><td>1.0</td><td>248.6</td><td>5.0</td><td>N</td><td>138</td><td>265</td><td>1</td><td>475.0</td><td>0.0</td><td>0.0</td><td>8.88</td><td>18.62</td><td>0.3</td><td>502.8</td><td>0.0</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|       2| 2019-12-04 10:20:13|  2019-12-04 10:24:43|            1.0|     19130.18|       5.0|                 N|         224|         224|           2|       11.0|  0.0|    0.0|       0.0|         0.0|                  0.0|        11.0|                 0.0|       null|\n",
       "|       2| 2019-12-25 20:44:07|  2019-12-26 03:10:41|            2.0|       363.13|       5.0|                 N|         132|         265|           2|      400.0|  0.0|    0.5|       0.0|       46.34|                  0.3|      447.14|                 0.0|       null|\n",
       "|       2| 2019-12-09 21:17:33|  2019-12-10 02:55:18|            4.0|       323.81|       5.0|                 N|         130|         265|           2|      400.0|  0.0|    0.0|       0.0|       126.0|                  0.3|       526.3|                 0.0|       null|\n",
       "|       1| 2019-12-29 12:29:25|  2019-12-29 12:34:03|            1.0|        300.8|       1.0|                 N|         231|         125|           2|        5.5|  2.5|    0.5|       0.0|         0.0|                  0.3|         8.8|                 2.5|       null|\n",
       "|       1| 2019-12-15 10:44:46|  2019-12-15 14:45:38|            1.0|        248.6|       5.0|                 N|         138|         265|           1|      475.0|  0.0|    0.0|      8.88|       18.62|                  0.3|       502.8|                 0.0|       null|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are large trip distances that I need to filter out\n",
    "example_df.sort('trip_distance', ascending = False).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th></tr>\n",
       "<tr><td>1</td><td>2019-12-01 00:26:58</td><td>2019-12-01 00:41:45</td><td>1.0</td><td>4.2</td><td>1.0</td><td>N</td><td>142</td><td>116</td><td>2</td><td>14.5</td><td>3.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>18.3</td><td>2.5</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-12-01 00:12:08</td><td>2019-12-01 00:12:14</td><td>1.0</td><td>0.0</td><td>1.0</td><td>N</td><td>145</td><td>145</td><td>2</td><td>2.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>3.8</td><td>0.0</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-12-01 00:25:53</td><td>2019-12-01 00:26:04</td><td>1.0</td><td>0.0</td><td>1.0</td><td>N</td><td>145</td><td>145</td><td>2</td><td>2.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>3.8</td><td>0.0</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-12-01 00:12:03</td><td>2019-12-01 00:33:19</td><td>2.0</td><td>9.4</td><td>1.0</td><td>N</td><td>138</td><td>25</td><td>1</td><td>28.5</td><td>0.5</td><td>0.5</td><td>10.0</td><td>0.0</td><td>0.3</td><td>39.8</td><td>0.0</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-12-01 00:05:27</td><td>2019-12-01 00:16:32</td><td>2.0</td><td>1.6</td><td>1.0</td><td>N</td><td>161</td><td>237</td><td>2</td><td>9.0</td><td>3.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>12.8</td><td>2.5</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|       1| 2019-12-01 00:26:58|  2019-12-01 00:41:45|            1.0|          4.2|       1.0|                 N|         142|         116|           2|       14.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        18.3|                 2.5|       null|\n",
       "|       1| 2019-12-01 00:12:08|  2019-12-01 00:12:14|            1.0|          0.0|       1.0|                 N|         145|         145|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                 0.0|       null|\n",
       "|       1| 2019-12-01 00:25:53|  2019-12-01 00:26:04|            1.0|          0.0|       1.0|                 N|         145|         145|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                 0.0|       null|\n",
       "|       1| 2019-12-01 00:12:03|  2019-12-01 00:33:19|            2.0|          9.4|       1.0|                 N|         138|          25|           1|       28.5|  0.5|    0.5|      10.0|         0.0|                  0.3|        39.8|                 0.0|       null|\n",
       "|       1| 2019-12-01 00:05:27|  2019-12-01 00:16:32|            2.0|          1.6|       1.0|                 N|         161|         237|           2|        9.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        12.8|                 2.5|       null|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the tlc data\n",
    "tlc_df = jh.read_stacked_tlc_df(spark)\n",
    "tlc_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64913648"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the amount of raw rows\n",
    "tlc_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive extra values which are used to filter out valid trips\n",
    "SECONDS_TO_HOURS = 1 / (60*60)\n",
    "tlc_df = tlc_df\\\n",
    "    .withColumn('hours_elapsed', \n",
    "        ( # counts how long the trip was in hours\n",
    "            (F.col(\"tpep_dropoff_datetime\").cast(\"long\")\n",
    "            - F.col('tpep_pickup_datetime').cast(\"long\")) \n",
    "            * SECONDS_TO_HOURS\n",
    "        )\n",
    "    )\\\n",
    "    .withColumn('mph', \n",
    "        ( # calculate the speed of the trip\n",
    "            F.col('trip_distance') / F.col('hours_elapsed')\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th><th>hours_elapsed</th><th>mph</th></tr>\n",
       "<tr><td>1</td><td>2019-12-01 00:26:58</td><td>2019-12-01 00:41:45</td><td>1.0</td><td>4.2</td><td>1.0</td><td>N</td><td>142</td><td>116</td><td>2</td><td>14.5</td><td>3.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>18.3</td><td>2.5</td><td>null</td><td>0.24638888888888888</td><td>17.04622322435175</td></tr>\n",
       "<tr><td>1</td><td>2019-12-01 00:12:08</td><td>2019-12-01 00:12:14</td><td>1.0</td><td>0.0</td><td>1.0</td><td>N</td><td>145</td><td>145</td><td>2</td><td>2.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>3.8</td><td>0.0</td><td>null</td><td>0.001666666666666...</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2019-12-01 00:25:53</td><td>2019-12-01 00:26:04</td><td>1.0</td><td>0.0</td><td>1.0</td><td>N</td><td>145</td><td>145</td><td>2</td><td>2.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>3.8</td><td>0.0</td><td>null</td><td>0.003055555555555...</td><td>0.0</td></tr>\n",
       "<tr><td>1</td><td>2019-12-01 00:12:03</td><td>2019-12-01 00:33:19</td><td>2.0</td><td>9.4</td><td>1.0</td><td>N</td><td>138</td><td>25</td><td>1</td><td>28.5</td><td>0.5</td><td>0.5</td><td>10.0</td><td>0.0</td><td>0.3</td><td>39.8</td><td>0.0</td><td>null</td><td>0.35444444444444445</td><td>26.52037617554859</td></tr>\n",
       "<tr><td>1</td><td>2019-12-01 00:05:27</td><td>2019-12-01 00:16:32</td><td>2.0</td><td>1.6</td><td>1.0</td><td>N</td><td>161</td><td>237</td><td>2</td><td>9.0</td><td>3.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>12.8</td><td>2.5</td><td>null</td><td>0.18472222222222223</td><td>8.661654135338345</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+--------------------+-----------------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|       hours_elapsed|              mph|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+--------------------+-----------------+\n",
       "|       1| 2019-12-01 00:26:58|  2019-12-01 00:41:45|            1.0|          4.2|       1.0|                 N|         142|         116|           2|       14.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        18.3|                 2.5|       null| 0.24638888888888888|17.04622322435175|\n",
       "|       1| 2019-12-01 00:12:08|  2019-12-01 00:12:14|            1.0|          0.0|       1.0|                 N|         145|         145|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                 0.0|       null|0.001666666666666...|              0.0|\n",
       "|       1| 2019-12-01 00:25:53|  2019-12-01 00:26:04|            1.0|          0.0|       1.0|                 N|         145|         145|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                 0.0|       null|0.003055555555555...|              0.0|\n",
       "|       1| 2019-12-01 00:12:03|  2019-12-01 00:33:19|            2.0|          9.4|       1.0|                 N|         138|          25|           1|       28.5|  0.5|    0.5|      10.0|         0.0|                  0.3|        39.8|                 0.0|       null| 0.35444444444444445|26.52037617554859|\n",
       "|       1| 2019-12-01 00:05:27|  2019-12-01 00:16:32|            2.0|          1.6|       1.0|                 N|         161|         237|           2|        9.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        12.8|                 2.5|       null| 0.18472222222222223|8.661654135338345|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+--------------------+-----------------+"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the columns look correct\n",
    "tlc_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ypdcrime.com/vt/article30.php?zoom_highlight=fifty+five+miles+per+hour#t1180-a\n",
    "# As per: https://www.dot.ny.gov/divisions/operating/oom/transportation-systems/repository/TSMI-17-05.pdf\n",
    "# the NYS maximum speed limit is 65 mph. filter out trips faster than legal.\n",
    "tlc_df = tlc_df.where(\n",
    "    (F.col('mph').isNotNull()) &\n",
    "    (F.col('mph') <= 65)\n",
    ")\n",
    "\n",
    "# this legitimately removes any invalid trips \n",
    "# (and other null values are culled later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th><th>hours_elapsed</th><th>mph</th></tr>\n",
       "<tr><td>2</td><td>2021-10-12 21:32:01</td><td>2021-10-13 04:57:45</td><td>1.0</td><td>448.47</td><td>5.0</td><td>N</td><td>216</td><td>265</td><td>2</td><td>400.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>6.55</td><td>0.3</td><td>406.85</td><td>0.0</td><td>0.0</td><td>7.428888888888889</td><td>60.368381693090036</td></tr>\n",
       "<tr><td>1</td><td>2020-06-02 06:36:15</td><td>2020-06-02 14:33:50</td><td>1.0</td><td>441.6</td><td>5.0</td><td>N</td><td>68</td><td>265</td><td>2</td><td>300.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.3</td><td>300.3</td><td>0.0</td><td>null</td><td>7.959722222222222</td><td>55.479322980282674</td></tr>\n",
       "<tr><td>1</td><td>2021-01-20 11:22:05</td><td>2021-01-20 19:47:56</td><td>1.0</td><td>427.7</td><td>1.0</td><td>Y</td><td>4</td><td>265</td><td>1</td><td>1128.5</td><td>2.5</td><td>0.5</td><td>1140.44</td><td>20.16</td><td>0.3</td><td>2292.4</td><td>2.5</td><td>null</td><td>8.430833333333334</td><td>50.73045369180586</td></tr>\n",
       "<tr><td>1</td><td>2020-07-30 15:10:02</td><td>2020-07-30 22:04:34</td><td>1.0</td><td>414.4</td><td>5.0</td><td>N</td><td>138</td><td>265</td><td>1</td><td>400.0</td><td>0.0</td><td>0.0</td><td>87.2</td><td>35.74</td><td>0.3</td><td>523.24</td><td>0.0</td><td>null</td><td>6.908888888888889</td><td>59.98070119009328</td></tr>\n",
       "<tr><td>2</td><td>2020-12-06 07:33:27</td><td>2020-12-06 14:01:29</td><td>1.0</td><td>407.78</td><td>5.0</td><td>N</td><td>264</td><td>265</td><td>1</td><td>200.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>11.75</td><td>0.3</td><td>215.55</td><td>2.5</td><td>null</td><td>6.467222222222222</td><td>63.05334593248002</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-----------------+------------------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|    hours_elapsed|               mph|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-----------------+------------------+\n",
       "|       2| 2021-10-12 21:32:01|  2021-10-13 04:57:45|            1.0|       448.47|       5.0|                 N|         216|         265|           2|      400.0|  0.0|    0.0|       0.0|        6.55|                  0.3|      406.85|                 0.0|        0.0|7.428888888888889|60.368381693090036|\n",
       "|       1| 2020-06-02 06:36:15|  2020-06-02 14:33:50|            1.0|        441.6|       5.0|                 N|          68|         265|           2|      300.0|  0.0|    0.0|       0.0|         0.0|                  0.3|       300.3|                 0.0|       null|7.959722222222222|55.479322980282674|\n",
       "|       1| 2021-01-20 11:22:05|  2021-01-20 19:47:56|            1.0|        427.7|       1.0|                 Y|           4|         265|           1|     1128.5|  2.5|    0.5|   1140.44|       20.16|                  0.3|      2292.4|                 2.5|       null|8.430833333333334| 50.73045369180586|\n",
       "|       1| 2020-07-30 15:10:02|  2020-07-30 22:04:34|            1.0|        414.4|       5.0|                 N|         138|         265|           1|      400.0|  0.0|    0.0|      87.2|       35.74|                  0.3|      523.24|                 0.0|       null|6.908888888888889| 59.98070119009328|\n",
       "|       2| 2020-12-06 07:33:27|  2020-12-06 14:01:29|            1.0|       407.78|       5.0|                 N|         264|         265|           1|      200.0|  0.0|    0.0|       1.0|       11.75|                  0.3|      215.55|                 2.5|       null|6.467222222222222| 63.05334593248002|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-----------------+------------------+"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WARNING: this one is time intensive \n",
    "# check for large distance trips \n",
    "# (as long as the timing seems reasonable, they are kept)\n",
    "tlc_df.sort('trip_distance', ascending = False).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>pu_location_id</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th><th>hours_elapsed</th><th>mph</th><th>pu_borough</th></tr>\n",
       "<tr><td>2</td><td>2021-10-12 21:32:01</td><td>2021-10-13 04:57:45</td><td>1.0</td><td>448.47</td><td>5.0</td><td>N</td><td>216</td><td>265</td><td>2</td><td>400.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>6.55</td><td>0.3</td><td>406.85</td><td>0.0</td><td>0.0</td><td>7.428888888888889</td><td>60.368381693090036</td><td>Queens</td></tr>\n",
       "<tr><td>1</td><td>2020-06-02 06:36:15</td><td>2020-06-02 14:33:50</td><td>1.0</td><td>441.6</td><td>5.0</td><td>N</td><td>68</td><td>265</td><td>2</td><td>300.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.3</td><td>300.3</td><td>0.0</td><td>null</td><td>7.959722222222222</td><td>55.479322980282674</td><td>Manhattan</td></tr>\n",
       "<tr><td>1</td><td>2021-01-20 11:22:05</td><td>2021-01-20 19:47:56</td><td>1.0</td><td>427.7</td><td>1.0</td><td>Y</td><td>4</td><td>265</td><td>1</td><td>1128.5</td><td>2.5</td><td>0.5</td><td>1140.44</td><td>20.16</td><td>0.3</td><td>2292.4</td><td>2.5</td><td>null</td><td>8.430833333333334</td><td>50.73045369180586</td><td>Manhattan</td></tr>\n",
       "<tr><td>1</td><td>2020-07-30 15:10:02</td><td>2020-07-30 22:04:34</td><td>1.0</td><td>414.4</td><td>5.0</td><td>N</td><td>138</td><td>265</td><td>1</td><td>400.0</td><td>0.0</td><td>0.0</td><td>87.2</td><td>35.74</td><td>0.3</td><td>523.24</td><td>0.0</td><td>null</td><td>6.908888888888889</td><td>59.98070119009328</td><td>Queens</td></tr>\n",
       "<tr><td>2</td><td>2020-02-08 08:58:50</td><td>2020-02-08 15:03:36</td><td>3.0</td><td>369.94</td><td>3.0</td><td>N</td><td>48</td><td>265</td><td>2</td><td>960.5</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.3</td><td>960.8</td><td>0.0</td><td>null</td><td>6.079444444444444</td><td>60.85095494836882</td><td>Manhattan</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+--------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-----------------+------------------+----------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|pu_location_id|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|    hours_elapsed|               mph|pu_borough|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+--------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-----------------+------------------+----------+\n",
       "|       2| 2021-10-12 21:32:01|  2021-10-13 04:57:45|            1.0|       448.47|       5.0|                 N|           216|         265|           2|      400.0|  0.0|    0.0|       0.0|        6.55|                  0.3|      406.85|                 0.0|        0.0|7.428888888888889|60.368381693090036|    Queens|\n",
       "|       1| 2020-06-02 06:36:15|  2020-06-02 14:33:50|            1.0|        441.6|       5.0|                 N|            68|         265|           2|      300.0|  0.0|    0.0|       0.0|         0.0|                  0.3|       300.3|                 0.0|       null|7.959722222222222|55.479322980282674| Manhattan|\n",
       "|       1| 2021-01-20 11:22:05|  2021-01-20 19:47:56|            1.0|        427.7|       1.0|                 Y|             4|         265|           1|     1128.5|  2.5|    0.5|   1140.44|       20.16|                  0.3|      2292.4|                 2.5|       null|8.430833333333334| 50.73045369180586| Manhattan|\n",
       "|       1| 2020-07-30 15:10:02|  2020-07-30 22:04:34|            1.0|        414.4|       5.0|                 N|           138|         265|           1|      400.0|  0.0|    0.0|      87.2|       35.74|                  0.3|      523.24|                 0.0|       null|6.908888888888889| 59.98070119009328|    Queens|\n",
       "|       2| 2020-02-08 08:58:50|  2020-02-08 15:03:36|            3.0|       369.94|       3.0|                 N|            48|         265|           2|      960.5|  0.0|    0.0|       0.0|         0.0|                  0.3|       960.8|                 0.0|       null|6.079444444444444| 60.85095494836882| Manhattan|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+--------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-----------------+------------------+----------+"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WARNING: this one is time intensive \n",
    "# next, filter out trips which do not start  within the 5 boroughs \n",
    "tlc_df = ch.extract_borough_name(\n",
    "    tlc_df.withColumnRenamed('PULocationID', 'pu_location_id'), zones_df,  'pu')\n",
    "# tlc_df = ch.extract_borough_name(tlc_df, zones_df,  'do')\n",
    "tlc_df.sort('trip_distance', ascending=False).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of the tlc datasets to clean \n",
    "# (I was originally planning on working on fhvhv and green as well)\n",
    "TLC_NAMES = ['yellow']\n",
    "\n",
    "# dictionary to rename all the columns I want to keep\n",
    "TLC_KEEP_COLUMNS = {\n",
    "    'tpep_pickup_datetime': 'date',\n",
    "    # 'passenger_count': 'passengers',\n",
    "    'trip_distance': 'trip_distance',\n",
    "    'pu_borough': 'pu_borough',\n",
    "    # 'DOLocationID': 'do_location_id',\n",
    "    'hours_elapsed': 'hours_elapsed'\n",
    "    # #  below only apply to fhvhv\n",
    "    # 'hvfhs_license_num': 'fhvhv_license',\n",
    "    # 'pickup_datetime': 'date',\n",
    "    # 'trip_miles': 'trip_distance',\n",
    "    # 'shared_request_flag': 'shared'\n",
    "}\n",
    "\n",
    "# create a dictionary of the columns to keep and the required filters\n",
    "TLC_CLEAN_COLUMNS = {\n",
    "    'pu_location_id': [ch.non_null], \n",
    "    # 'do_location_id': [ch.non_null], \n",
    "    # 'passengers': [ch.non_null], \n",
    "    'trip_distance': [ch.non_null, ch.non_negative], \n",
    "    # #  below only apply to fhvhv\n",
    "    # 'fhvhv_license': [ch.non_null], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the drawn out cleaning process (function in `scripts/helpers`)\n",
    "tlc_df = ch.perform_cleaning(tlc_df, mmwr_weeks_df, TLC_KEEP_COLUMNS, \n",
    "    TLC_CLEAN_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>month</th><th>day</th><th>week_ending</th><th>week_year</th><th>week_month</th><th>week_index</th><th>date</th><th>trip_distance</th><th>pu_borough</th><th>hours_elapsed</th></tr>\n",
       "<tr><td>2022</td><td>1</td><td>1</td><td>2022-01-01</td><td>2021</td><td>12</td><td>105</td><td>01/01/2022</td><td>8.46</td><td>Queens</td><td>0.3136111111111111</td></tr>\n",
       "<tr><td>2022</td><td>1</td><td>1</td><td>2022-01-01</td><td>2021</td><td>12</td><td>105</td><td>01/01/2022</td><td>8.65</td><td>Queens</td><td>0.2544444444444444</td></tr>\n",
       "<tr><td>2022</td><td>1</td><td>1</td><td>2022-01-01</td><td>2021</td><td>12</td><td>105</td><td>01/01/2022</td><td>2.44</td><td>Queens</td><td>0.12055555555555555</td></tr>\n",
       "<tr><td>2022</td><td>1</td><td>1</td><td>2022-01-01</td><td>2021</td><td>12</td><td>105</td><td>01/01/2022</td><td>13.03</td><td>Queens</td><td>0.35388888888888886</td></tr>\n",
       "<tr><td>2022</td><td>1</td><td>1</td><td>2022-01-01</td><td>2021</td><td>12</td><td>105</td><td>01/01/2022</td><td>10.01</td><td>Queens</td><td>0.4211111111111111</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-----+---+-----------+---------+----------+----------+----------+-------------+----------+-------------------+\n",
       "|year|month|day|week_ending|week_year|week_month|week_index|      date|trip_distance|pu_borough|      hours_elapsed|\n",
       "+----+-----+---+-----------+---------+----------+----------+----------+-------------+----------+-------------------+\n",
       "|2022|    1|  1| 2022-01-01|     2021|        12|       105|01/01/2022|         8.46|    Queens| 0.3136111111111111|\n",
       "|2022|    1|  1| 2022-01-01|     2021|        12|       105|01/01/2022|         8.65|    Queens| 0.2544444444444444|\n",
       "|2022|    1|  1| 2022-01-01|     2021|        12|       105|01/01/2022|         2.44|    Queens|0.12055555555555555|\n",
       "|2022|    1|  1| 2022-01-01|     2021|        12|       105|01/01/2022|        13.03|    Queens|0.35388888888888886|\n",
       "|2022|    1|  1| 2022-01-01|     2021|        12|       105|01/01/2022|        10.01|    Queens| 0.4211111111111111|\n",
       "+----+-----+---+-----------+---------+----------+----------+----------+-------------+----------+-------------------+"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WARNING: this one is time intensive \n",
    "# make sure that the latest data pads the used timeline \n",
    "# (so I'm not missing any weeks in the final timeline)\n",
    "tlc_df.sort('week_index', ascending = False).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>month</th><th>day</th><th>week_ending</th><th>week_year</th><th>week_month</th><th>week_index</th><th>date</th><th>trip_distance</th><th>pu_borough</th><th>hours_elapsed</th></tr>\n",
       "<tr><td>2021</td><td>10</td><td>12</td><td>2021-10-16</td><td>2021</td><td>10</td><td>94</td><td>10/12/2021</td><td>448.47</td><td>Queens</td><td>7.428888888888889</td></tr>\n",
       "<tr><td>2020</td><td>6</td><td>2</td><td>2020-06-06</td><td>2020</td><td>6</td><td>23</td><td>06/02/2020</td><td>441.6</td><td>Manhattan</td><td>7.959722222222222</td></tr>\n",
       "<tr><td>2021</td><td>1</td><td>20</td><td>2021-01-23</td><td>2021</td><td>1</td><td>56</td><td>01/20/2021</td><td>427.7</td><td>Manhattan</td><td>8.430833333333334</td></tr>\n",
       "<tr><td>2020</td><td>7</td><td>30</td><td>2020-08-01</td><td>2020</td><td>7</td><td>31</td><td>07/30/2020</td><td>414.4</td><td>Queens</td><td>6.908888888888889</td></tr>\n",
       "<tr><td>2020</td><td>2</td><td>8</td><td>2020-02-08</td><td>2020</td><td>2</td><td>6</td><td>02/08/2020</td><td>369.94</td><td>Manhattan</td><td>6.079444444444444</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-----+---+-----------+---------+----------+----------+----------+-------------+----------+-----------------+\n",
       "|year|month|day|week_ending|week_year|week_month|week_index|      date|trip_distance|pu_borough|    hours_elapsed|\n",
       "+----+-----+---+-----------+---------+----------+----------+----------+-------------+----------+-----------------+\n",
       "|2021|   10| 12| 2021-10-16|     2021|        10|        94|10/12/2021|       448.47|    Queens|7.428888888888889|\n",
       "|2020|    6|  2| 2020-06-06|     2020|         6|        23|06/02/2020|        441.6| Manhattan|7.959722222222222|\n",
       "|2021|    1| 20| 2021-01-23|     2021|         1|        56|01/20/2021|        427.7| Manhattan|8.430833333333334|\n",
       "|2020|    7| 30| 2020-08-01|     2020|         7|        31|07/30/2020|        414.4|    Queens|6.908888888888889|\n",
       "|2020|    2|  8| 2020-02-08|     2020|         2|         6|02/08/2020|       369.94| Manhattan|6.079444444444444|\n",
       "+----+-----+---+-----------+---------+----------+----------+----------+-------------+----------+-----------------+"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WARNING: this one is time intensive \n",
    "# double check for any trip distance outliers\n",
    "tlc_df.sort('trip_distance', ascending=False).limit(5)\n",
    "\n",
    "# my cleaning seems to have worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55439045"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WARNING: this one is time intensive \n",
    "# count the number of rows after cleaning\n",
    "tlc_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# WARNING: this one is time intensive \n",
    "# save the stacked df by month (this will take a while)\n",
    "# sorting first prevents the partitioning part of the write from crashing\n",
    "# (form personal experience)\n",
    "tlc_df = tlc_df.sort('week_year', 'week_month')\n",
    "tlc_df.write\\\n",
    "    .partitionBy('week_year', 'week_month')\\\n",
    "    .mode('overwrite')\\\n",
    "    .parquet(f'{DATA_PATH}/curated/tlc/cleaned/yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cleaning the COVID dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/21 08:16:11 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>date_of_interest</th><th>CASE_COUNT</th><th>PROBABLE_CASE_COUNT</th><th>HOSPITALIZED_COUNT</th><th>DEATH_COUNT</th><th>PROBABLE_DEATH_COUNT</th><th>CASE_COUNT_7DAY_AVG</th><th>ALL_CASE_COUNT_7DAY_AVG</th><th>HOSP_COUNT_7DAY_AVG</th><th>DEATH_COUNT_7DAY_AVG</th><th>ALL_DEATH_COUNT_7DAY_AVG</th><th>BX_CASE_COUNT</th><th>BX_PROBABLE_CASE_COUNT</th><th>BX_HOSPITALIZED_COUNT</th><th>BX_DEATH_COUNT</th><th>BX_PROBABLE_DEATH_COUNT</th><th>BX_CASE_COUNT_7DAY_AVG</th><th>BX_PROBABLE_CASE_COUNT_7DAY_AVG</th><th>BX_ALL_CASE_COUNT_7DAY_AVG</th><th>BX_HOSPITALIZED_COUNT_7DAY_AVG</th><th>BX_DEATH_COUNT_7DAY_AVG</th><th>BX_ALL_DEATH_COUNT_7DAY_AVG</th><th>BK_CASE_COUNT</th><th>BK_PROBABLE_CASE_COUNT</th><th>BK_HOSPITALIZED_COUNT</th><th>BK_DEATH_COUNT</th><th>BK_PROBABLE_DEATH_COUNT</th><th>BK_CASE_COUNT_7DAY_AVG</th><th>BK_PROBABLE_CASE_COUNT_7DAY_AVG</th><th>BK_ALL_CASE_COUNT_7DAY_AVG</th><th>BK_HOSPITALIZED_COUNT_7DAY_AVG</th><th>BK_DEATH_COUNT_7DAY_AVG</th><th>BK_ALL_DEATH_COUNT_7DAY_AVG</th><th>MN_CASE_COUNT</th><th>MN_PROBABLE_CASE_COUNT</th><th>MN_HOSPITALIZED_COUNT</th><th>MN_DEATH_COUNT</th><th>MN_PROBABLE_DEATH_COUNT</th><th>MN_CASE_COUNT_7DAY_AVG</th><th>MN_PROBABLE_CASE_COUNT_7DAY_AVG</th><th>MN_ALL_CASE_COUNT_7DAY_AVG</th><th>MN_HOSPITALIZED_COUNT_7DAY_AVG</th><th>MN_DEATH_COUNT_7DAY_AVG</th><th>MN_ALL_DEATH_COUNT_7DAY_AVG</th><th>QN_CASE_COUNT</th><th>QN_PROBABLE_CASE_COUNT</th><th>QN_HOSPITALIZED_COUNT</th><th>QN_DEATH_COUNT</th><th>QN_PROBABLE_DEATH_COUNT</th><th>QN_CASE_COUNT_7DAY_AVG</th><th>QN_PROBABLE_CASE_COUNT_7DAY_AVG</th><th>QN_ALL_CASE_COUNT_7DAY_AVG</th><th>QN_HOSPITALIZED_COUNT_7DAY_AVG</th><th>QN_DEATH_COUNT_7DAY_AVG</th><th>QN_ALL_DEATH_COUNT_7DAY_AVG</th><th>SI_CASE_COUNT</th><th>SI_PROBABLE_CASE_COUNT</th><th>SI_HOSPITALIZED_COUNT</th><th>SI_DEATH_COUNT</th><th>SI_PROBABLE_DEATH_COUNT</th><th>SI_CASE_COUNT_7DAY_AVG</th><th>SI_PROBABLE_CASE_COUNT_7DAY_AVG</th><th>SI_ALL_CASE_COUNT_7DAY_AVG</th><th>SI_HOSPITALIZED_COUNT_7DAY_AVG</th><th>SI_DEATH_COUNT_7DAY_AVG</th><th>SI_ALL_DEATH_COUNT_7DAY_AVG</th><th>INCOMPLETE</th></tr>\n",
       "<tr><td>02/29/2020</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>03/01/2020</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>03/02/2020</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>03/03/2020</td><td>1</td><td>0</td><td>7</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>03/04/2020</td><td>5</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------------+----------+-------------------+------------------+-----------+--------------------+-------------------+-----------------------+-------------------+--------------------+------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+----------+\n",
       "|date_of_interest|CASE_COUNT|PROBABLE_CASE_COUNT|HOSPITALIZED_COUNT|DEATH_COUNT|PROBABLE_DEATH_COUNT|CASE_COUNT_7DAY_AVG|ALL_CASE_COUNT_7DAY_AVG|HOSP_COUNT_7DAY_AVG|DEATH_COUNT_7DAY_AVG|ALL_DEATH_COUNT_7DAY_AVG|BX_CASE_COUNT|BX_PROBABLE_CASE_COUNT|BX_HOSPITALIZED_COUNT|BX_DEATH_COUNT|BX_PROBABLE_DEATH_COUNT|BX_CASE_COUNT_7DAY_AVG|BX_PROBABLE_CASE_COUNT_7DAY_AVG|BX_ALL_CASE_COUNT_7DAY_AVG|BX_HOSPITALIZED_COUNT_7DAY_AVG|BX_DEATH_COUNT_7DAY_AVG|BX_ALL_DEATH_COUNT_7DAY_AVG|BK_CASE_COUNT|BK_PROBABLE_CASE_COUNT|BK_HOSPITALIZED_COUNT|BK_DEATH_COUNT|BK_PROBABLE_DEATH_COUNT|BK_CASE_COUNT_7DAY_AVG|BK_PROBABLE_CASE_COUNT_7DAY_AVG|BK_ALL_CASE_COUNT_7DAY_AVG|BK_HOSPITALIZED_COUNT_7DAY_AVG|BK_DEATH_COUNT_7DAY_AVG|BK_ALL_DEATH_COUNT_7DAY_AVG|MN_CASE_COUNT|MN_PROBABLE_CASE_COUNT|MN_HOSPITALIZED_COUNT|MN_DEATH_COUNT|MN_PROBABLE_DEATH_COUNT|MN_CASE_COUNT_7DAY_AVG|MN_PROBABLE_CASE_COUNT_7DAY_AVG|MN_ALL_CASE_COUNT_7DAY_AVG|MN_HOSPITALIZED_COUNT_7DAY_AVG|MN_DEATH_COUNT_7DAY_AVG|MN_ALL_DEATH_COUNT_7DAY_AVG|QN_CASE_COUNT|QN_PROBABLE_CASE_COUNT|QN_HOSPITALIZED_COUNT|QN_DEATH_COUNT|QN_PROBABLE_DEATH_COUNT|QN_CASE_COUNT_7DAY_AVG|QN_PROBABLE_CASE_COUNT_7DAY_AVG|QN_ALL_CASE_COUNT_7DAY_AVG|QN_HOSPITALIZED_COUNT_7DAY_AVG|QN_DEATH_COUNT_7DAY_AVG|QN_ALL_DEATH_COUNT_7DAY_AVG|SI_CASE_COUNT|SI_PROBABLE_CASE_COUNT|SI_HOSPITALIZED_COUNT|SI_DEATH_COUNT|SI_PROBABLE_DEATH_COUNT|SI_CASE_COUNT_7DAY_AVG|SI_PROBABLE_CASE_COUNT_7DAY_AVG|SI_ALL_CASE_COUNT_7DAY_AVG|SI_HOSPITALIZED_COUNT_7DAY_AVG|SI_DEATH_COUNT_7DAY_AVG|SI_ALL_DEATH_COUNT_7DAY_AVG|INCOMPLETE|\n",
       "+----------------+----------+-------------------+------------------+-----------+--------------------+-------------------+-----------------------+-------------------+--------------------+------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+----------+\n",
       "|      02/29/2020|         1|                  0|                 1|          0|                   0|                  0|                      0|                  0|                   0|                       0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    1|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            1|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|         0|\n",
       "|      03/01/2020|         0|                  0|                 1|          0|                   0|                  0|                      0|                  0|                   0|                       0|            0|                     0|                    1|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|         0|\n",
       "|      03/02/2020|         0|                  0|                 2|          0|                   0|                  0|                      0|                  0|                   0|                       0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    2|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|         0|\n",
       "|      03/03/2020|         1|                  0|                 7|          0|                   0|                  0|                      0|                  0|                   0|                       0|            0|                     0|                    1|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    3|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    1|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            1|                     0|                    2|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|         0|\n",
       "|      03/04/2020|         5|                  0|                 2|          0|                   0|                  0|                      0|                  0|                   0|                       0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            1|                     0|                    1|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            2|                     0|                    1|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            2|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|            0|                     0|                    0|             0|                      0|                     0|                              0|                         0|                             0|                      0|                          0|         0|\n",
       "+----------------+----------+-------------------+------------------+-----------+--------------------+-------------------+-----------------------+-------------------+--------------------+------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+-------------+----------------------+---------------------+--------------+-----------------------+----------------------+-------------------------------+--------------------------+------------------------------+-----------------------+---------------------------+----------+"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the covid dataset\n",
    "covid_df = spark.read.csv(f'{DATA_PATH}/raw/virals/covid/cases_by_day.csv',\n",
    "    header = True, inferSchema=True)\n",
    "covid_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(INCOMPLETE + 0)'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum the number of incomplete datasets (ensure no incomplete values)\n",
    "sum(covid_df.select('INCOMPLETE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to rename all the columns I want to keep\n",
    "COVID_KEEP_COLUMNS = {\n",
    "    'date_of_interest':'date'\n",
    "}\n",
    "\n",
    "# create a dictionary of the columns to keep and the required filters\n",
    "COVID_CLEAN_COLUMNS = defaultdict(lambda: ch.non_negative)\n",
    "\n",
    "# define the boroughs as they appear in columns of the covid dataset\n",
    "COVID_BOROUGHS = {\n",
    "    'BX_':'Bronx',\n",
    "    'BK_':'Brooklyn',\n",
    "    'MN_':'Manhattan',\n",
    "    'QN_':'Queens',\n",
    "    'SI_':'Staten Island',\n",
    "}\n",
    "\n",
    "# define the count values to extract\n",
    "COVID_COUNTS = {\n",
    "    'CASE_COUNT': 'cases', \n",
    "    # 'DEATH_COUNT': 'deaths', \n",
    "    # 'HOSPITALIZED_COUNT': 'hospitalised'\n",
    "}\n",
    "\n",
    "# got throuch each borough and count value and add them to the columns to keep\n",
    "for prefix, new_prefix in COVID_BOROUGHS.items():\n",
    "    for suffix, new_suffix in COVID_COUNTS.items():\n",
    "        COVID_KEEP_COLUMNS[f'{prefix}{suffix}'] = f'{new_prefix}{new_suffix}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the drawn out cleaning process (function in `scripts/helpers`)\n",
    "covid_df = ch.perform_cleaning(covid_df, mmwr_weeks_df, COVID_KEEP_COLUMNS, \n",
    "    COVID_CLEAN_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date columns to keep after verticalising the covid data\n",
    "COVID_DATE_COLUMNS = [\n",
    "    F.col('date'), \n",
    "    F.col('week_ending'), \n",
    "    F.col('week_year'), \n",
    "    F.col('week_month'), \n",
    "    F.col('week_index')\n",
    "]\n",
    "\n",
    "# verticalise this dataset\n",
    "# I'd rather just have a 'borough' column for homogeneity of all the data\n",
    "temp_df = None\n",
    "for prefix in COVID_BOROUGHS.values():\n",
    "    # derive the columns for this borough to extract and stack\n",
    "    borough_columns = []\n",
    "    for suffix in COVID_COUNTS.values():\n",
    "        borough_columns.append(F.col(f'{prefix}{suffix}').alias(suffix))\n",
    "\n",
    "    # extract the counts for this borough and add them to the stacked dataframe\n",
    "    if temp_df == None:\n",
    "        temp_df = covid_df.select(COVID_DATE_COLUMNS + borough_columns)\\\n",
    "            .withColumn('borough', F.lit(prefix))\n",
    "    else:\n",
    "        temp_df = temp_df\\\n",
    "            .union(\n",
    "                covid_df.select(COVID_DATE_COLUMNS + borough_columns)\\\n",
    "                    .withColumn('borough', F.lit(prefix))\n",
    "            )\n",
    "\n",
    "# set the df to the stacked data\n",
    "covid_df = temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the null cases (created from the one-sided outer join for the df) with 0\n",
    "covid_df = covid_df.fillna(0, 'cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>date</th><th>week_ending</th><th>week_year</th><th>week_month</th><th>week_index</th><th>cases</th><th>borough</th></tr>\n",
       "<tr><td>null</td><td>2020-01-04</td><td>2020</td><td>1</td><td>1</td><td>0</td><td>Bronx</td></tr>\n",
       "<tr><td>null</td><td>2020-01-04</td><td>2020</td><td>1</td><td>1</td><td>0</td><td>Bronx</td></tr>\n",
       "<tr><td>null</td><td>2020-01-04</td><td>2020</td><td>1</td><td>1</td><td>0</td><td>Bronx</td></tr>\n",
       "<tr><td>null</td><td>2020-01-04</td><td>2020</td><td>1</td><td>1</td><td>0</td><td>Bronx</td></tr>\n",
       "<tr><td>null</td><td>2020-01-04</td><td>2020</td><td>1</td><td>1</td><td>0</td><td>Bronx</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-----------+---------+----------+----------+-----+-------+\n",
       "|date|week_ending|week_year|week_month|week_index|cases|borough|\n",
       "+----+-----------+---------+----------+----------+-----+-------+\n",
       "|null| 2020-01-04|     2020|         1|         1|    0|  Bronx|\n",
       "|null| 2020-01-04|     2020|         1|         1|    0|  Bronx|\n",
       "|null| 2020-01-04|     2020|         1|         1|    0|  Bronx|\n",
       "|null| 2020-01-04|     2020|         1|         1|    0|  Bronx|\n",
       "|null| 2020-01-04|     2020|         1|         1|    0|  Bronx|\n",
       "+----+-----------+---------+----------+----------+-----+-------+"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check that dates of weeks are correctly added/derived\n",
    "covid_df.sort('week_index', 'date').limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned covid data\n",
    "covid_df.write.mode('overwrite').parquet(f'{DATA_PATH}/curated/virals/covid/cleaned/cases_by_day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cleaning the flu dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Season</th><th>Region</th><th>County</th><th>CDC Week</th><th>Week Ending Date</th><th>Disease</th><th>Count</th><th>County Centroid</th><th>FIPS</th></tr>\n",
       "<tr><td>2012-2013</td><td>NYC</td><td>RICHMOND</td><td>10</td><td>03/09/2013</td><td>INFLUENZA_A</td><td>0</td><td>(40.5795, -74.1502)</td><td>36085</td></tr>\n",
       "<tr><td>2011-2012</td><td>CAPITAL DISTRICT</td><td>ALBANY</td><td>10</td><td>03/10/2012</td><td>INFLUENZA_UNSPECI...</td><td>0</td><td>(42.5882713, -73....</td><td>36001</td></tr>\n",
       "<tr><td>2009-2010</td><td>CAPITAL DISTRICT</td><td>SCHENECTADY</td><td>41</td><td>10/17/2009</td><td>INFLUENZA_UNSPECI...</td><td>0</td><td>(42.8175421, -74....</td><td>36093</td></tr>\n",
       "<tr><td>2010-2011</td><td>WESTERN</td><td>CHAUTAUQUA</td><td>19</td><td>05/14/2011</td><td>INFLUENZA_B</td><td>0</td><td>(42.3042159, -79....</td><td>36013</td></tr>\n",
       "<tr><td>2013-2014</td><td>METRO</td><td>DUTCHESS</td><td>44</td><td>11/02/2013</td><td>INFLUENZA_A</td><td>0</td><td>(41.7550085, -73....</td><td>36027</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+----------------+-----------+--------+----------------+--------------------+-----+--------------------+-----+\n",
       "|   Season|          Region|     County|CDC Week|Week Ending Date|             Disease|Count|     County Centroid| FIPS|\n",
       "+---------+----------------+-----------+--------+----------------+--------------------+-----+--------------------+-----+\n",
       "|2012-2013|             NYC|   RICHMOND|      10|      03/09/2013|         INFLUENZA_A|    0| (40.5795, -74.1502)|36085|\n",
       "|2011-2012|CAPITAL DISTRICT|     ALBANY|      10|      03/10/2012|INFLUENZA_UNSPECI...|    0|(42.5882713, -73....|36001|\n",
       "|2009-2010|CAPITAL DISTRICT|SCHENECTADY|      41|      10/17/2009|INFLUENZA_UNSPECI...|    0|(42.8175421, -74....|36093|\n",
       "|2010-2011|         WESTERN| CHAUTAUQUA|      19|      05/14/2011|         INFLUENZA_B|    0|(42.3042159, -79....|36013|\n",
       "|2013-2014|           METRO|   DUTCHESS|      44|      11/02/2013|         INFLUENZA_A|    0|(41.7550085, -73....|36027|\n",
       "+---------+----------------+-----------+--------+----------------+--------------------+-----+--------------------+-----+"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the flu dataset\n",
    "flu_df = spark.read.csv(f'{DATA_PATH}/raw/virals/flu/cases_by_week.csv',\n",
    "    header=True, inferSchema=True)\n",
    "flu_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>County</th></tr>\n",
       "<tr><td>FULTON</td></tr>\n",
       "<tr><td>CATTARAUGUS</td></tr>\n",
       "<tr><td>STEUBEN</td></tr>\n",
       "<tr><td>YATES</td></tr>\n",
       "<tr><td>KINGS</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+\n",
       "|     County|\n",
       "+-----------+\n",
       "|     FULTON|\n",
       "|CATTARAUGUS|\n",
       "|    STEUBEN|\n",
       "|      YATES|\n",
       "|      KINGS|\n",
       "+-----------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the list of distinct counties (column now called 'borough')\n",
    "flu_df.select('County').distinct().limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the boroughs to their proper names\n",
    "# from: https://portal.311.nyc.gov/article/?kanumber=KA-02877\n",
    "# also from map dict\n",
    "FLU_COUNTY_TO_BOROUGH = {\n",
    "    'BRONX': 'Bronx',\n",
    "    'KINGS': 'Brooklyn',\n",
    "    'NEW YORK': 'Manhattan',\n",
    "    'QUEENS': 'Queens',\n",
    "    'RICHMOND': 'Staten Island'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the mapping to the flu df\n",
    "flu_df = ch.replace_column_using_dict(flu_df, 'County', FLU_COUNTY_TO_BOROUGH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to rename all the columns I want to keep\n",
    "FLU_KEEP_COLUMNS = {\n",
    "    'Week Ending Date': 'date',\n",
    "    'County': 'borough',\n",
    "    'Disease': 'disease',\n",
    "    'Count': 'cases',\n",
    "}\n",
    "\n",
    "# create a dictionary of the columns to keep and the required filters\n",
    "FLU_CLEAN_COLUMNS = {\n",
    "    'date': [],\n",
    "    'region': [lambda _: F.col('region') == 'NYC'],\n",
    "    'borough': [],\n",
    "    'disease': [],\n",
    "    'cases': [ch.non_negative]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the drawn out cleaning process (function in `scripts/helpers`)\n",
    "flu_df = ch.perform_cleaning(flu_df, mmwr_weeks_df, FLU_KEEP_COLUMNS, \n",
    "    FLU_CLEAN_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the null cases (created from the one-sided outer join for the df) with 0\n",
    "flu_df = flu_df.fillna(0, 'cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>month</th><th>day</th><th>week_ending</th><th>week_year</th><th>week_month</th><th>week_index</th><th>date</th><th>borough</th><th>disease</th><th>cases</th></tr>\n",
       "<tr><td>2019</td><td>12</td><td>29</td><td>2020-01-04</td><td>2020</td><td>1</td><td>1</td><td>null</td><td>Bronx</td><td>null</td><td>0</td></tr>\n",
       "<tr><td>2019</td><td>12</td><td>30</td><td>2020-01-04</td><td>2020</td><td>1</td><td>1</td><td>null</td><td>Bronx</td><td>null</td><td>0</td></tr>\n",
       "<tr><td>2019</td><td>12</td><td>31</td><td>2020-01-04</td><td>2020</td><td>1</td><td>1</td><td>null</td><td>Bronx</td><td>null</td><td>0</td></tr>\n",
       "<tr><td>2020</td><td>1</td><td>1</td><td>2020-01-04</td><td>2020</td><td>1</td><td>1</td><td>null</td><td>Bronx</td><td>null</td><td>0</td></tr>\n",
       "<tr><td>2020</td><td>1</td><td>2</td><td>2020-01-04</td><td>2020</td><td>1</td><td>1</td><td>null</td><td>Bronx</td><td>null</td><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-----+---+-----------+---------+----------+----------+----+-------+-------+-----+\n",
       "|year|month|day|week_ending|week_year|week_month|week_index|date|borough|disease|cases|\n",
       "+----+-----+---+-----------+---------+----------+----------+----+-------+-------+-----+\n",
       "|2019|   12| 29| 2020-01-04|     2020|         1|         1|null|  Bronx|   null|    0|\n",
       "|2019|   12| 30| 2020-01-04|     2020|         1|         1|null|  Bronx|   null|    0|\n",
       "|2019|   12| 31| 2020-01-04|     2020|         1|         1|null|  Bronx|   null|    0|\n",
       "|2020|    1|  1| 2020-01-04|     2020|         1|         1|null|  Bronx|   null|    0|\n",
       "|2020|    1|  2| 2020-01-04|     2020|         1|         1|null|  Bronx|   null|    0|\n",
       "+----+-----+---+-----------+---------+----------+----------+----+-------+-------+-----+"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that converting the boroughs worked\n",
    "flu_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned flu data\n",
    "flu_df.write.mode('overwrite').parquet(f'{DATA_PATH}/curated/virals/flu/cleaned/cases_by_week')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
