{"cells":[{"cell_type":"markdown","metadata":{},"source":["### MAST30034: Applied Data Science Project 1\n","---\n","# Preprocessing Part 2: Aggregating Data by MMWR Week\n","#### Xavier Travers (1178369)\n","\n","Aggregate all the data by MMWR week (defined [here](https://ndc.services.cdc.gov/wp-content/uploads/MMWR_Week_overview.pdf)).\n","This means counting trips to and from each of the boroughs per month.\n","This is done for each of the taxi types."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# imports used throughout this notebook\n","from pyspark.sql import DataFrame\n","from pyspark.sql import functions as F\n","import os\n","import sys\n","import re\n","from itertools import chain\n","\n","# add homemade helpers\n","sys.path.insert(1, '../scripts')\n","import helpers.aggregation_helpers as ah\n","\n","# for printouts\n","DEBUGGING = True"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["22/08/09 01:03:10 WARN Utils: Your hostname, Polaris resolves to a loopback address: 127.0.1.1; using 172.20.95.79 instead (on interface eth0)\n","22/08/09 01:03:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"]},{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"]},{"name":"stdout","output_type":"stream","text":["22/08/09 01:03:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","22/08/09 01:03:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"]}],"source":["from pyspark.sql import SparkSession\n","\n","# Create a spark session (which will run spark jobs)\n","spark = (\n","    SparkSession.builder.appName('MAST30034 XT Project 1')\n","    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n","    .config('spark.sql.repl.eagerEval.enabled', True) \n","    .config('spark.sql.parquet.cacheMetadata', 'true')\n","    .getOrCreate()\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<table border='1'>\n","<tr><th>OBJECTID</th><th>Shape_Leng</th><th>the_geom</th><th>Shape_Area</th><th>zone</th><th>LocationID</th><th>borough</th></tr>\n","<tr><td>1</td><td>0.116357453189</td><td>MULTIPOLYGON (((-...</td><td>0.0007823067885</td><td>Newark Airport</td><td>1</td><td>EWR</td></tr>\n","<tr><td>2</td><td>0.43346966679</td><td>MULTIPOLYGON (((-...</td><td>0.00486634037837</td><td>Jamaica Bay</td><td>2</td><td>Queens</td></tr>\n","<tr><td>3</td><td>0.0843411059012</td><td>MULTIPOLYGON (((-...</td><td>0.000314414156821</td><td>Allerton/Pelham G...</td><td>3</td><td>Bronx</td></tr>\n","<tr><td>4</td><td>0.0435665270921</td><td>MULTIPOLYGON (((-...</td><td>0.000111871946192</td><td>Alphabet City</td><td>4</td><td>Manhattan</td></tr>\n","<tr><td>5</td><td>0.0921464898574</td><td>MULTIPOLYGON (((-...</td><td>0.000497957489363</td><td>Arden Heights</td><td>5</td><td>Staten Island</td></tr>\n","</table>\n"],"text/plain":["+--------+---------------+--------------------+-----------------+--------------------+----------+-------------+\n","|OBJECTID|     Shape_Leng|            the_geom|       Shape_Area|                zone|LocationID|      borough|\n","+--------+---------------+--------------------+-----------------+--------------------+----------+-------------+\n","|       1| 0.116357453189|MULTIPOLYGON (((-...|  0.0007823067885|      Newark Airport|         1|          EWR|\n","|       2|  0.43346966679|MULTIPOLYGON (((-...| 0.00486634037837|         Jamaica Bay|         2|       Queens|\n","|       3|0.0843411059012|MULTIPOLYGON (((-...|0.000314414156821|Allerton/Pelham G...|         3|        Bronx|\n","|       4|0.0435665270921|MULTIPOLYGON (((-...|0.000111871946192|       Alphabet City|         4|    Manhattan|\n","|       5|0.0921464898574|MULTIPOLYGON (((-...|0.000497957489363|       Arden Heights|         5|Staten Island|\n","+--------+---------------+--------------------+-----------------+--------------------+----------+-------------+"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# read in the taxi zones dataset\n","zones_df = spark.read.csv('../data/raw/tlc_zones/zones.csv',\n","    header = True)\n","zones_df.limit(5)"]},{"cell_type":"markdown","metadata":{},"source":["### 1. Aggregating the TLC dataset"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# TODO: commenting\n","TLC_NAMES = ['yellow']"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["240824104 ROWS\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 105:====================================================>(305 + 3) / 308]\r"]},{"name":"stdout","output_type":"stream","text":["+----+-----+---+----------+--------+----------+----------+-------------+--------------+--------------+\n","|year|month|day|week_index|cdc_week|      date|passengers|trip_distance|pu_location_id|do_location_id|\n","+----+-----+---+----------+--------+----------+----------+-------------+--------------+--------------+\n","|2018|    1|  1|         1|       1|01/01/2018|       1.0|          0.5|            41|            24|\n","|2018|    1|  1|         1|       1|01/01/2018|       1.0|          2.7|           239|           140|\n","|2018|    1|  1|         1|       1|01/01/2018|       2.0|          0.8|           262|           141|\n","|2018|    1|  1|         1|       1|01/01/2018|       1.0|         10.2|           140|           257|\n","|2018|    1|  1|         1|       1|01/01/2018|       2.0|          2.5|           246|           239|\n","+----+-----+---+----------+--------+----------+----------+-------------+--------------+--------------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# read in the yellow dataset# TODO: commenting\n","tlc_df = None\n","for filename in os.listdir(f'../data/curated/tlc/cleaned/yellow'):\n","    if tlc_df == None:\n","        tlc_df = spark.read.parquet(f'../data/curated/tlc/cleaned/yellow/{filename}')\n","    else:\n","        tlc_df = tlc_df.union(\n","            spark.read.parquet(f'../data/curated/tlc/cleaned/yellow/{filename}')\n","        )\n","\n","print(f'{tlc_df.count()} ROWS')\n","print(tlc_df.limit(5))\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# join the yellow dataset with the taxi zones dataset\n","tlc_colnames = tlc_df.columns\n","tlc_df = ah.extract_borough_name(tlc_df, zones_df, 'pu_location_id', 'pu')\n","tlc_df = ah.extract_borough_name(tlc_df, zones_df, 'do_location_id', 'do')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["TLC_GROUP_COLUMNS = [\n","    'year',\n","    'cdc_week',\n","    'week_index',\n","    'pu_borough',\n","    'do_borough',\n","    'passengers'\n","]\n","# TODO: commenting\n","TLC_AGGREGATE_COLUMNS = {\n","    '*': ['count'],\n","    'trip_distance': ['total', 'average'],\n","}"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["tlc_df = ah.group_and_aggregate(tlc_df, TLC_GROUP_COLUMNS, \n","    TLC_AGGREGATE_COLUMNS)\n","# TODO: commenting\n","# force this into memory \n","# otherwise writing parquets results in a java executor out of memory error\n","tlc_df = spark.createDataFrame(tlc_df.collect())"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<table border='1'>\n","<tr><th>year</th><th>cdc_week</th><th>week_index</th><th>pu_borough</th><th>do_borough</th><th>passengers</th><th>num_*</th><th>tot_trip_distance</th><th>avg_trip_distance</th></tr>\n","<tr><td>2017</td><td>1</td><td>1</td><td>Queens</td><td>Brooklyn</td><td>1.0</td><td>1</td><td>11.91</td><td>11.91</td></tr>\n","<tr><td>2018</td><td>1</td><td>1</td><td>Queens</td><td>Staten Island</td><td>2.0</td><td>14</td><td>346.01000000000005</td><td>24.715000000000003</td></tr>\n","<tr><td>2017</td><td>1</td><td>1</td><td>Manhattan</td><td>Brooklyn</td><td>4.0</td><td>2</td><td>10.219999999999999</td><td>5.109999999999999</td></tr>\n","<tr><td>2018</td><td>1</td><td>1</td><td>Queens</td><td>Bronx</td><td>2.0</td><td>311</td><td>4892.789999999997</td><td>15.732443729903528</td></tr>\n","<tr><td>2018</td><td>1</td><td>1</td><td>Manhattan</td><td>Staten Island</td><td>5.0</td><td>11</td><td>200.72</td><td>18.247272727272726</td></tr>\n","</table>\n"],"text/plain":["+----+--------+----------+----------+-------------+----------+-----+------------------+------------------+\n","|year|cdc_week|week_index|pu_borough|   do_borough|passengers|num_*| tot_trip_distance| avg_trip_distance|\n","+----+--------+----------+----------+-------------+----------+-----+------------------+------------------+\n","|2017|       1|         1|    Queens|     Brooklyn|       1.0|    1|             11.91|             11.91|\n","|2018|       1|         1|    Queens|Staten Island|       2.0|   14|346.01000000000005|24.715000000000003|\n","|2017|       1|         1| Manhattan|     Brooklyn|       4.0|    2|10.219999999999999| 5.109999999999999|\n","|2018|       1|         1|    Queens|        Bronx|       2.0|  311| 4892.789999999997|15.732443729903528|\n","|2018|       1|         1| Manhattan|Staten Island|       5.0|   11|            200.72|18.247272727272726|\n","+----+--------+----------+----------+-------------+----------+-----+------------------+------------------+"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["tlc_df.sort('week_index').limit(5)\n","# TODO: commenting"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 92.12% for 8 writers\n","22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 81.89% for 9 writers\n","22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 73.70% for 10 writers\n","22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 67.00% for 11 writers\n","22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 61.42% for 12 writers\n","22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 56.69% for 13 writers\n","22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 52.64% for 14 writers\n","22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 49.13% for 15 writers\n","22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 46.06% for 16 writers\n","22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 49.13% for 15 writers\n","22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 52.64% for 14 writers\n","22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 56.69% for 13 writers\n","22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 61.42% for 12 writers\n","22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 67.00% for 11 writers\n","22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 73.70% for 10 writers\n","22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 81.89% for 9 writers\n","22/08/09 01:04:22 WARN MemoryManager: Total allocation exceeds 95.00% (989,174,157 bytes) of heap memory\n","Scaling row group sizes to 92.12% for 8 writers\n"]}],"source":["tlc_df.write.mode('overwrite').parquet('../data/curated/tlc/aggregated/yellow')\n","# TODO: commenting"]},{"cell_type":"markdown","metadata":{},"source":["### 2. Aggregating the COVID dataset"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<table border='1'>\n","<tr><th>date</th><th>year</th><th>cdc_week</th><th>week_index</th><th>cases</th><th>deaths</th><th>hospitalised</th><th>borough</th></tr>\n","<tr><td>02/29/2020</td><td>2020</td><td>9</td><td>113</td><td>1</td><td>0</td><td>1</td><td>Overall</td></tr>\n","<tr><td>03/01/2020</td><td>2020</td><td>10</td><td>114</td><td>0</td><td>0</td><td>1</td><td>Overall</td></tr>\n","<tr><td>03/02/2020</td><td>2020</td><td>10</td><td>114</td><td>0</td><td>0</td><td>2</td><td>Overall</td></tr>\n","<tr><td>03/03/2020</td><td>2020</td><td>10</td><td>114</td><td>1</td><td>0</td><td>7</td><td>Overall</td></tr>\n","<tr><td>03/04/2020</td><td>2020</td><td>10</td><td>114</td><td>5</td><td>0</td><td>2</td><td>Overall</td></tr>\n","</table>\n"],"text/plain":["+----------+----+--------+----------+-----+------+------------+-------+\n","|      date|year|cdc_week|week_index|cases|deaths|hospitalised|borough|\n","+----------+----+--------+----------+-----+------+------------+-------+\n","|02/29/2020|2020|       9|       113|    1|     0|           1|Overall|\n","|03/01/2020|2020|      10|       114|    0|     0|           1|Overall|\n","|03/02/2020|2020|      10|       114|    0|     0|           2|Overall|\n","|03/03/2020|2020|      10|       114|    1|     0|           7|Overall|\n","|03/04/2020|2020|      10|       114|    5|     0|           2|Overall|\n","+----------+----+--------+----------+-----+------+------------+-------+"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# read in the covid dataset\n","covid_df = spark.read.parquet('../data/curated/virals/covid/cases-by-day')\n","covid_df.limit(5)\n","# TODO: commenting"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["COVID_GROUP_COLUMNS = [\n","    'year',\n","    'cdc_week',\n","    'week_index',\n","    'borough'\n","]\n","# TODO: commenting\n","COVID_AGGREGATE_COLUMNS = {\n","    'cases': ['total', 'average'],\n","    'deaths': ['total', 'average'],\n","    'hospitalised': ['total', 'average'],\n","}"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["covid_df = ah.group_and_aggregate(covid_df, COVID_GROUP_COLUMNS, \n","    COVID_AGGREGATE_COLUMNS)\n","\n","# force this into memory \n","# otherwise writing parquets results in a java executor out of memory error\n","covid_df = spark.createDataFrame(covid_df.collect())\n","# TODO: commenting"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/html":["<table border='1'>\n","<tr><th>year</th><th>cdc_week</th><th>week_index</th><th>borough</th><th>tot_cases</th><th>avg_cases</th><th>tot_deaths</th><th>avg_deaths</th><th>tot_hospitalised</th><th>avg_hospitalised</th></tr>\n","<tr><td>2020</td><td>9</td><td>113</td><td>Overall</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td></tr>\n","<tr><td>2020</td><td>9</td><td>113</td><td>Brooklyn</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td></tr>\n","<tr><td>2020</td><td>9</td><td>113</td><td>Manhattan</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n","<tr><td>2020</td><td>9</td><td>113</td><td>Queens</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n","<tr><td>2020</td><td>9</td><td>113</td><td>Bronx</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n","</table>\n"],"text/plain":["+----+--------+----------+---------+---------+---------+----------+----------+----------------+----------------+\n","|year|cdc_week|week_index|  borough|tot_cases|avg_cases|tot_deaths|avg_deaths|tot_hospitalised|avg_hospitalised|\n","+----+--------+----------+---------+---------+---------+----------+----------+----------------+----------------+\n","|2020|       9|       113|  Overall|      1.0|      1.0|       0.0|       0.0|             1.0|             1.0|\n","|2020|       9|       113| Brooklyn|      0.0|      0.0|       0.0|       0.0|             1.0|             1.0|\n","|2020|       9|       113|Manhattan|      1.0|      1.0|       0.0|       0.0|             0.0|             0.0|\n","|2020|       9|       113|   Queens|      0.0|      0.0|       0.0|       0.0|             0.0|             0.0|\n","|2020|       9|       113|    Bronx|      0.0|      0.0|       0.0|       0.0|             0.0|             0.0|\n","+----+--------+----------+---------+---------+---------+----------+----------+----------------+----------------+"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["covid_df.sort('week_index').limit(5)\n","# TODO: commenting"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# save it\n","# TODO: commenting\n","covid_df.write.mode('overwrite').parquet('../data/curated/virals/covid/cases-by-week')"]},{"cell_type":"markdown","metadata":{},"source":["### 3. Aggregating the Flu dataset\n","*Nothing is done here, since the flu dataset is already grouped by MMWR week.*"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":2}
