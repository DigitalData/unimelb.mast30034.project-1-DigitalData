{"cells":[{"cell_type":"markdown","metadata":{},"source":["### MAST30034: Applied Data Science Project 1\n","---\n","# Aggregating TLC Data\n","#### Xavier Travers (1178369)\n","\n","Aggregate the TLC data by month.\n","This means counting trips to and from each of the boroughs per month.\n","This is done for each of the taxi types."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# imports used throughout this notebook\n","from pyspark.sql import DataFrame\n","from pyspark.sql import functions as F\n","import os\n","import re\n","from itertools import chain"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["22/07/31 01:06:05 WARN Utils: Your hostname, Polaris resolves to a loopback address: 127.0.1.1; using 192.168.153.180 instead (on interface eth0)\n","22/07/31 01:06:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"]},{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"]},{"name":"stdout","output_type":"stream","text":["22/07/31 01:06:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","22/07/31 01:06:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n","22/07/31 01:06:06 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"]}],"source":["from pyspark.sql import SparkSession\n","\n","# Create a spark session (which will run spark jobs)\n","spark = (\n","    SparkSession.builder.appName('MAST30034 XT Project 1')\n","    .config('spark.sql.repl.eagerEval.enabled', True) \n","    .config('spark.sql.parquet.cacheMetadata', 'true')\n","    .getOrCreate()\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# read in the taxi zones dataset\n","zones_df = spark.read.parquet('../data/raw/tlc_zones/zones')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def prefix_column_names(df: DataFrame, prefix: str) -> DataFrame:\n","    \"\"\" Add a prefix to the columns names of a `DataFrame`.\n","\n","    Args:\n","    - df (`DataFrame`): The `DataFrame` for which to add prefixes\n","    - prefix (str): The prefix\n","\n","    Returns:\n","        `DataFrame`: The modified `DataFrame`\n","    \"\"\"\n","\n","    out_df = df\n","    for col in df.columns:\n","        out_df = out_df.withColumnRenamed(col, prefix + col)\n","    return out_df"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# define the tlc dataset names\n","TLC_NAMES = ['yellow', 'green', 'fhv', 'fhvhv']"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def add_borough_names(df: DataFrame) -> DataFrame:\n","    location_id_colname = 'LocationID'\n","\n","    required_zone_colnames = [\n","        'LocationID',\n","        'borough',\n","        'zone']\n","\n","    out_df = df\n","    for prefix in ['PU', 'DO']:\n","        out_df = out_df.join(\n","            prefix_column_names(zones_df.select(\n","                required_zone_colnames), prefix),\n","            on=prefix + location_id_colname,\n","            how='inner'\n","        )\n","\n","    return out_df\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["OUT_COL_NAMES = [\n","    'year', # year group\n","    'month', # month group\n","    'type', # taxi type group\n","    'PUborough', # pickup borough group\n","    'DOborough', # dropoff borough group\n","    # grouping by sharing configuration \n","    'shared', # (bool for fhvhv and #passengers for yellow/green)\n","    'total_trips', # total trips in the group \n","    'avg_distance', # avg distance\n","]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def aggregate_trips_green_yellow(df: DataFrame, year:int, month:int, taxi_type:str) -> DataFrame:\n","    join_selections = ['PULocationID', 'DOLocationID', 'passenger_count', 'trip_distance']\n","    joined_df = df\\\n","        .select(join_selections)\\\n","        .join(prefix_column_names(zones_df, 'PU'), 'PULocationID', 'inner')\\\n","        .join(prefix_column_names(zones_df, 'DO'), 'DOLocationID', 'inner')\n","\n","    group_filters = ['PUborough', 'DOborough', 'passenger_count']\n","    grouped_df = joined_df.groupBy(group_filters)\n","    group_counts = grouped_df.count().collect()\n","    group_avg_distances = grouped_df.avg('trip_distance').collect()\n","    group_row_lists = [group_counts, group_avg_distances]\n","\n","    out_df = None\n","    for row_list in group_row_lists:\n","        temp_df = spark.createDataFrame(row_list)\n","        if(out_df == None):\n","            out_df = temp_df\n","        else:\n","            out_df = out_df\\\n","                .join(temp_df, group_filters, 'inner')\n","\n","    return out_df\\\n","        .withColumn('type', F.lit(taxi_type))\\\n","        .withColumn('year', F.lit(year))\\\n","        .withColumn('month', F.lit(month))\\\n","        .withColumnRenamed('count', 'total_trips')\\\n","        .withColumnRenamed('passenger_count', 'shared')\\\n","        .withColumnRenamed('avg(trip_distance)', 'avg_distance')\\\n","        .select(OUT_COL_NAMES)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def aggregate_trips_fhvhv(df: DataFrame, year:int, month:int) -> DataFrame:\n","    join_selections = ['PULocationID', 'DOLocationID', 'shared_request_flag', 'trip_miles', 'hvfhs_license_num']\n","    joined_df = df\\\n","        .select(join_selections)\\\n","        .join(prefix_column_names(zones_df, 'PU'), 'PULocationID', 'inner')\\\n","        .join(prefix_column_names(zones_df, 'DO'), 'DOLocationID', 'inner')\n","\n","    group_filters = ['PUborough', 'DOborough', 'hvfhs_license_num', 'shared_request_flag']\n","    grouped_df = joined_df.groupBy(group_filters)\n","    group_counts = grouped_df.count().collect()\n","    group_avg_sums = grouped_df.sum('trip_miles').collect()\n","    group_avg_distances = grouped_df.avg('trip_miles').collect()\n","    group_row_lists = [group_counts, group_avg_sums, group_avg_distances]\n","\n","    out_df = None\n","    for row_list in group_row_lists:\n","        temp_df = spark.createDataFrame(row_list)\n","        if(out_df == None):\n","            out_df = temp_df\n","        else:\n","            out_df = out_df\\\n","                .join(temp_df, group_filters, 'inner')\n","\n","    licenses_dict = {\n","        'HV0002': 'juno',\n","        'HV0003': 'uber',\n","        'HV0004': 'via',\n","        'HV0005': 'lyft'\n","    }\n","\n","    # from: https://stackoverflow.com/questions/42980704/pyspark-create-new-column-with-mapping-from-a-dict\n","    license_mapping_expr = F.create_map([F.lit(x) for x in chain(*licenses_dict.items())])\n","\n","    flags_dict = {\n","        'Y': 1.0,\n","        'N': 0.0\n","    }\n","\n","    # from: https://stackoverflow.com/questions/42980704/pyspark-create-new-column-with-mapping-from-a-dict\n","    flag_mapping_expr = F.create_map([F.lit(x) for x in chain(*flags_dict.items())])\n","\n","    return out_df\\\n","        .withColumn('year', F.lit(year))\\\n","        .withColumn('month', F.lit(month))\\\n","        .withColumn('type', license_mapping_expr[F.col('hvfhs_license_num')])\\\n","        .withColumn('shared', flag_mapping_expr[F.col('shared_request_flag')])\\\n","        .withColumnRenamed('count', 'total_trips')\\\n","        .withColumnRenamed('avg(trip_miles)', 'avg_distance')\\\n","        .select(OUT_COL_NAMES)\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def aggregate_trips(df: DataFrame, year:int, month:int, taxi_type: str) -> DataFrame:\n","    if taxi_type == 'fhvhv':\n","        return aggregate_trips_fhvhv(df, year, month)\n","    return aggregate_trips_green_yellow(df, year, month, taxi_type)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'tlc_yellow_df' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/mnt/c/Users/Xavier Travers/Desktop/Uni/ADS/mast30034-project-1-DigitalData/notebooks/preprocessing_part_3_aggregation.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Xavier%20Travers/Desktop/Uni/ADS/mast30034-project-1-DigitalData/notebooks/preprocessing_part_3_aggregation.ipynb#ch0000019vscode-remote?line=0'>1</a>\u001b[0m aggregate_trips_green_yellow(tlc_yellow_df, \u001b[39m2019\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m'\u001b[39m\u001b[39myellow\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mlimit(\u001b[39m5\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'tlc_yellow_df' is not defined"]}],"source":["aggregate_trips_green_yellow(tlc_yellow_df, 2019, 6, 'yellow').limit(5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/html":["<table border='1'>\n","<tr><th>year</th><th>month</th><th>type</th><th>PUborough</th><th>DOborough</th><th>shared</th><th>total_trips</th><th>avg_distance</th></tr>\n","<tr><td>2019</td><td>6</td><td>uber</td><td>Manhattan</td><td>Manhattan</td><td>0.0</td><td>3875134</td><td>2.5829985801779927</td></tr>\n","<tr><td>2019</td><td>6</td><td>juno</td><td>Staten Island</td><td>Brooklyn</td><td>0.0</td><td>488</td><td>11.244057377049181</td></tr>\n","<tr><td>2019</td><td>6</td><td>via</td><td>Queens</td><td>Brooklyn</td><td>1.0</td><td>7666</td><td>7.53632663709886</td></tr>\n","<tr><td>2019</td><td>6</td><td>lyft</td><td>Brooklyn</td><td>Brooklyn</td><td>0.0</td><td>897851</td><td>2.7321963042865622</td></tr>\n","<tr><td>2019</td><td>6</td><td>lyft</td><td>Manhattan</td><td>Bronx</td><td>0.0</td><td>67456</td><td>6.804377875948789</td></tr>\n","</table>\n"],"text/plain":["+----+-----+----+-------------+---------+------+-----------+------------------+\n","|year|month|type|    PUborough|DOborough|shared|total_trips|      avg_distance|\n","+----+-----+----+-------------+---------+------+-----------+------------------+\n","|2019|    6|uber|    Manhattan|Manhattan|   0.0|    3875134|2.5829985801779927|\n","|2019|    6|juno|Staten Island| Brooklyn|   0.0|        488|11.244057377049181|\n","|2019|    6| via|       Queens| Brooklyn|   1.0|       7666|  7.53632663709886|\n","|2019|    6|lyft|     Brooklyn| Brooklyn|   0.0|     897851|2.7321963042865622|\n","|2019|    6|lyft|    Manhattan|    Bronx|   0.0|      67456| 6.804377875948789|\n","+----+-----+----+-------------+---------+------+-----------+------------------+"]},"execution_count":106,"metadata":{},"output_type":"execute_result"}],"source":["aggregate_trips_fhvhv(tlc_fhvhv_df, 2019, 6).limit(5)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","AGGREGATING \"green\" DATA\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["3180\n","\n","AGGREGATING \"yellow\" DATA\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["4284\n","\n","AGGREGATING \"fhvhv\" DATA\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["3626\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["11090\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 89.06% for 8 writers\n","22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 79.17% for 9 writers\n","22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 71.25% for 10 writers\n","22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 64.77% for 11 writers\n","22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 59.37% for 12 writers\n","22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 54.81% for 13 writers\n","22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 50.89% for 14 writers\n","22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 47.50% for 15 writers\n","22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 44.53% for 16 writers\n","22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 47.50% for 15 writers\n","22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 50.89% for 14 writers\n","22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 54.81% for 13 writers\n","22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 59.37% for 12 writers\n","22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 64.77% for 11 writers\n","22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 71.25% for 10 writers\n","22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 79.17% for 9 writers\n","22/07/31 01:17:51 WARN MemoryManager: Total allocation exceeds 95.00% (956,301,300 bytes) of heap memory\n","Scaling row group sizes to 89.06% for 8 writers\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["TLC_NAMES = ['green', 'yellow', 'fhvhv']\n","aggregated_df = None\n","\n","for name in TLC_NAMES:\n","    print(f'\\nAGGREGATING \"{name}\" DATA')\n","    temp_df = None\n","    for filename in os.listdir(f'../data/raw/tlc/{name}'):\n","        tlc_df = spark.read.parquet(f'../data/raw/tlc/{name}/{filename}')\n","        filedata = re.split(r'[-.]', filename)\n","        if temp_df == None:\n","            temp_df = aggregate_trips(tlc_df, int(filedata[0]), int(filedata[1]), name)\n","        else:\n","            temp_df = temp_df.union(aggregate_trips(tlc_df, int(filedata[0]), int(filedata[1]), name))\n","    print(temp_df.count())\n","\n","    if aggregated_df == None:\n","        aggregated_df = temp_df\n","    else:\n","        aggregated_df = aggregated_df.union(temp_df)\n","\n","print(aggregated_df.count())\n","aggregated_df.limit(20)\n","\n","# save the aggregated data\n","aggregated_df.write.mode('overwrite').parquet('../data/curated/tlc/aggregated')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":2}
