{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports used throughout this notebook\n",
    "from pyspark.sql import DataFrame, Column, Window\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add homemade helpers\n",
    "sys.path.insert(1, '../../scripts')\n",
    "import helpers.join_helpers as jh\n",
    "import helpers.plot_helpers as ph\n",
    "\n",
    "# path where the data files are stored\n",
    "DATA_PATH = '../../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/16 23:45:18 WARN Utils: Your hostname, Polaris resolves to a loopback address: 127.0.1.1; using 172.22.169.117 instead (on interface eth0)\n",
      "22/08/16 23:45:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/16 23:45:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName('MAST30034 XT Project 1')\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config('spark.sql.repl.eagerEval.enabled', True) \n",
    "    .config('spark.sql.parquet.cacheMetadata', 'true')\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>week_year</th><th>week_month</th><th>week_ending</th><th>week_index</th><th>timeline</th><th>borough</th><th>population</th><th>tot_cases</th><th>tot_pc_cases</th><th>tot_p100k_cases</th></tr>\n",
       "<tr><td>2021</td><td>12</td><td>2022-01-01</td><td>209</td><td>0</td><td>Staten Island</td><td>493494.0</td><td>18157.0</td><td>0.03679274722691664</td><td>3679.274722691664</td></tr>\n",
       "<tr><td>2021</td><td>5</td><td>2021-05-29</td><td>178</td><td>2</td><td>Staten Island</td><td>493494.0</td><td>177.0</td><td>3.586669746744641...</td><td>35.866697467446414</td></tr>\n",
       "<tr><td>2020</td><td>4</td><td>2020-04-04</td><td>118</td><td>1</td><td>Staten Island</td><td>495522.0</td><td>2188.0</td><td>0.004415545626632118</td><td>441.5545626632117</td></tr>\n",
       "<tr><td>2020</td><td>7</td><td>2020-07-25</td><td>134</td><td>2</td><td>Staten Island</td><td>495522.0</td><td>158.0</td><td>3.188556713929956...</td><td>31.885567139299567</td></tr>\n",
       "<tr><td>2021</td><td>3</td><td>2021-03-13</td><td>167</td><td>2</td><td>Staten Island</td><td>493494.0</td><td>1532.0</td><td>0.003104394379668...</td><td>310.4394379668243</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+----------+-----------+----------+--------+-------------+----------+---------+--------------------+------------------+\n",
       "|week_year|week_month|week_ending|week_index|timeline|      borough|population|tot_cases|        tot_pc_cases|   tot_p100k_cases|\n",
       "+---------+----------+-----------+----------+--------+-------------+----------+---------+--------------------+------------------+\n",
       "|     2021|        12| 2022-01-01|       209|       0|Staten Island|  493494.0|  18157.0| 0.03679274722691664| 3679.274722691664|\n",
       "|     2021|         5| 2021-05-29|       178|       2|Staten Island|  493494.0|    177.0|3.586669746744641...|35.866697467446414|\n",
       "|     2020|         4| 2020-04-04|       118|       1|Staten Island|  495522.0|   2188.0|0.004415545626632118| 441.5545626632117|\n",
       "|     2020|         7| 2020-07-25|       134|       2|Staten Island|  495522.0|    158.0|3.188556713929956...|31.885567139299567|\n",
       "|     2021|         3| 2021-03-13|       167|       2|Staten Island|  493494.0|   1532.0|0.003104394379668...| 310.4394379668243|\n",
       "+---------+----------+-----------+----------+--------+-------------+----------+---------+--------------------+------------------+"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the aggregated covid data\n",
    "covid_df = spark.read.parquet(f'{DATA_PATH}/curated/virals/covid/aggregated/cases_by_week')\n",
    "covid_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>week_year</th><th>week_month</th><th>week_ending</th><th>week_index</th><th>timeline</th><th>borough</th><th>population</th><th>tot_cases</th><th>tot_pc_cases</th><th>tot_p100k_cases</th></tr>\n",
       "<tr><td>2019</td><td>2</td><td>2019-02-16</td><td>59</td><td>1</td><td>Bronx</td><td>1418207.0</td><td>934.0</td><td>6.585780496077089E-4</td><td>65.85780496077089</td></tr>\n",
       "<tr><td>2019</td><td>1</td><td>2019-01-26</td><td>56</td><td>1</td><td>Bronx</td><td>1418207.0</td><td>857.0</td><td>6.042841418777372E-4</td><td>60.42841418777372</td></tr>\n",
       "<tr><td>2019</td><td>1</td><td>2019-01-12</td><td>54</td><td>1</td><td>Bronx</td><td>1418207.0</td><td>493.0</td><td>3.476220326087799...</td><td>34.762203260877996</td></tr>\n",
       "<tr><td>2019</td><td>11</td><td>2019-11-30</td><td>100</td><td>1</td><td>Bronx</td><td>1418207.0</td><td>217.0</td><td>1.530101036026475...</td><td>15.301010360264756</td></tr>\n",
       "<tr><td>2019</td><td>3</td><td>2019-03-16</td><td>63</td><td>1</td><td>Bronx</td><td>1418207.0</td><td>554.0</td><td>3.906340893818744...</td><td>39.06340893818744</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+----------+-----------+----------+--------+-------+----------+---------+--------------------+------------------+\n",
       "|week_year|week_month|week_ending|week_index|timeline|borough|population|tot_cases|        tot_pc_cases|   tot_p100k_cases|\n",
       "+---------+----------+-----------+----------+--------+-------+----------+---------+--------------------+------------------+\n",
       "|     2019|         2| 2019-02-16|        59|       1|  Bronx| 1418207.0|    934.0|6.585780496077089E-4| 65.85780496077089|\n",
       "|     2019|         1| 2019-01-26|        56|       1|  Bronx| 1418207.0|    857.0|6.042841418777372E-4| 60.42841418777372|\n",
       "|     2019|         1| 2019-01-12|        54|       1|  Bronx| 1418207.0|    493.0|3.476220326087799...|34.762203260877996|\n",
       "|     2019|        11| 2019-11-30|       100|       1|  Bronx| 1418207.0|    217.0|1.530101036026475...|15.301010360264756|\n",
       "|     2019|         3| 2019-03-16|        63|       1|  Bronx| 1418207.0|    554.0|3.906340893818744...| 39.06340893818744|\n",
       "+---------+----------+-----------+----------+--------+-------+----------+---------+--------------------+------------------+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the aggregated covid data\n",
    "flu_df = spark.read.parquet(f'{DATA_PATH}/curated/virals/flu/aggregated/cases_by_week')\n",
    "flu_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>week_year</th><th>week_month</th><th>week_ending</th><th>week_index</th><th>timeline</th><th>pu_borough</th><th>population</th><th>num_trips</th><th>num_pc_trips</th><th>num_p100k_trips</th><th>avg_passengers</th><th>avg_trip_distance</th></tr>\n",
       "<tr><td>2020</td><td>9</td><td>2020-09-19</td><td>142</td><td>2</td><td>Brooklyn</td><td>2727393.0</td><td>2290</td><td>8.396296389995868E-4</td><td>83.96296389995868</td><td>1.3458515283842796</td><td>2.9860742358078607</td></tr>\n",
       "<tr><td>2021</td><td>2</td><td>2021-02-20</td><td>164</td><td>2</td><td>Manhattan</td><td>1576876.0</td><td>291970</td><td>0.1851572349379406</td><td>18515.72349379406</td><td>1.4186286262287222</td><td>2.1355327944652136</td></tr>\n",
       "<tr><td>2020</td><td>9</td><td>2020-09-19</td><td>142</td><td>2</td><td>Staten Island</td><td>495522.0</td><td>39</td><td>7.870488091346096E-5</td><td>7.870488091346096</td><td>1.0</td><td>31.242307692307687</td></tr>\n",
       "<tr><td>2021</td><td>1</td><td>2021-01-09</td><td>158</td><td>2</td><td>Staten Island</td><td>493494.0</td><td>55</td><td>1.114501898705962E-4</td><td>11.14501898705962</td><td>1.0363636363636364</td><td>30.25254545454545</td></tr>\n",
       "<tr><td>2020</td><td>9</td><td>2020-09-26</td><td>143</td><td>2</td><td>Bronx</td><td>1466438.0</td><td>904</td><td>6.164597480425358E-4</td><td>61.64597480425357</td><td>1.3152654867256637</td><td>3.758019911504428</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+----------+-----------+----------+--------+-------------+----------+---------+--------------------+-----------------+------------------+------------------+\n",
       "|week_year|week_month|week_ending|week_index|timeline|   pu_borough|population|num_trips|        num_pc_trips|  num_p100k_trips|    avg_passengers| avg_trip_distance|\n",
       "+---------+----------+-----------+----------+--------+-------------+----------+---------+--------------------+-----------------+------------------+------------------+\n",
       "|     2020|         9| 2020-09-19|       142|       2|     Brooklyn| 2727393.0|     2290|8.396296389995868E-4|83.96296389995868|1.3458515283842796|2.9860742358078607|\n",
       "|     2021|         2| 2021-02-20|       164|       2|    Manhattan| 1576876.0|   291970|  0.1851572349379406|18515.72349379406|1.4186286262287222|2.1355327944652136|\n",
       "|     2020|         9| 2020-09-19|       142|       2|Staten Island|  495522.0|       39|7.870488091346096E-5|7.870488091346096|               1.0|31.242307692307687|\n",
       "|     2021|         1| 2021-01-09|       158|       2|Staten Island|  493494.0|       55|1.114501898705962E-4|11.14501898705962|1.0363636363636364| 30.25254545454545|\n",
       "|     2020|         9| 2020-09-26|       143|       2|        Bronx| 1466438.0|      904|6.164597480425358E-4|61.64597480425357|1.3152654867256637| 3.758019911504428|\n",
       "+---------+----------+-----------+----------+--------+-------------+----------+---------+--------------------+-----------------+------------------+------------------+"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the aggregated yellow tlc data\n",
    "tlc_pu_df = spark.read.parquet(f'{DATA_PATH}/curated/tlc/aggregated/yellow/by_pu')\n",
    "tlc_pu_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the datasets by week_index\n",
    "joined_pu_df = jh.join_by_week_by_borough(tlc_pu_df, covid_df, 'covid')\n",
    "joined_pu_df = jh.join_by_week_by_borough(joined_pu_df, flu_df, 'flu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for only timeline 2\n",
    "joined_pu_df = joined_pu_df.where(F.col('timeline') == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>week_year</th><th>week_month</th><th>week_ending</th><th>week_index</th><th>timeline</th><th>pu_borough</th><th>population</th><th>num_trips</th><th>num_pc_trips</th><th>num_p100k_trips</th><th>avg_passengers</th><th>avg_trip_distance</th><th>covid_week_year</th><th>covid_week_month</th><th>covid_week_ending</th><th>covid_week_index</th><th>covid_timeline</th><th>covid_borough</th><th>covid_population</th><th>covid_tot_cases</th><th>covid_tot_pc_cases</th><th>covid_tot_p100k_cases</th><th>flu_week_year</th><th>flu_week_month</th><th>flu_week_ending</th><th>flu_week_index</th><th>flu_timeline</th><th>flu_borough</th><th>flu_population</th><th>flu_tot_cases</th><th>flu_tot_pc_cases</th><th>flu_tot_p100k_cases</th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+----------+-----------+----------+--------+----------+----------+---------+------------+---------------+--------------+-----------------+---------------+----------------+-----------------+----------------+--------------+-------------+----------------+---------------+------------------+---------------------+-------------+--------------+---------------+--------------+------------+-----------+--------------+-------------+----------------+-------------------+\n",
       "|week_year|week_month|week_ending|week_index|timeline|pu_borough|population|num_trips|num_pc_trips|num_p100k_trips|avg_passengers|avg_trip_distance|covid_week_year|covid_week_month|covid_week_ending|covid_week_index|covid_timeline|covid_borough|covid_population|covid_tot_cases|covid_tot_pc_cases|covid_tot_p100k_cases|flu_week_year|flu_week_month|flu_week_ending|flu_week_index|flu_timeline|flu_borough|flu_population|flu_tot_cases|flu_tot_pc_cases|flu_tot_p100k_cases|\n",
       "+---------+----------+-----------+----------+--------+----------+----------+---------+------------+---------------+--------------+-----------------+---------------+----------------+-----------------+----------------+--------------+-------------+----------------+---------------+------------------+---------------------+-------------+--------------+---------------+--------------+------------+-----------+--------------+-------------+----------------+-------------------+\n",
       "+---------+----------+-----------+----------+--------+----------+----------+---------+------------+---------------+--------------+-----------------+---------------+----------------+-----------------+----------------+--------------+-------------+----------------+---------------+------------------+---------------------+-------------+--------------+---------------+--------------+------------+-----------+--------------+-------------+----------------+-------------------+"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_pu_df.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all columns except those being fitted\n",
    "joined_pu_df = joined_pu_df.select(\n",
    "    'avg_trip_distance',\n",
    "    'week_index',\n",
    "    'pu_borough',\n",
    "    'covid_tot_p100k_cases',\n",
    "    'flu_tot_p100k_cases'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "negative dimensions are not allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/Xavier Travers/Desktop/Uni/ADS/mast30034-project-1-DigitalData/notebooks/data_analysis_distance_vs_virus.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Xavier%20Travers/Desktop/Uni/ADS/mast30034-project-1-DigitalData/notebooks/data_analysis_distance_vs_virus.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m normal_lm \u001b[39m=\u001b[39m ols(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Xavier%20Travers/Desktop/Uni/ADS/mast30034-project-1-DigitalData/notebooks/data_analysis_distance_vs_virus.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     formula \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mavg_trip_distance ~ week_index + pu_borough * covid_tot_p100k_cases + pu_borough * flu_tot_p100k_cases\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Xavier%20Travers/Desktop/Uni/ADS/mast30034-project-1-DigitalData/notebooks/data_analysis_distance_vs_virus.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     data \u001b[39m=\u001b[39;49m joined_pu_df\u001b[39m.\u001b[39;49mtoPandas()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Xavier%20Travers/Desktop/Uni/ADS/mast30034-project-1-DigitalData/notebooks/data_analysis_distance_vs_virus.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m )\u001b[39m.\u001b[39mfit()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/base/model.py:200\u001b[0m, in \u001b[0;36mModel.from_formula\u001b[0;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mif\u001b[39;00m missing \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m:  \u001b[39m# with patsy it's drop or raise. let's raise.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     missing \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 200\u001b[0m tmp \u001b[39m=\u001b[39m handle_formula_data(data, \u001b[39mNone\u001b[39;49;00m, formula, depth\u001b[39m=\u001b[39;49meval_env,\n\u001b[1;32m    201\u001b[0m                           missing\u001b[39m=\u001b[39;49mmissing)\n\u001b[1;32m    202\u001b[0m ((endog, exog), missing_idx, design_info) \u001b[39m=\u001b[39m tmp\n\u001b[1;32m    203\u001b[0m max_endog \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_formula_max_endog\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/statsmodels/formula/formulatools.py:63\u001b[0m, in \u001b[0;36mhandle_formula_data\u001b[0;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m data_util\u001b[39m.\u001b[39m_is_using_pandas(Y, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 63\u001b[0m         result \u001b[39m=\u001b[39m dmatrices(formula, Y, depth, return_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdataframe\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     64\u001b[0m                            NA_action\u001b[39m=\u001b[39;49mna_action)\n\u001b[1;32m     65\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m         result \u001b[39m=\u001b[39m dmatrices(formula, Y, depth, return_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdataframe\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     67\u001b[0m                            NA_action\u001b[39m=\u001b[39mna_action)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/highlevel.py:309\u001b[0m, in \u001b[0;36mdmatrices\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39m\"\"\"Construct two design matrices given a formula_like and data.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \n\u001b[1;32m    301\u001b[0m \u001b[39mThis function is identical to :func:`dmatrix`, except that it requires\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mSee :func:`dmatrix` for details.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    308\u001b[0m eval_env \u001b[39m=\u001b[39m EvalEnvironment\u001b[39m.\u001b[39mcapture(eval_env, reference\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 309\u001b[0m (lhs, rhs) \u001b[39m=\u001b[39m _do_highlevel_design(formula_like, data, eval_env,\n\u001b[1;32m    310\u001b[0m                                   NA_action, return_type)\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m lhs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    312\u001b[0m     \u001b[39mraise\u001b[39;00m PatsyError(\u001b[39m\"\u001b[39m\u001b[39mmodel is missing required outcome variables\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/highlevel.py:164\u001b[0m, in \u001b[0;36m_do_highlevel_design\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdata_iter_maker\u001b[39m():\n\u001b[1;32m    163\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39miter\u001b[39m([data])\n\u001b[0;32m--> 164\u001b[0m design_infos \u001b[39m=\u001b[39m _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[1;32m    165\u001b[0m                                   NA_action)\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m design_infos \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[39mreturn\u001b[39;00m build_design_matrices(design_infos, data,\n\u001b[1;32m    168\u001b[0m                                  NA_action\u001b[39m=\u001b[39mNA_action,\n\u001b[1;32m    169\u001b[0m                                  return_type\u001b[39m=\u001b[39mreturn_type)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/highlevel.py:66\u001b[0m, in \u001b[0;36m_try_incr_builders\u001b[0;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(formula_like, ModelDesc):\n\u001b[1;32m     65\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(eval_env, EvalEnvironment)\n\u001b[0;32m---> 66\u001b[0m     \u001b[39mreturn\u001b[39;00m design_matrix_builders([formula_like\u001b[39m.\u001b[39;49mlhs_termlist,\n\u001b[1;32m     67\u001b[0m                                    formula_like\u001b[39m.\u001b[39;49mrhs_termlist],\n\u001b[1;32m     68\u001b[0m                                   data_iter_maker,\n\u001b[1;32m     69\u001b[0m                                   eval_env,\n\u001b[1;32m     70\u001b[0m                                   NA_action)\n\u001b[1;32m     71\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/build.py:719\u001b[0m, in \u001b[0;36mdesign_matrix_builders\u001b[0;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m    717\u001b[0m design_infos \u001b[39m=\u001b[39m []\n\u001b[1;32m    718\u001b[0m \u001b[39mfor\u001b[39;00m termlist \u001b[39min\u001b[39;00m termlists:\n\u001b[0;32m--> 719\u001b[0m     term_to_subterm_infos \u001b[39m=\u001b[39m _make_subterm_infos(termlist,\n\u001b[1;32m    720\u001b[0m                                                 num_column_counts,\n\u001b[1;32m    721\u001b[0m                                                 cat_levels_contrasts)\n\u001b[1;32m    722\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(term_to_subterm_infos, OrderedDict)\n\u001b[1;32m    723\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mfrozenset\u001b[39m(term_to_subterm_infos) \u001b[39m==\u001b[39m \u001b[39mfrozenset\u001b[39m(termlist)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/build.py:626\u001b[0m, in \u001b[0;36m_make_subterm_infos\u001b[0;34m(terms, num_column_counts, cat_levels_contrasts)\u001b[0m\n\u001b[1;32m    623\u001b[0m levels, contrast \u001b[39m=\u001b[39m cat_levels_contrasts[factor]\n\u001b[1;32m    624\u001b[0m \u001b[39m# This is where the default coding is set to\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \u001b[39m# Treatment:\u001b[39;00m\n\u001b[0;32m--> 626\u001b[0m coded \u001b[39m=\u001b[39m code_contrast_matrix(factor_coding[factor],\n\u001b[1;32m    627\u001b[0m                              levels, contrast,\n\u001b[1;32m    628\u001b[0m                              default\u001b[39m=\u001b[39;49mTreatment)\n\u001b[1;32m    629\u001b[0m contrast_matrices[factor] \u001b[39m=\u001b[39m coded\n\u001b[1;32m    630\u001b[0m subterm_columns \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m coded\u001b[39m.\u001b[39mmatrix\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/contrasts.py:602\u001b[0m, in \u001b[0;36mcode_contrast_matrix\u001b[0;34m(intercept, levels, contrast, default)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[39mreturn\u001b[39;00m contrast\u001b[39m.\u001b[39mcode_with_intercept(levels)\n\u001b[1;32m    601\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 602\u001b[0m     \u001b[39mreturn\u001b[39;00m contrast\u001b[39m.\u001b[39;49mcode_without_intercept(levels)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/patsy/contrasts.py:183\u001b[0m, in \u001b[0;36mTreatment.code_without_intercept\u001b[0;34m(self, levels)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     reference \u001b[39m=\u001b[39m _get_level(levels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreference)\n\u001b[0;32m--> 183\u001b[0m eye \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49meye(\u001b[39mlen\u001b[39;49m(levels) \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    184\u001b[0m contrasts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack((eye[:reference, :],\n\u001b[1;32m    185\u001b[0m                         np\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(levels) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)),\n\u001b[1;32m    186\u001b[0m                         eye[reference:, :]))\n\u001b[1;32m    187\u001b[0m names \u001b[39m=\u001b[39m _name_levels(\u001b[39m\"\u001b[39m\u001b[39mT.\u001b[39m\u001b[39m\"\u001b[39m, levels[:reference] \u001b[39m+\u001b[39m levels[reference \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m:])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/twodim_base.py:215\u001b[0m, in \u001b[0;36meye\u001b[0;34m(N, M, k, dtype, order, like)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m M \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     M \u001b[39m=\u001b[39m N\n\u001b[0;32m--> 215\u001b[0m m \u001b[39m=\u001b[39m zeros((N, M), dtype\u001b[39m=\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49morder)\n\u001b[1;32m    216\u001b[0m \u001b[39mif\u001b[39;00m k \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m M:\n\u001b[1;32m    217\u001b[0m     \u001b[39mreturn\u001b[39;00m m\n",
      "\u001b[0;31mValueError\u001b[0m: negative dimensions are not allowed"
     ]
    }
   ],
   "source": [
    "normal_lm = ols(\n",
    "    formula = 'avg_trip_distance ~ week_index + pu_borough * covid_tot_p100k_cases + pu_borough * flu_tot_p100k_cases',\n",
    "    data = joined_pu_df.toPandas()\n",
    ").fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normal_lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table = sm.stats.anova_lm(moore_lm, typ=2)\n",
    "table = sm.stats.anova_lm(normal_lm, typ=2)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for interaction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
